{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3rOHeiHoOKPe"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78XXjkCdOOzD"},"outputs":[],"source":["!pip install -q pytorch-lightning wandb torchmetrics transformers sentencepiece\n","!pip install -q --upgrade --force-reinstall --no-deps kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQmGCwMMOREH"},"outputs":[],"source":["!mkdir /root/.kaggle\n","!cp /content/drive/MyDrive/Colab/kaggle/kaggle.json /root/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yg3vCpmCcpvn"},"outputs":[],"source":["# import deberta-v2-v3-fast-tokenizer\n","import shutil\n","from pathlib import Path\n","\n","transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n","input_dir = Path(\"/content/drive/MyDrive/Colab/kaggle/nbme-score-clinical-patient-notes/input/deberta-v2-v3-fast-tokenizer\")\n","\n","convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","conversion_path = transformers_path/convert_file.name\n","\n","if conversion_path.exists():\n","    conversion_path.unlink()\n","\n","shutil.copy(convert_file, transformers_path)\n","deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n","    filepath = deberta_v2_path/filename\n","    \n","    if filepath.exists():\n","        filepath.unlink()\n","\n","    shutil.copy(input_dir/filename, filepath)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9159,"status":"ok","timestamp":1649039387670,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"tFUGUD38OVhD","outputId":"b685025b-0aa9-49b2-9127-1a0f003755cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["import os\n","import gc\n","import sys\n","import json\n","import itertools\n","from tqdm.auto import tqdm\n","import logging\n","import datetime\n","import ast\n","import numpy as np\n","import pandas as pd\n","import sklearn.model_selection as sms\n","from sklearn.metrics import f1_score\n","import math\n","import re\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning import Trainer, seed_everything\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n","from pytorch_lightning.loggers import WandbLogger\n","\n","from transformers import AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n","\n","import wandb\n","\n","%env TOKENIZERS_PARALLELISM=true"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1649039387671,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"1duE-kW_OZZq"},"outputs":[],"source":["class Config:\n","    # ==============================\n","    # Globals #\n","    # ==============================\n","    competition_name = \"nbme-score-clinical-patient-notes\"\n","    group = \"DeBERTa-v3-large\"\n","    exp_id = \"009\"\n","    debug = False\n","    inference_only = False\n","    upload_from_colab = True\n","    colab_dir = \"/content/drive/MyDrive/Colab/kaggle/nbme-score-clinical-patient-notes\"\n","    kaggle_json_path = \"/root/.kaggle/kaggle.json\"\n","    kaggle_dataset_path = None\n","    gpus = 1\n","    seed = 2434\n","    max_epochs = 5\n","    accumulate_grad_batches = 4\n","    precision = 32\n","    num_fold = 5\n","    train_fold = [0,1,2,3,4] # 実行するfold\n","    pred_threshold = 0.45\n","    # ==============================\n","    # Dataloader #\n","    # ==============================\n","    train_batch_size = 2\n","    valid_batch_size = 32\n","    test_batch_size = 32\n","    num_workers = 8\n","    # ==============================\n","    # Split #\n","    # ==============================\n","    split_name = \"GroupKFold\"\n","    split_params = {\n","        \"n_splits\": num_fold if not debug else 4,\n","        # \"shuffle\": True,\n","        # \"random_state\": seed,\n","    }\n","    # ==============================\n","    # Model #\n","    # ==============================\n","    model_name = \"microsoft/deberta-v3-large\"\n","    max_length = 512\n","    hidden_size = 1024\n","    num_class = 1\n","    use_backbone_dropout = False\n","    dropout = 0.0\n","    initializer_range = 0.02\n","    lstm_params = {\n","        \"num_layers\": 1,\n","        \"batch_first\": True,\n","        \"bidirectional\": True,\n","        \"dropout\": 0.0\n","    }\n","    # ==============================\n","    # Loss #\n","    # ==============================\n","    loss_name = \"BCEWithLogitsLoss\"\n","    loss_params = {\n","        \"reduction\": \"none\"\n","    }\n","    # ==============================\n","    # Optimizer #\n","    # ==============================\n","    optimizer_name = \"AdamW\"\n","    optimizer_params = {\n","        \"lr\": 2e-5,\n","        \"weight_decay\": 1e-2,\n","        \"eps\": 1e-6,\n","        \"betas\": (0.9, 0.999)\n","    }\n","    encoder_lr = 2e-5\n","    decoder_lr = 2e-5\n","    weight_decay = 0.01\n","    # ==============================\n","    # Scheduler #\n","    # ==============================\n","    scheduler_name = \"cosine-warmup\"\n","    scheduler_warmup_ratio = 0.1\n","    scheduler_params = {}\n","    scheduler_interval = \"step\"\n","    scheduler_cycle = \"one-cycle\" # epoch or one-cycle\n","    # ==============================\n","    # Callbacks #\n","    # ==============================\n","    checkpoint_params = {\n","        \"monitor\": \"val/micro-F1\",\n","        \"save_top_k\": 1,\n","        \"save_weights_only\": True,\n","        \"mode\": \"max\",\n","        \"verbose\": True,\n","    }\n","    early_stopping = False\n","    early_stopping_params = {\n","        \"monitor\": \"val/loss\",\n","        \"min_delta\": 0.0,\n","        \"patience\": 8,\n","        \"verbose\": False,\n","        \"mode\": \"min\",\n","    }"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4434,"status":"ok","timestamp":1649039392098,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"dS4JYVxT1wEt"},"outputs":[],"source":["# ====================================\n","# Setup #\n","# ====================================\n","class Logger:\n","    \"\"\" ref) https://github.com/ghmagazine/kagglebook/blob/master/ch04-model-interface/code/util.py\"\"\"\n","    def __init__(self, path):\n","        self.general_logger = logging.getLogger(path)\n","        stream_handler = logging.StreamHandler()\n","        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n","        if len(self.general_logger.handlers) == 0:\n","            self.general_logger.addHandler(stream_handler)\n","            self.general_logger.addHandler(file_general_handler)\n","            self.general_logger.setLevel(logging.INFO)\n","\n","    def info(self, message):\n","        # display time\n","        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n","\n","    @staticmethod\n","    def now_string():\n","        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n","\n","\n","def setup(cfg):\n","    cfg.on_colab = \"google.colab\" in sys.modules\n","    if cfg.on_colab:\n","        # kaggle api\n","        f = open(Config.kaggle_json_path, 'r')\n","        json_data = json.load(f)\n","        os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n","        # set input/output dir\n","        cfg.input_dir = os.path.join(cfg.colab_dir, \"input\")\n","        cfg.train_csv = os.path.join(cfg.input_dir, \"cleaned_train.csv\")\n","        cfg.features_csv = os.path.join(cfg.input_dir, \"features.csv\")\n","        cfg.patient_notes_csv = os.path.join(cfg.input_dir, \"patient_notes.csv\")\n","        cfg.test_csv = os.path.join(cfg.input_dir, \"test.csv\")\n","        cfg.sample_submission = os.path.join(cfg.input_dir, \"sample_submission.csv\")\n","        cfg.output_dir = os.path.join(cfg.colab_dir, \"output\")\n","        cfg.exp_output_dir = os.path.join(cfg.output_dir, f\"exp{cfg.exp_id}\")\n","        cfg.model_dir = os.path.join(cfg.exp_output_dir, \"model\")\n","\n","        for d in [cfg.output_dir, cfg.exp_output_dir, cfg.model_dir]:\n","            os.makedirs(d, exist_ok=True)\n","            \n","        # wandb\n","        wandb.login()\n","    else:\n","        cfg.input_dir = f\"../input/{cfg.competition_name}\"\n","        cfg.train_csv = os.path.join(cfg.input_dir, \"train.csv\")\n","        cfg.features_csv = os.path.join(cfg.input_dir, \"features.csv\")\n","        cfg.patient_notes_csv = os.path.join(cfg.input_dir, \"patient_notes.csv\")\n","        cfg.test_csv = os.path.join(cfg.input_dir, \"test.csv\")\n","        cfg.sample_submission = os.path.join(cfg.input_dir, \"sample_submission.csv\")\n","        cfg.submission = \"./\"\n","        cfg.exp_output_dir = f\"exp{cfg.exp_id}\"\n","        cfg.model_dir = os.path.join(cfg.exp_output_dir, \"model\")\n","\n","        if cfg.kaggle_dataset_path is not None:\n","            cfg.model_dir = os.path.join(cfg.kaggle_dataset_path, \"model\")\n","\n","        for d in [cfg.exp_output_dir, cfg.model_dir]:\n","            os.makedirs(d, exist_ok=True)\n","\n","    return cfg\n","\n","\n","# ====================================\n","# Preprocess #\n","# ====================================\n","def get_input_data(cfg, input_type=\"train\"):\n","    input_df = pd.read_csv(cfg.train_csv) if input_type == \"train\" else pd.read_csv(cfg.test_csv)\n","    if cfg.debug and input_type != \"test\":\n","        input_df = input_df[input_df[\"pn_num\"].isin(input_df[\"pn_num\"].unique()[:100])].reset_index(drop=True)\n","    \n","    feature_texts_df = pd.read_csv(Config.features_csv)\n","    patient_notes_df = pd.read_csv(Config.patient_notes_csv)\n","\n","    if input_type == \"train\":\n","        input_df[\"annotation\"] = input_df[\"annotation\"].apply(ast.literal_eval)\n","        input_df[\"location\"] = input_df[\"location\"].apply(ast.literal_eval)\n","    \n","    input_df = input_df.merge(feature_texts_df, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","    input_df = input_df.merge(patient_notes_df, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","    input_df[\"pn_history\"] = input_df[\"pn_history\"].apply(clean_feature_text_for_preprocess)\n","\n","    return input_df\n","\n","\n","def get_split(cfg, train_df):\n","    split_name = cfg.split_name\n","    split_params = cfg.split_params\n","    splitter = sms.__getattribute__(split_name)(**split_params)\n","\n","    groups = train_df[\"pn_num\"].to_numpy()\n","    train_df[\"fold\"] = -1\n","\n","    for fold_id, (train_idx, valid_idx) in enumerate(splitter.split(train_df, train_df[\"location\"], groups)):\n","        train_df.loc[valid_idx, \"fold\"] = int(fold_id)\n","\n","    return train_df\n","\n","\n","def get_filname_listdir(dirctory):\n","    listdir = os.listdir(dirctory)\n","    out_lst = [os.path.splitext(d)[0] for d in listdir]\n","    return out_lst\n","\n","\n","def get_tokenizer(cfg):\n","    if cfg.kaggle_dataset_path is not None:\n","        pretrained_dir = os.path.join(cfg.kaggle_dataset_path, \"pretrain_tokenizer\")\n","    else:\n","        pretrained_dir = os.path.join(cfg.exp_output_dir, \"pretrain_tokenizer\")\n","\n","    if not os.path.isdir(pretrained_dir):\n","        # deberta-v2 or deberta-v3\n","        if (\"deberta-v2\" in cfg.model_name) or (\"deberta-v3\" in cfg.model_name):\n","            tokenizer = DebertaV2TokenizerFast.from_pretrained(cfg.model_name)\n","        # except for (\"roberta\", \"deberta-v2\", \"deberta-v3\")\n","        elif \"roberta\" not in cfg.model_name:\n","            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n","        # roberta\n","        else:\n","            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name, trim_offsets=False)\n","\n","        tokenizer.save_pretrained(pretrained_dir)\n","\n","    else:\n","        # deberta-v2 or deberta-v3\n","        if (\"deberta-v2\" in cfg.model_name) or (\"deberta-v3\" in cfg.model_name):\n","            tokenizer = DebertaV2TokenizerFast.from_pretrained(pretrained_dir)\n","        # except for (\"roberta\", \"deberta-v2\", \"deberta-v3\")\n","        elif \"roberta\" not in cfg.model_name:\n","            tokenizer = AutoTokenizer.from_pretrained(pretrained_dir)\n","        # roberta\n","        else:\n","            tokenizer = AutoTokenizer.from_pretrained(pretrained_dir, trim_offsets=False)\n","\n","    return tokenizer\n","\n","\n","def get_backbone(cfg):\n","    if cfg.kaggle_dataset_path is not None:\n","        pretrained_dir = os.path.join(cfg.kaggle_dataset_path, \"pretrain_model\")\n","    else:\n","        pretrained_dir = os.path.join(cfg.exp_output_dir, \"pretrain_model\")\n","\n","    if not os.path.isdir(pretrained_dir):\n","        model_config = AutoConfig.from_pretrained(cfg.model_name)\n","        if not cfg.use_backbone_dropout:\n","            model_config.attention_probs_dropout_prob = 0.0\n","            model_config.hidden_dropout_prob = 0.0\n","        backbone = AutoModel.from_pretrained(cfg.model_name, config=model_config)\n","\n","        backbone.save_pretrained(pretrained_dir)\n","\n","    else:\n","        model_config = AutoConfig.from_pretrained(pretrained_dir)\n","        if not cfg.use_backbone_dropout:\n","            model_config.attention_probs_dropout_prob = 0.0\n","            model_config.hidden_dropout_prob = 0.0\n","        backbone = AutoModel.from_pretrained(pretrained_dir, config=model_config)\n","\n","    return backbone\n","\n","\n","def clean_feature_text_for_preprocess(text: str):\n","    \"\"\"\n","    reference: https://www.kaggle.com/code/theoviel/roberta-strikes-back\n","    \"\"\"\n","    text = re.sub('I-year', '1-year', text)\n","    text = re.sub('-OR-', \" or \", text)\n","    text = re.sub('-', ' ', text)\n","\n","    return text\n","\n","\n","# ====================================\n","# Dataset #\n","# ====================================\n","def get_inputs(cfg, text: str, feature_text: str, tokenizer):\n","    encoding = tokenizer(\n","        text,\n","        feature_text,\n","        max_length=cfg.max_length,\n","        padding=\"max_length\",\n","        return_offsets_mapping=False,\n","        # add_special_tokens=True\n","    )\n","\n","    for k, v in encoding.items():\n","        encoding[k] = torch.tensor(v, dtype=torch.long)\n","\n","    return encoding\n","\n","\n","def get_label(cfg, text: str, locations: list, tokenizer):\n","    encoding = tokenizer(\n","        text,\n","        max_length=cfg.max_length,\n","        padding=\"max_length\",\n","        return_offsets_mapping=True,\n","        # add_special_tokens=True\n","    )\n","    \n","    offset_mapping = encoding[\"offset_mapping\"]\n","    ignore_idx = np.where(np.array(encoding.sequence_ids()) != 0)[0]\n","    label = np.zeros(len(offset_mapping))\n","    label[ignore_idx] = -1\n","\n","    if len(locations) != 0:\n","        for location in locations:\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start_idx = -1\n","                end_idx = -1\n","                start, end = int(loc[0]), int(loc[1])\n","                for idx in range(len(offset_mapping)):\n","                    # DeBERTaのTokenizerは前の空白も含めるため+1する\n","                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                        start_idx = idx - 1\n","                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                        end_idx = idx + 1\n","                if start_idx == -1:\n","                    start_idx = end_idx\n","                if (start_idx != -1) & (end_idx != -1):\n","                    label[start_idx: end_idx] = 1\n","    \n","    return torch.tensor(label, dtype=torch.float)\n","\n","\n","class NBMEDataset(Dataset):\n","    def __init__(self, cfg, input_df: pd.DataFrame, tokenizer, phase: str = \"train\"):\n","        self.cfg = cfg\n","        self.input_df = input_df\n","        self.tokenizer = tokenizer\n","        self.phase = phase\n","        self.pn_histories = self.input_df[\"pn_history\"].to_numpy()\n","        self.feature_texts = self.input_df[\"feature_text\"].to_numpy()\n","        self.locations = self.input_df[\"location\"].to_numpy() if self.phase is \"train\" else None\n","\n","    def __len__(self):\n","        return len(self.input_df)\n","\n","    def __getitem__(self, idx):\n","        if self.phase == \"train\":\n","            inputs = get_inputs(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.feature_texts[idx],\n","                self.tokenizer,\n","            )\n","            label = get_label(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.locations[idx],\n","                self.tokenizer,\n","            )\n","\n","            return {\n","                \"input_ids\": inputs[\"input_ids\"],\n","                \"attention_mask\": inputs[\"attention_mask\"],\n","                \"labels\": label,\n","            }\n","\n","        elif self.phase == \"test\":\n","            inputs = get_inputs(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.feature_texts[idx],\n","                self.tokenizer,\n","            )\n","\n","            return {\n","                \"input_ids\": inputs[\"input_ids\"],\n","                \"attention_mask\": inputs[\"attention_mask\"],\n","            }\n","        else:\n","            raise NotImplementedError\n","\n","\n","class NBMEDataModule(pl.LightningDataModule):\n","    def __init__(self, cfg, tokenizer, train_df: pd.DataFrame = None, valid_df: pd.DataFrame = None, test_df: pd.DataFrame = None):\n","        super(NBMEDataModule, self).__init__()\n","\n","        self.cfg = cfg\n","        self.tokenizer = tokenizer\n","        self.train_df = train_df\n","        self.valid_df = valid_df\n","        self.test_df = test_df\n","\n","    def prepare_data(self):\n","        if self.test_df is None:\n","            self.train_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.train_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"train\"\n","            )\n","            self.val_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.valid_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"train\"\n","            )\n","        else:\n","            self.test_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.test_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"test\"\n","            )\n","\n","    def train_dataloader(self):\n","        return DataLoader(\n","            self.train_dataset,\n","            batch_size=self.cfg.train_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","    \n","    def val_dataloader(self):\n","        return DataLoader(\n","            self.val_dataset,\n","            batch_size=self.cfg.valid_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","\n","    def predict_dataloader(self):\n","        return DataLoader(\n","            self.test_dataset,\n","            batch_size=self.cfg.test_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","\n","\n","# ====================================\n","# Model #\n","# ====================================\n","class NBMEModel(nn.Module):\n","    def __init__(self, cfg):\n","        super(NBMEModel, self).__init__()\n","\n","        self.cfg = cfg\n","        self.backbone = get_backbone(self.cfg)\n","        self.dropout = nn.Dropout(self.cfg.dropout)\n","        self.lstm = nn.LSTM(self.cfg.hidden_size, self.cfg.hidden_size, **self.cfg.lstm_params)\n","        self.classifier = nn.Linear(self.cfg.hidden_size * 2, self.cfg.num_class)\n","        self._init_weights(self.classifier)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.cfg.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.cfg.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask) # (batch_size, seq_len, hidden_size)\n","        x = outputs[0] # extract last_hidden_states\n","        x, _ = self.lstm(x)\n","        x = self.dropout(x)\n","        x = self.classifier(x) # (batch_size, seq_len, num_class)\n","\n","        return x\n","\n","\n","class NBMELightningModule(pl.LightningModule):\n","    def __init__(self, cfg, tokenizer=None, valid_df=None, valid_labels=None):\n","        super(NBMELightningModule, self).__init__()\n","\n","        self.cfg = cfg\n","        self.model = NBMEModel(self.cfg)\n","        self.criterion = get_criterion(self.cfg)\n","        self.tokenizer = tokenizer\n","        self.valid_df = valid_df\n","        self.valid_labels = valid_labels\n","\n","    def setup(self, stage=None):\n","        # calculate training total steps\n","        if stage == \"fit\":\n","            if self.cfg.scheduler_cycle == \"one-cycle\":\n","                self.training_steps = math.ceil(len(self.trainer.datamodule.train_dataloader()) / self.trainer.accumulate_grad_batches) * self.trainer.max_epochs\n","            elif self.cfg.scheduler_cycle == \"epoch\":\n","                self.training_steps = math.ceil(len(self.trainer.datamodule.train_dataloader()) / self.trainer.accumulate_grad_batches) * 1\n","            else:\n","                raise NotImplementedError\n","            self.warmup_steps = int(self.training_steps * self.cfg.scheduler_warmup_ratio) if self.cfg.scheduler_warmup_ratio else None\n","    \n","    def forward(self, input_ids, attention_mask):\n","        return self.model(input_ids, attention_mask)\n","\n","    def training_step(self, batch, batch_idx):\n","        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        mask = (labels.view(-1, 1) != -1)\n","        loss = torch.masked_select(loss, mask).mean()\n","        self.log(\"train/loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        mask = (labels.view(-1, 1) != -1)\n","        loss = torch.masked_select(loss, mask).mean()\n","        self.log(\"val/loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n","\n","        return {\n","            \"loss\": loss,\n","            \"preds\": y_preds.detach()\n","        }\n","\n","    def validation_epoch_end(self, outputs):\n","        preds = torch.cat([output[\"preds\"] for output in outputs]).squeeze().cpu().numpy()\n","        char_preds = get_token_probs_to_char_probs(self.valid_df[\"pn_history\"].to_numpy(), preds, self.tokenizer)\n","        results = get_results(char_preds, th=0.5)\n","        preds = get_predictions(results)\n","        score = get_score(self.valid_labels, preds)\n","        self.log(\"val/micro-F1\", score, logger=True, prog_bar=True)\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n","        input_ids, attention_mask = batch[\"input_ids\"], batch[\"attention_mask\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        y_preds = y_preds.sigmoid()\n","\n","        return y_preds.squeeze()\n","\n","    def configure_optimizers(self):\n","        optimizer_params = get_optimizer_params(self.model, self.cfg.encoder_lr, self.cfg.decoder_lr, self.cfg.weight_decay)\n","        optimizer = get_optimizer(self.cfg, optimizer_params)\n","\n","        if self.cfg.scheduler_name is None:\n","            return [optimizer]\n","        else:\n","            scheduler = get_scheduler(self.cfg, optimizer, num_warmup_steps=self.warmup_steps, num_training_steps=self.training_steps)\n","            scheduler = {\"scheduler\": scheduler, \"interval\": self.cfg.scheduler_interval}\n","\n","            return [optimizer], [scheduler]\n","\n","\n","# ====================================\n","# Criterion, Optimizer, Scheduler #\n","# ====================================\n","def get_criterion(cfg):\n","    loss_name = cfg.loss_name\n","    loss_params = cfg.loss_params\n","\n","    return nn.__getattribute__(loss_name)(**loss_params)\n","\n","\n","def get_optimizer(cfg, parameters):\n","    optimizer_name = cfg.optimizer_name\n","    optimizer_params = cfg.optimizer_params\n","\n","    return optim.__getattribute__(optimizer_name)(parameters, **optimizer_params)\n","\n","\n","def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","    # param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_parameters = [\n","        {'params': [p for n, p in model.backbone.named_parameters() if not any(nd in n for nd in no_decay)],\n","            'lr': encoder_lr, 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.backbone.named_parameters() if any(nd in n for nd in no_decay)],\n","            'lr': encoder_lr, 'weight_decay': 0.0},\n","        {'params': [p for n, p in model.named_parameters() if \"backbone\" not in n],\n","            'lr': decoder_lr, 'weight_decay': 0.0}\n","    ]\n","\n","    return optimizer_parameters\n","\n","\n","def get_scheduler(cfg, optimizer, num_warmup_steps=None, num_training_steps=None):\n","    scheduler_name = cfg.scheduler_name\n","    scheduler_params = cfg.scheduler_params\n","\n","    if scheduler_name == \"cosine-warmup\":\n","        return get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","            **scheduler_params\n","        )\n","    elif scheduler_name == \"linear-warmup\":\n","        return get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","            **scheduler_params\n","        )\n","    else:\n","        return optim.lr_scheduler.__getattribute__(scheduler_name)(optimizer, **scheduler_params)\n","\n","\n","# ====================================\n","# Train & Predict #\n","# ====================================\n","def train_fold(cfg, train_df, valid_df, tokenizer, fold, valid_labels):\n","    # Seed\n","    seed_everything(cfg.seed)\n","\n","    # Wandb\n","    wandb_logger = WandbLogger(\n","        project=cfg.competition_name,\n","        group=cfg.group,\n","        name=f\"exp{cfg.exp_id}-fold-{fold}\",\n","        job_type=f\"exp{cfg.exp_id}\",\n","        reinit=True,\n","        anonymous=\"must\",\n","    )\n","\n","    # Model Checkpoint\n","    checkpoint = ModelCheckpoint(\n","        dirpath=cfg.model_dir,\n","        # filename=f\"exp{cfg.exp_id}-fold-{fold}\" + \"-{epoch}\",\n","        filename=f\"exp{cfg.exp_id}-fold-{fold}\",\n","        **cfg.checkpoint_params,\n","    )\n","\n","    # Learning Rate\n","    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n","    callbacks = [checkpoint, lr_monitor]\n","\n","    # Early Stopping\n","    if cfg.early_stopping:\n","        early_stopping = EarlyStopping(**cfg.early_stopping_params)\n","        callbacks += [early_stopping]\n","    \n","    # DataModule\n","    lightning_datamodule = NBMEDataModule(\n","        cfg=cfg,\n","        tokenizer=tokenizer,\n","        train_df=train_df,\n","        valid_df=valid_df,\n","    )\n","\n","    # Model\n","    lightning_model = NBMELightningModule(\n","        cfg,\n","        tokenizer,\n","        valid_df,\n","        valid_labels,\n","    )\n","\n","    # Trainer\n","    trainer = Trainer(\n","        gpus=cfg.gpus,\n","        max_epochs=cfg.max_epochs,\n","        callbacks=callbacks,\n","        logger=[wandb_logger],\n","        accumulate_grad_batches=cfg.accumulate_grad_batches,\n","        precision=cfg.precision,\n","        # deterministic=True,\n","        benchmark=False,\n","    )\n","\n","    trainer.fit(lightning_model, datamodule=lightning_datamodule)\n","    wandb.finish(quiet=True)\n","\n","    del lightning_datamodule, lightning_model, trainer\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","\n","def train_cv(cfg, input_df, tokenizer):\n","    oof_char_probs = []\n","    true_labels = []\n","\n","    for fold_id in range(cfg.num_fold):\n","        if fold_id in cfg.train_fold:\n","            filename = f\"exp{cfg.exp_id}-fold-{fold_id}\"\n","            filelist = get_filname_listdir(cfg.model_dir)\n","\n","            train_df = input_df[input_df[\"fold\"] != fold_id].reset_index(drop=True)\n","            valid_df = input_df[input_df[\"fold\"] == fold_id].reset_index(drop=True)\n","            valid_labels = create_labels_for_scoring(valid_df)\n","\n","            # training\n","            if not filename in filelist:\n","                train_fold(\n","                    cfg=cfg,\n","                    train_df=train_df,\n","                    valid_df=valid_df,\n","                    tokenizer=tokenizer,\n","                    fold=fold_id,\n","                    valid_labels=valid_labels,\n","                )\n","\n","            # oof\n","            char_probs = predict(\n","                cfg=cfg,\n","                input_df=valid_df,\n","                tokenizer=tokenizer,\n","                filename=filename,\n","                labels=valid_labels,\n","            )\n","            results = get_results(char_probs, th=0.5)\n","            preds = get_predictions(results)\n","            oof_score = get_score(valid_labels, preds)\n","            cfg.logger.info(f\"Fold: {fold_id} oof-score: {oof_score}\")\n","            \n","            oof_char_probs += char_probs\n","            true_labels += valid_labels\n","\n","    return oof_char_probs, true_labels\n","\n","\n","def predict_raw_prediction(cfg, input_df, tokenizer, filename, labels=None):\n","    checkpoint_path = os.path.join(cfg.model_dir, filename + \".ckpt\")\n","\n","    lightning_model = NBMELightningModule(\n","        cfg,\n","        tokenizer,\n","        input_df,\n","        labels,\n","    )\n","\n","    lightning_model = lightning_model.load_from_checkpoint(\n","        checkpoint_path=checkpoint_path,\n","        cfg=cfg,\n","    )\n","\n","    lightning_datamodule = NBMEDataModule(\n","        cfg,\n","        tokenizer=tokenizer,\n","        test_df=input_df\n","    )\n","\n","    trainer = Trainer(\n","        gpus=cfg.gpus,\n","    )\n","\n","    preds = trainer.predict(\n","        lightning_model,\n","        datamodule=lightning_datamodule,\n","        return_predictions=True\n","    )\n","\n","    preds = torch.cat(preds).cpu().numpy() # (sample, max_seq, num_class)\n","\n","    del lightning_datamodule, lightning_model, trainer\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    \n","    return preds\n","    \n","\n","def predict(cfg, input_df, tokenizer, filename, labels):\n","    file_path = os.path.join(cfg.exp_output_dir, f\"{filename}.npy\")\n","    \n","    if os.path.isfile(file_path):\n","        preds = np.load(file_path)\n","    else:\n","        preds = predict_raw_prediction(cfg, input_df, tokenizer, filename, labels)\n","        np.save(os.path.join(cfg.exp_output_dir, filename), preds)\n","\n","    char_probs = get_token_probs_to_char_probs(input_df[\"pn_history\"].to_numpy(), preds, tokenizer)\n","\n","    return char_probs\n","\n","\n","def predict_cv(cfg, input_df, tokenizer):\n","    \"\"\"\n","    CVモデルで予測\n","    \"\"\"\n","    fold_preds = []\n","    for fold_id in range(cfg.num_fold):\n","        if fold_id in cfg.train_fold:\n","            filename = f\"exp{cfg.exp_id}-fold-{fold_id}\"\n","            preds = predict_raw_prediction(cfg, input_df, tokenizer, filename)\n","            char_preds = get_token_probs_to_char_probs(input_df[\"pn_history\"].to_numpy(), preds, tokenizer)\n","            fold_preds.append(char_preds)\n","\n","    fold_preds = np.mean(fold_preds, axis=0)\n","    results = get_results(fold_preds, th=cfg.pred_threshold)\n","\n","    output_df = input_df.copy()\n","    output_df[\"location\"] = results\n","    \n","    return output_df\n","\n","\n","def get_token_probs_to_char_probs(texts, predictions, tokenizer):\n","    \"\"\"\n","    予測値をtoken-level -> char-levelに変形\n","    \"\"\"\n","    results = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n","        encoded = tokenizer(\n","            text, \n","            add_special_tokens=True,\n","            return_offsets_mapping=True\n","        )\n","        \n","        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n","            start = offset_mapping[0]\n","            end = offset_mapping[1]\n","\n","            # 先行するスペースがあればスパンから除く\n","            # if text[start] == \" \":\n","            #     start = start + 1\n","            \n","            results[i][start: end] = pred\n","    \n","    return results\n","\n","\n","def get_results(char_probs, th=0.5):\n","    \"\"\"\n","    \";\"区切りのスパンに変換\n","    \"\"\"\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    \n","    return results\n","\n","\n","def get_predictions(results):\n","    \"\"\"\n","    各スパンのリストを要素とするリストに変換\n","    '3 4;7 9;12 13' -> [[3, 4], [7, 9], [12, 13]]\n","    \"\"\"\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(';')]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    \n","    return predictions\n","\n","\n","def create_labels_for_scoring(df):\n","    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n","    df = df.copy()\n","    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, 'location']\n","        if lst:\n","            new_lst = ';'.join(lst)\n","            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n","    # create labels\n","    truths = []\n","    for location_list in df['location_for_create_labels'].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(';')]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","    \n","    return truths\n","\n","\n","# ====================================\n","# Metrics #\n","# ====================================\n","def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    \n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    \n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","\n","    return score\n","\n","\n","# ====================================\n","# Postprocess #\n","# ====================================\n","def optimize_threshold_for_postprocess(cfg, valid_labels, char_probs):\n","    best_thres = 0.5\n","    best_score = 0.0\n","    for th in np.arange(0.40, 0.60, 0.01):\n","        th = np.round(th, 2)\n","        results = get_results(char_probs, th=th)\n","        preds = get_predictions(results)\n","        score = get_score(valid_labels, preds)\n","\n","        if best_score < score:\n","            best_thres = th\n","            best_score = score\n","\n","        cfg.logger.info(f\"th: {th}  score: {score:.5f}\")\n","    cfg.logger.info(f\"best_th: {best_thres}  score: {best_score:.5f}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["fe057c8638c042d0a3f1cd8198f16797","cb0c24dbdb2d4607b86a5c82891dbc0b","26065160dc344c57afaff943cdd547ff","e423bb1538584d2bb28ec77edf700def","c92d5fb7c9b849748c8ba2261686e506","572d8996f35c491990b50768c0a9b8f4","4940f21b169947e7a672e07b5da0581a","38b9571d053541d3a904d0dd965365fc","a9bfa978e53d43b89020dfb288762df6","e9181f28c41f46e6920b45ff8d73d962","420591932cef4ed69d8a80604c4222d2","24a3910b0f464d5396374de586903149","549e530bd96e4f3e9b43021604869c55","c476f685cce5427fad04031a3a7a50a9","3d6ad534f39345168d431d20cdec42ce","9b6a3441bd2f482b90aae4212a027cb2","9cd10a8c1f9f416a83f68ea558d9f261","7e413fc532da4128b7c495d1ad1f0c97","6a9088aef78a4e9db4264b3020366221","68bbe0377884475ab9da7e68bcee441d","b91e3438379644bd999614640f9daa38","c3155d5d3c784748be13ada3d2a129b9","c9f3599303f54c46a8321aec97f7b502","6ab6595849db4788b45b3851f4c4cc1d","9c2c531dc9334f949b249951ff41daab","1f19efa89a6b4c37aef37db937a399b4","2b22ac33f6c440628d352c9b42bb2c91","8dfeb686bf594d7daee05397ea62f3bf","9dc2ce187b204a9fb2f5c1a78fbc7a48","8e8d7df0617c4d7ea79ddd8697b044d9","24a33a8e9acb4a29992984c79cbaa6ac","b68ee0105df046f2b28ffc0c39072bb2","fdda1574a76f40daa05759f7e114a545","158e7c8914594e91b62c6be28c03a923","4d54d44850b647af87bb037609b64ac4","e4f23b4d67c84c7697578cb47f83eafb","9d0ad204020342bca6c22847d92212e2","5e16cfdde9224db5a20a10fdfa08edbe","82a77a060f634cb98ade476ae3779bc6","e2591cfad3e04e66a922338ce4393c34","b762a3d21d35487ab11b197b366f9775","3e5c95d031df499eaf35773a2df85e54","28f1a3c451654f89b0bf51ef4090082a","fe4e3798c4164faba7320b22447dc347","b42863368cff407a9543d4cc3e917503","14f9e928d82d4bc5be73a4f3cbf8d5eb","adf068867c874eef980e49381df15b33","36062e5d409a45489ce12cc25c3c34c6","439c330ea8a4437381ac3de6e1307701","781ddcbaf06e457b83a66d1b08bb79d3","5a8561a4d8a84958901f296fbe55c0aa","011036d94f814f3e808f4dea6a7aa1aa","3e4c87b999824bb3ae0ed131bbebd490","b8b5e531ca6142cea0fe4f7f1340932a","c673edceaf2f4d4cab0d65a595ea6cc4"]},"id":"ytwVk3R5jvUe","executionInfo":{"status":"ok","timestamp":1649039966677,"user_tz":-540,"elapsed":574600,"user":{"displayName":"永友遥","userId":"11743586908271963047"}},"outputId":"b54a3d1f-f715-40dd-ad86-50970a9646f3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","[2022-04-04 02:30:07] - Fold: 0 oof-score: 0.8829342603804538\n","[2022-04-04 02:30:10] - Fold: 1 oof-score: 0.8786625393606233\n","[2022-04-04 02:30:13] - Fold: 2 oof-score: 0.8739383977143753\n","[2022-04-04 02:30:16] - Fold: 3 oof-score: 0.8734382476474027\n","[2022-04-04 02:30:19] - Fold: 4 oof-score: 0.8749065408513161\n","[2022-04-04 02:30:21] - th: 0.4  score: 0.87709\n","[2022-04-04 02:30:24] - th: 0.41  score: 0.87711\n","[2022-04-04 02:30:26] - th: 0.42  score: 0.87724\n","[2022-04-04 02:30:28] - th: 0.43  score: 0.87737\n","[2022-04-04 02:30:30] - th: 0.44  score: 0.87744\n","[2022-04-04 02:30:32] - th: 0.45  score: 0.87753\n","[2022-04-04 02:30:34] - th: 0.46  score: 0.87742\n","[2022-04-04 02:30:36] - th: 0.47  score: 0.87732\n","[2022-04-04 02:30:38] - th: 0.48  score: 0.87721\n","[2022-04-04 02:30:40] - th: 0.49  score: 0.87697\n","[2022-04-04 02:30:42] - th: 0.5  score: 0.87678\n","[2022-04-04 02:30:44] - th: 0.51  score: 0.87681\n","[2022-04-04 02:30:46] - th: 0.52  score: 0.87694\n","[2022-04-04 02:30:48] - th: 0.53  score: 0.87677\n","[2022-04-04 02:30:50] - th: 0.54  score: 0.87661\n","[2022-04-04 02:30:52] - th: 0.55  score: 0.87666\n","[2022-04-04 02:30:54] - th: 0.56  score: 0.87659\n","[2022-04-04 02:30:56] - th: 0.57  score: 0.87621\n","[2022-04-04 02:30:58] - th: 0.58  score: 0.87618\n","[2022-04-04 02:31:00] - th: 0.59  score: 0.87577\n","[2022-04-04 02:31:00] - best_th: 0.45  score: 0.87753\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n","  category=PossibleUserWarning,\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","Missing logger folder: /content/lightning_logs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe057c8638c042d0a3f1cd8198f16797"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24a3910b0f464d5396374de586903149"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9f3599303f54c46a8321aec97f7b502"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"158e7c8914594e91b62c6be28c03a923"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b42863368cff407a9543d4cc3e917503"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting upload for file model.tar\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8.40G/8.40G [03:54<00:00, 38.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: model.tar (8GB)\n","Starting upload for file pretrain_tokenizer.tar\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10.6M/10.6M [00:03<00:00, 3.58MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: pretrain_tokenizer.tar (11MB)\n","Starting upload for file pretrain_model.tar\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.62G/1.62G [00:44<00:00, 39.0MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: pretrain_model.tar (2GB)\n","Starting upload for file exp009-fold-0.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:02<00:00, 1.99MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp009-fold-0.npy (6MB)\n","Starting upload for file exp009-fold-1.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:04<00:00, 1.30MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp009-fold-1.npy (6MB)\n","Starting upload for file exp009-fold-2.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:02<00:00, 2.60MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp009-fold-2.npy (6MB)\n","Starting upload for file exp009-fold-3.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:02<00:00, 2.06MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp009-fold-3.npy (6MB)\n","Starting upload for file exp009-fold-4.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:02<00:00, 2.27MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp009-fold-4.npy (6MB)\n","Starting upload for file Experiment.log\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.31k/1.31k [00:04<00:00, 333B/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: Experiment.log (1KB)\n"]}],"source":["def main(Config):\n","    # setup\n","    Config = setup(Config)\n","    Config.logger = Logger(Config.exp_output_dir)\n","    # load dataset\n","    train_df = get_input_data(Config, input_type=\"train\")\n","    test_df = get_input_data(Config, input_type=\"test\")\n","    submission_df = pd.read_csv(Config.sample_submission)\n","\n","    # split\n","    train_df = get_split(Config, train_df)\n","\n","    # tokenizer\n","    tokenizer = get_tokenizer(Config)\n","\n","    if not Config.inference_only:\n","        # training\n","        raw_oof_char_probs, true_labels = train_cv(\n","            cfg=Config,\n","            input_df=train_df,\n","            tokenizer=tokenizer,\n","        )\n","        # optimize threshold\n","        optimize_threshold_for_postprocess(Config, true_labels, raw_oof_char_probs)\n","\n","    # predict\n","    raw_pred_df = predict_cv(\n","        cfg=Config,\n","        input_df=test_df,\n","        tokenizer=tokenizer,\n","    )\n","\n","    # upload output to kaggle dataset\n","    if Config.upload_from_colab:\n","        from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","        def dataset_create_new(dataset_name, upload_dir):\n","            dataset_metadata = {}\n","            dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","            dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","            dataset_metadata['title'] = dataset_name\n","            with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","                json.dump(dataset_metadata, f, indent=4)\n","            api = KaggleApi()\n","            api.authenticate()\n","            api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n","\n","        dataset_create_new(dataset_name=f\"{Config.competition_name}-exp{Config.exp_id}\", upload_dir=Config.exp_output_dir)\n","\n","    # make submission\n","    if not Config.on_colab:\n","        raw_pred_df[[\"id\", \"location\"]].to_csv(os.path.join(Config.submission, \"submission.csv\"), index=False)\n","\n","\n","if __name__ == \"__main__\":\n","    main(Config)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"nfsZJQyVq-oT","executionInfo":{"status":"ok","timestamp":1649039966678,"user_tz":-540,"elapsed":10,"user":{"displayName":"永友遥","userId":"11743586908271963047"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"exp009.ipynb","provenance":[],"mount_file_id":"1x133M6KZH9FVTODlUv4nObGecvEnnyFp","authorship_tag":"ABX9TyNcvr8CyXY3p8cLv3AAFkuS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"fe057c8638c042d0a3f1cd8198f16797":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb0c24dbdb2d4607b86a5c82891dbc0b","IPY_MODEL_26065160dc344c57afaff943cdd547ff","IPY_MODEL_e423bb1538584d2bb28ec77edf700def"],"layout":"IPY_MODEL_c92d5fb7c9b849748c8ba2261686e506"}},"cb0c24dbdb2d4607b86a5c82891dbc0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_572d8996f35c491990b50768c0a9b8f4","placeholder":"​","style":"IPY_MODEL_4940f21b169947e7a672e07b5da0581a","value":"Predicting DataLoader 0: 100%"}},"26065160dc344c57afaff943cdd547ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38b9571d053541d3a904d0dd965365fc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9bfa978e53d43b89020dfb288762df6","value":1}},"e423bb1538584d2bb28ec77edf700def":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9181f28c41f46e6920b45ff8d73d962","placeholder":"​","style":"IPY_MODEL_420591932cef4ed69d8a80604c4222d2","value":" 1/1 [00:01&lt;00:00,  1.46s/it]"}},"c92d5fb7c9b849748c8ba2261686e506":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"572d8996f35c491990b50768c0a9b8f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4940f21b169947e7a672e07b5da0581a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38b9571d053541d3a904d0dd965365fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9bfa978e53d43b89020dfb288762df6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9181f28c41f46e6920b45ff8d73d962":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"420591932cef4ed69d8a80604c4222d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24a3910b0f464d5396374de586903149":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_549e530bd96e4f3e9b43021604869c55","IPY_MODEL_c476f685cce5427fad04031a3a7a50a9","IPY_MODEL_3d6ad534f39345168d431d20cdec42ce"],"layout":"IPY_MODEL_9b6a3441bd2f482b90aae4212a027cb2"}},"549e530bd96e4f3e9b43021604869c55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cd10a8c1f9f416a83f68ea558d9f261","placeholder":"​","style":"IPY_MODEL_7e413fc532da4128b7c495d1ad1f0c97","value":"Predicting DataLoader 0: 100%"}},"c476f685cce5427fad04031a3a7a50a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a9088aef78a4e9db4264b3020366221","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68bbe0377884475ab9da7e68bcee441d","value":1}},"3d6ad534f39345168d431d20cdec42ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b91e3438379644bd999614640f9daa38","placeholder":"​","style":"IPY_MODEL_c3155d5d3c784748be13ada3d2a129b9","value":" 1/1 [00:01&lt;00:00,  1.35s/it]"}},"9b6a3441bd2f482b90aae4212a027cb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"9cd10a8c1f9f416a83f68ea558d9f261":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e413fc532da4128b7c495d1ad1f0c97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a9088aef78a4e9db4264b3020366221":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68bbe0377884475ab9da7e68bcee441d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b91e3438379644bd999614640f9daa38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3155d5d3c784748be13ada3d2a129b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9f3599303f54c46a8321aec97f7b502":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ab6595849db4788b45b3851f4c4cc1d","IPY_MODEL_9c2c531dc9334f949b249951ff41daab","IPY_MODEL_1f19efa89a6b4c37aef37db937a399b4"],"layout":"IPY_MODEL_2b22ac33f6c440628d352c9b42bb2c91"}},"6ab6595849db4788b45b3851f4c4cc1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dfeb686bf594d7daee05397ea62f3bf","placeholder":"​","style":"IPY_MODEL_9dc2ce187b204a9fb2f5c1a78fbc7a48","value":"Predicting DataLoader 0: 100%"}},"9c2c531dc9334f949b249951ff41daab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e8d7df0617c4d7ea79ddd8697b044d9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24a33a8e9acb4a29992984c79cbaa6ac","value":1}},"1f19efa89a6b4c37aef37db937a399b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b68ee0105df046f2b28ffc0c39072bb2","placeholder":"​","style":"IPY_MODEL_fdda1574a76f40daa05759f7e114a545","value":" 1/1 [00:01&lt;00:00,  1.76s/it]"}},"2b22ac33f6c440628d352c9b42bb2c91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"8dfeb686bf594d7daee05397ea62f3bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dc2ce187b204a9fb2f5c1a78fbc7a48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e8d7df0617c4d7ea79ddd8697b044d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24a33a8e9acb4a29992984c79cbaa6ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b68ee0105df046f2b28ffc0c39072bb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdda1574a76f40daa05759f7e114a545":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"158e7c8914594e91b62c6be28c03a923":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d54d44850b647af87bb037609b64ac4","IPY_MODEL_e4f23b4d67c84c7697578cb47f83eafb","IPY_MODEL_9d0ad204020342bca6c22847d92212e2"],"layout":"IPY_MODEL_5e16cfdde9224db5a20a10fdfa08edbe"}},"4d54d44850b647af87bb037609b64ac4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82a77a060f634cb98ade476ae3779bc6","placeholder":"​","style":"IPY_MODEL_e2591cfad3e04e66a922338ce4393c34","value":"Predicting DataLoader 0: 100%"}},"e4f23b4d67c84c7697578cb47f83eafb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b762a3d21d35487ab11b197b366f9775","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e5c95d031df499eaf35773a2df85e54","value":1}},"9d0ad204020342bca6c22847d92212e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28f1a3c451654f89b0bf51ef4090082a","placeholder":"​","style":"IPY_MODEL_fe4e3798c4164faba7320b22447dc347","value":" 1/1 [00:01&lt;00:00,  1.78s/it]"}},"5e16cfdde9224db5a20a10fdfa08edbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"82a77a060f634cb98ade476ae3779bc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2591cfad3e04e66a922338ce4393c34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b762a3d21d35487ab11b197b366f9775":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e5c95d031df499eaf35773a2df85e54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28f1a3c451654f89b0bf51ef4090082a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe4e3798c4164faba7320b22447dc347":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b42863368cff407a9543d4cc3e917503":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14f9e928d82d4bc5be73a4f3cbf8d5eb","IPY_MODEL_adf068867c874eef980e49381df15b33","IPY_MODEL_36062e5d409a45489ce12cc25c3c34c6"],"layout":"IPY_MODEL_439c330ea8a4437381ac3de6e1307701"}},"14f9e928d82d4bc5be73a4f3cbf8d5eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_781ddcbaf06e457b83a66d1b08bb79d3","placeholder":"​","style":"IPY_MODEL_5a8561a4d8a84958901f296fbe55c0aa","value":"Predicting DataLoader 0: 100%"}},"adf068867c874eef980e49381df15b33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_011036d94f814f3e808f4dea6a7aa1aa","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e4c87b999824bb3ae0ed131bbebd490","value":1}},"36062e5d409a45489ce12cc25c3c34c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8b5e531ca6142cea0fe4f7f1340932a","placeholder":"​","style":"IPY_MODEL_c673edceaf2f4d4cab0d65a595ea6cc4","value":" 1/1 [00:01&lt;00:00,  1.77s/it]"}},"439c330ea8a4437381ac3de6e1307701":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"781ddcbaf06e457b83a66d1b08bb79d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a8561a4d8a84958901f296fbe55c0aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"011036d94f814f3e808f4dea6a7aa1aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e4c87b999824bb3ae0ed131bbebd490":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8b5e531ca6142cea0fe4f7f1340932a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c673edceaf2f4d4cab0d65a595ea6cc4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}