{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3rOHeiHoOKPe"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78XXjkCdOOzD"},"outputs":[],"source":["!pip install -q pytorch-lightning wandb torchmetrics transformers sentencepiece\n","!pip install -q --upgrade --force-reinstall --no-deps kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQmGCwMMOREH"},"outputs":[],"source":["!mkdir /root/.kaggle\n","!cp /content/drive/MyDrive/Colab/kaggle/kaggle.json /root/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yg3vCpmCcpvn"},"outputs":[],"source":["# import deberta-v2-v3-fast-tokenizer\n","import shutil\n","from pathlib import Path\n","\n","transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n","input_dir = Path(\"/content/drive/MyDrive/Colab/kaggle/nbme-score-clinical-patient-notes/input/deberta-v2-v3-fast-tokenizer\")\n","\n","convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","conversion_path = transformers_path/convert_file.name\n","\n","if conversion_path.exists():\n","    conversion_path.unlink()\n","\n","shutil.copy(convert_file, transformers_path)\n","deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n","    filepath = deberta_v2_path/filename\n","    \n","    if filepath.exists():\n","        filepath.unlink()\n","\n","    shutil.copy(input_dir/filename, filepath)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9443,"status":"ok","timestamp":1649931521842,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"tFUGUD38OVhD","outputId":"60149d88-ec57-4331-904a-7d7e6375f2ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["import os\n","import gc\n","import sys\n","import json\n","import itertools\n","from tqdm.auto import tqdm\n","import logging\n","import datetime\n","import ast\n","import numpy as np\n","import pandas as pd\n","import sklearn.model_selection as sms\n","from sklearn.metrics import f1_score\n","import math\n","import re\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning import Trainer, seed_everything\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n","from pytorch_lightning.loggers import WandbLogger\n","\n","from transformers import AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n","\n","import wandb\n","\n","%env TOKENIZERS_PARALLELISM=true"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1649931634152,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"1duE-kW_OZZq"},"outputs":[],"source":["class ConfigExp018:\n","    # ==============================\n","    # Globals #\n","    # ==============================\n","    competition_name = \"nbme-score-clinical-patient-notes\"\n","    group = \"DeBERTa-v3-large\"\n","    exp_id = \"018\"\n","    debug = False\n","    inference_only = True\n","    upload_from_colab = False\n","    colab_dir = \"/content/drive/MyDrive/Colab/kaggle/nbme-score-clinical-patient-notes\"\n","    kaggle_json_path = \"/root/.kaggle/kaggle.json\"\n","    kaggle_dataset_path = None\n","    gpus = 1\n","    seed = 2434\n","    max_epochs = 5\n","    accumulate_grad_batches = 4\n","    precision = 32\n","    num_fold = 5\n","    train_fold = [0,1,2,3,4] # 実行するfold\n","    pred_threshold = {\n","        0: 0.52,\n","        1: 0.52,\n","        2: 0.52,\n","        3: 0.52,\n","        4: 0.52,\n","        5: 0.52,\n","        6: 0.52,\n","        7: 0.52,\n","        8: 0.52,\n","        9: 0.52,\n","        # best_th: 0.52\n","    }\n","    use_pseudo_train = True\n","    # ==============================\n","    # Dataloader #\n","    # ==============================\n","    train_batch_size = 2\n","    valid_batch_size = 32\n","    test_batch_size = 32\n","    num_workers = 8\n","    # ==============================\n","    # Split #\n","    # ==============================\n","    split_name = \"StratifiedGroupKFold\"\n","    split_params = {\n","        \"n_splits\": num_fold if not debug else 4,\n","        \"shuffle\": True,\n","        \"random_state\": seed,\n","    }\n","    # ==============================\n","    # Model #\n","    # ==============================\n","    model_name = \"microsoft/deberta-v3-large\"\n","    max_length = 512\n","    hidden_size = 1024\n","    num_class = 1\n","    use_backbone_dropout = True\n","    dropout = 0.2\n","    initializer_range = 0.02\n","    lstm_params = {\n","        \"num_layers\": 1,\n","        \"batch_first\": True,\n","        \"bidirectional\": True,\n","        \"dropout\": 0.2,\n","    }\n","    # ==============================\n","    # Loss #\n","    # ==============================\n","    loss_name = \"BCEWithLogitsLoss\"\n","    loss_params = {\n","        \"reduction\": \"none\"\n","    }\n","    # ==============================\n","    # Optimizer #\n","    # ==============================\n","    optimizer_name = \"AdamW\"\n","    optimizer_params = {\n","        \"lr\": 2e-5,\n","        \"weight_decay\": 1e-2,\n","        \"eps\": 1e-6,\n","        \"betas\": (0.9, 0.999)\n","    }\n","    encoder_lr = 2e-5\n","    decoder_lr = 2e-5\n","    weight_decay = 0.01\n","    # ==============================\n","    # Scheduler #\n","    # ==============================\n","    scheduler_name = \"cosine-warmup\"\n","    scheduler_warmup_ratio = 0.1\n","    scheduler_params = {}\n","    scheduler_interval = \"step\"\n","    scheduler_cycle = \"one-cycle\" # epoch or one-cycle\n","    # ==============================\n","    # Callbacks #\n","    # ==============================\n","    checkpoint_params = {\n","        \"monitor\": \"val/micro-F1\",\n","        \"save_top_k\": 1,\n","        \"save_weights_only\": True,\n","        \"mode\": \"max\",\n","        \"verbose\": True,\n","    }\n","    early_stopping = False\n","    early_stopping_params = {\n","        \"monitor\": \"val/loss\",\n","        \"min_delta\": 0.0,\n","        \"patience\": 8,\n","        \"verbose\": False,\n","        \"mode\": \"min\",\n","    }\n","\n","\n","class ConfigExp020:\n","    # ==============================\n","    # Globals #\n","    # ==============================\n","    competition_name = \"nbme-score-clinical-patient-notes\"\n","    group = \"RoBERTa-large\"\n","    exp_id = \"020\"\n","    debug = False\n","    inference_only = True\n","    upload_from_colab = False\n","    colab_dir = \"/content/drive/MyDrive/Colab/kaggle/nbme-score-clinical-patient-notes\"\n","    kaggle_json_path = \"/root/.kaggle/kaggle.json\"\n","    kaggle_dataset_path = None\n","    gpus = 1\n","    seed = 2434\n","    max_epochs = 5\n","    accumulate_grad_batches = 4\n","    precision = 32\n","    num_fold = 5\n","    train_fold = [0,1,2,3,4] # 実行するfold\n","    pred_threshold = {\n","        0: 0.53,\n","        1: 0.53,\n","        2: 0.53,\n","        3: 0.53,\n","        4: 0.53,\n","        5: 0.53,\n","        6: 0.53,\n","        7: 0.53,\n","        8: 0.53,\n","        9: 0.53,\n","        # best_th: 0.53\n","    }\n","    use_pseudo_train = True\n","    # ==============================\n","    # Dataloader #\n","    # ==============================\n","    train_batch_size = 2\n","    valid_batch_size = 32\n","    test_batch_size = 32\n","    num_workers = 8\n","    # ==============================\n","    # Split #\n","    # ==============================\n","    split_name = \"StratifiedGroupKFold\"\n","    split_params = {\n","        \"n_splits\": num_fold if not debug else 4,\n","        \"shuffle\": True,\n","        \"random_state\": seed,\n","    }\n","    # ==============================\n","    # Model #\n","    # ==============================\n","    model_name = \"roberta-large\"\n","    max_length = 512\n","    hidden_size = 1024\n","    num_class = 1\n","    use_backbone_dropout = True\n","    dropout = 0.2\n","    initializer_range = 0.02\n","    lstm_params = {\n","        \"num_layers\": 1,\n","        \"batch_first\": True,\n","        \"bidirectional\": True,\n","        \"dropout\": 0.2,\n","    }\n","    # ==============================\n","    # Loss #\n","    # ==============================\n","    loss_name = \"BCEWithLogitsLoss\"\n","    loss_params = {\n","        \"reduction\": \"none\"\n","    }\n","    # ==============================\n","    # Optimizer #\n","    # ==============================\n","    optimizer_name = \"AdamW\"\n","    optimizer_params = {\n","        \"lr\": 2e-5,\n","        \"weight_decay\": 1e-2,\n","        \"eps\": 1e-6,\n","        \"betas\": (0.9, 0.999)\n","    }\n","    encoder_lr = 2e-5\n","    decoder_lr = 2e-5\n","    weight_decay = 0.01\n","    # ==============================\n","    # Scheduler #\n","    # ==============================\n","    scheduler_name = \"cosine-warmup\"\n","    scheduler_warmup_ratio = 0.1\n","    scheduler_params = {}\n","    scheduler_interval = \"step\"\n","    scheduler_cycle = \"one-cycle\" # epoch or one-cycle\n","    # ==============================\n","    # Callbacks #\n","    # ==============================\n","    checkpoint_params = {\n","        \"monitor\": \"val/micro-F1\",\n","        \"save_top_k\": 1,\n","        \"save_weights_only\": True,\n","        \"mode\": \"max\",\n","        \"verbose\": True,\n","    }\n","    early_stopping = False\n","    early_stopping_params = {\n","        \"monitor\": \"val/loss\",\n","        \"min_delta\": 0.0,\n","        \"patience\": 8,\n","        \"verbose\": False,\n","        \"mode\": \"min\",\n","    }"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7677,"status":"ok","timestamp":1649931634151,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"sokiSfvKSjft"},"outputs":[],"source":["# ====================================\n","# Setup #\n","# ====================================\n","class Logger:\n","    \"\"\" ref) https://github.com/ghmagazine/kagglebook/blob/master/ch04-model-interface/code/util.py\"\"\"\n","    def __init__(self, path):\n","        self.general_logger = logging.getLogger(path)\n","        stream_handler = logging.StreamHandler()\n","        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n","        if len(self.general_logger.handlers) == 0:\n","            self.general_logger.addHandler(stream_handler)\n","            self.general_logger.addHandler(file_general_handler)\n","            self.general_logger.setLevel(logging.INFO)\n","\n","    def info(self, message):\n","        # display time\n","        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n","\n","    @staticmethod\n","    def now_string():\n","        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n","\n","\n","def setup(cfg):\n","    cfg.on_colab = \"google.colab\" in sys.modules\n","    if cfg.on_colab:\n","        # kaggle api\n","        f = open(cfg.kaggle_json_path, 'r')\n","        json_data = json.load(f)\n","        os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n","        # set input/output dir\n","        cfg.input_dir = os.path.join(cfg.colab_dir, \"input\")\n","        cfg.train_csv = os.path.join(cfg.input_dir, \"cleaned_train.csv\")\n","        cfg.external_train_csv = os.path.join(cfg.input_dir, \"external_exact_match_train.csv\")\n","        cfg.features_csv = os.path.join(cfg.input_dir, \"features.csv\")\n","        cfg.patient_notes_csv = os.path.join(cfg.input_dir, \"patient_notes.csv\")\n","        cfg.test_csv = os.path.join(cfg.input_dir, \"test.csv\")\n","        cfg.sample_submission = os.path.join(cfg.input_dir, \"sample_submission.csv\")\n","        cfg.output_dir = os.path.join(cfg.colab_dir, \"output\")\n","        cfg.exp_output_dir = os.path.join(cfg.output_dir, f\"exp{cfg.exp_id}\")\n","        cfg.model_dir = os.path.join(cfg.exp_output_dir, \"model\")\n","\n","        for d in [cfg.output_dir, cfg.exp_output_dir, cfg.model_dir]:\n","            os.makedirs(d, exist_ok=True)\n","            \n","        # wandb\n","        wandb.login()\n","    else:\n","        cfg.input_dir = f\"../input/{cfg.competition_name}\"\n","        cfg.train_csv = os.path.join(cfg.input_dir, \"train.csv\")\n","        cfg.features_csv = os.path.join(cfg.input_dir, \"features.csv\")\n","        cfg.patient_notes_csv = os.path.join(cfg.input_dir, \"patient_notes.csv\")\n","        cfg.test_csv = os.path.join(cfg.input_dir, \"test.csv\")\n","        cfg.sample_submission = os.path.join(cfg.input_dir, \"sample_submission.csv\")\n","        cfg.submission = \"./\"\n","        cfg.exp_output_dir = f\"exp{cfg.exp_id}\"\n","        cfg.model_dir = os.path.join(cfg.exp_output_dir, \"model\")\n","\n","        if cfg.kaggle_dataset_path is not None:\n","            cfg.model_dir = os.path.join(cfg.kaggle_dataset_path, \"model\")\n","\n","        for d in [cfg.exp_output_dir, cfg.model_dir]:\n","            os.makedirs(d, exist_ok=True)\n","\n","    return cfg\n","\n","\n","# ====================================\n","# Preprocess #\n","# ====================================\n","def get_input_data(cfg, input_type=\"train\"):\n","    input_df = pd.read_csv(cfg.train_csv) if input_type == \"train\" else pd.read_csv(cfg.test_csv)\n","    if cfg.debug and input_type != \"test\":\n","        input_df = input_df[input_df[\"pn_num\"].isin(input_df[\"pn_num\"].unique()[:100])].reset_index(drop=True)\n","    \n","    feature_texts_df = pd.read_csv(cfg.features_csv)\n","    patient_notes_df = pd.read_csv(cfg.patient_notes_csv)\n","\n","    if input_type == \"train\":\n","        # external_df = pd.read_csv(cfg.external_train_csv)\n","        # external_df = external_df.sample(14300 * 4, random_state=2434)\n","        # input_df = pd.concat([input_df, external_df], axis=0).reset_index(drop=True)\n","        input_df[\"annotation\"] = input_df[\"annotation\"].apply(ast.literal_eval)\n","        input_df[\"location\"] = input_df[\"location\"].apply(ast.literal_eval)\n","    \n","    input_df = input_df.merge(feature_texts_df, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","    input_df = input_df.merge(patient_notes_df, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","    input_df[\"pn_history\"] = input_df[\"pn_history\"].apply(clean_feature_text_for_preprocess)\n","\n","    return input_df\n","\n","\n","def get_and_merge_external_data(cfg, train_df: pd.DataFrame, fold: int):\n","    input_df = pd.read_csv(os.path.join(cfg.input_dir, f\"external_train_fold_{fold}.csv\"))\n","    input_df = input_df.sample(10000, random_state=2434)\n","    input_df[\"annotation\"] = input_df[\"annotation\"].apply(ast.literal_eval)\n","    input_df[\"location\"] = input_df[\"location\"].apply(ast.literal_eval)\n","    input_df[\"pn_history\"] = input_df[\"pn_history\"].apply(clean_feature_text_for_preprocess)\n","\n","    train_df = pd.concat([train_df, input_df], axis=0).reset_index(drop=True)\n","\n","    return train_df\n","\n","\n","def get_split(cfg, train_df):\n","    split_name = cfg.split_name\n","    split_params = cfg.split_params\n","    splitter = sms.__getattribute__(split_name)(**split_params)\n","\n","    groups = train_df[\"pn_num\"].to_numpy()\n","    train_df[\"fold\"] = -1\n","\n","    for fold_id, (train_idx, valid_idx) in enumerate(splitter.split(train_df, train_df[\"case_num\"], groups)):\n","        train_df.loc[valid_idx, \"fold\"] = int(fold_id)\n","\n","    return train_df\n","\n","\n","def get_filname_listdir(dirctory):\n","    listdir = os.listdir(dirctory)\n","    out_lst = [os.path.splitext(d)[0] for d in listdir]\n","    return out_lst\n","\n","\n","def get_tokenizer(cfg):\n","    if cfg.kaggle_dataset_path is not None:\n","        pretrained_dir = os.path.join(cfg.kaggle_dataset_path, \"pretrain_tokenizer\")\n","    else:\n","        pretrained_dir = os.path.join(cfg.exp_output_dir, \"pretrain_tokenizer\")\n","\n","    if not os.path.isdir(pretrained_dir):\n","        # deberta-v2 or deberta-v3\n","        if (\"deberta-v2\" in cfg.model_name) or (\"deberta-v3\" in cfg.model_name):\n","            tokenizer = DebertaV2TokenizerFast.from_pretrained(cfg.model_name)\n","        # except for (\"roberta\", \"deberta-v2\", \"deberta-v3\")\n","        elif \"roberta\" not in cfg.model_name:\n","            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n","        # roberta\n","        else:\n","            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name, trim_offsets=False)\n","\n","        tokenizer.save_pretrained(pretrained_dir)\n","\n","    else:\n","        # deberta-v2 or deberta-v3\n","        if (\"deberta-v2\" in cfg.model_name) or (\"deberta-v3\" in cfg.model_name):\n","            tokenizer = DebertaV2TokenizerFast.from_pretrained(pretrained_dir)\n","        # except for (\"roberta\", \"deberta-v2\", \"deberta-v3\")\n","        elif \"roberta\" not in cfg.model_name:\n","            tokenizer = AutoTokenizer.from_pretrained(pretrained_dir)\n","        # roberta\n","        else:\n","            tokenizer = AutoTokenizer.from_pretrained(pretrained_dir, trim_offsets=False)\n","\n","    return tokenizer\n","\n","\n","def get_backbone(cfg):\n","    if cfg.kaggle_dataset_path is not None:\n","        pretrained_dir = os.path.join(cfg.kaggle_dataset_path, \"pretrain_model\")\n","    else:\n","        pretrained_dir = os.path.join(cfg.exp_output_dir, \"pretrain_model\")\n","\n","    if not os.path.isdir(pretrained_dir):\n","        model_config = AutoConfig.from_pretrained(cfg.model_name)\n","        if not cfg.use_backbone_dropout:\n","            model_config.attention_probs_dropout_prob = 0.0\n","            model_config.hidden_dropout_prob = 0.0\n","        backbone = AutoModel.from_pretrained(cfg.model_name, config=model_config)\n","\n","        backbone.save_pretrained(pretrained_dir)\n","\n","    else:\n","        model_config = AutoConfig.from_pretrained(pretrained_dir)\n","        if not cfg.use_backbone_dropout:\n","            model_config.attention_probs_dropout_prob = 0.0\n","            model_config.hidden_dropout_prob = 0.0\n","        backbone = AutoModel.from_pretrained(pretrained_dir, config=model_config)\n","\n","    return backbone\n","\n","\n","def clean_feature_text_for_preprocess(text: str):\n","    \"\"\"\n","    reference: https://www.kaggle.com/code/theoviel/roberta-strikes-back\n","    \"\"\"\n","    text = re.sub('I-year', '1-year', text)\n","    text = re.sub('-OR-', \" or \", text)\n","    text = re.sub('-', ' ', text)\n","\n","    return text\n","\n","\n","# ====================================\n","# Dataset #\n","# ====================================\n","def get_inputs(cfg, text: str, feature_text: str, tokenizer):\n","    encoding = tokenizer(\n","        text,\n","        feature_text,\n","        max_length=cfg.max_length,\n","        padding=\"max_length\",\n","        return_offsets_mapping=False,\n","        # add_special_tokens=True\n","    )\n","\n","    for k, v in encoding.items():\n","        encoding[k] = torch.tensor(v, dtype=torch.long)\n","\n","    return encoding\n","\n","\n","def get_label(cfg, text: str, locations: list, tokenizer):\n","    encoding = tokenizer(\n","        text,\n","        max_length=cfg.max_length,\n","        padding=\"max_length\",\n","        return_offsets_mapping=True,\n","        # add_special_tokens=True\n","    )\n","    \n","    offset_mapping = encoding[\"offset_mapping\"]\n","    ignore_idx = np.where(np.array(encoding.sequence_ids()) != 0)[0]\n","    label = np.zeros(len(offset_mapping))\n","    label[ignore_idx] = -1\n","\n","    if len(locations) != 0:\n","        for location in locations:\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start_idx = -1\n","                end_idx = -1\n","                start, end = int(loc[0]), int(loc[1])\n","                for idx in range(len(offset_mapping)):\n","                    # DeBERTaのTokenizerは前の空白も含めるため+1する\n","                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                        start_idx = idx - 1\n","                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                        end_idx = idx + 1\n","                if start_idx == -1:\n","                    start_idx = end_idx\n","                if (start_idx != -1) & (end_idx != -1):\n","                    label[start_idx: end_idx] = 1\n","    \n","    return torch.tensor(label, dtype=torch.float)\n","\n","\n","class NBMEDataset(Dataset):\n","    def __init__(self, cfg, input_df: pd.DataFrame, tokenizer, phase: str = \"train\"):\n","        self.cfg = cfg\n","        self.input_df = input_df\n","        self.tokenizer = tokenizer\n","        self.phase = phase\n","        self.pn_histories = self.input_df[\"pn_history\"].to_numpy()\n","        self.feature_texts = self.input_df[\"feature_text\"].to_numpy()\n","        self.locations = self.input_df[\"location\"].to_numpy() if self.phase is \"train\" else None\n","\n","    def __len__(self):\n","        return len(self.input_df)\n","\n","    def __getitem__(self, idx):\n","        if self.phase == \"train\":\n","            inputs = get_inputs(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.feature_texts[idx],\n","                self.tokenizer,\n","            )\n","            label = get_label(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.locations[idx],\n","                self.tokenizer,\n","            )\n","\n","            return {\n","                \"input_ids\": inputs[\"input_ids\"],\n","                \"attention_mask\": inputs[\"attention_mask\"],\n","                \"labels\": label,\n","            }\n","\n","        elif self.phase == \"test\":\n","            inputs = get_inputs(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.feature_texts[idx],\n","                self.tokenizer,\n","            )\n","\n","            return {\n","                \"input_ids\": inputs[\"input_ids\"],\n","                \"attention_mask\": inputs[\"attention_mask\"],\n","            }\n","        else:\n","            raise NotImplementedError\n","\n","\n","class NBMEDataModule(pl.LightningDataModule):\n","    def __init__(self, cfg, tokenizer, train_df: pd.DataFrame = None, valid_df: pd.DataFrame = None, test_df: pd.DataFrame = None):\n","        super(NBMEDataModule, self).__init__()\n","\n","        self.cfg = cfg\n","        self.tokenizer = tokenizer\n","        self.train_df = train_df\n","        self.valid_df = valid_df\n","        self.test_df = test_df\n","\n","    def prepare_data(self):\n","        if self.test_df is None:\n","            self.train_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.train_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"train\"\n","            )\n","            self.val_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.valid_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"train\"\n","            )\n","        else:\n","            self.test_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.test_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"test\"\n","            )\n","\n","    def train_dataloader(self):\n","        return DataLoader(\n","            self.train_dataset,\n","            batch_size=self.cfg.train_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","    \n","    def val_dataloader(self):\n","        return DataLoader(\n","            self.val_dataset,\n","            batch_size=self.cfg.valid_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","\n","    def predict_dataloader(self):\n","        return DataLoader(\n","            self.test_dataset,\n","            batch_size=self.cfg.test_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","\n","\n","# ====================================\n","# Model #\n","# ====================================\n","class NBMEModel(nn.Module):\n","    def __init__(self, cfg):\n","        super(NBMEModel, self).__init__()\n","\n","        self.cfg = cfg\n","        self.backbone = get_backbone(self.cfg)\n","        self.dropout = nn.Dropout(self.cfg.dropout)\n","        self.lstm = nn.LSTM(self.cfg.hidden_size, self.cfg.hidden_size, **self.cfg.lstm_params)\n","        self.classifier = nn.Linear(self.cfg.hidden_size * 2, self.cfg.num_class)\n","        self._init_weights(self.classifier)\n","        self._reinitialize()\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.cfg.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.cfg.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def _reinitialize(self):\n","        \"\"\"\n","        Tensorflow/Keras-like initialization\n","        \"\"\"\n","        for name, p in self.named_parameters():\n","            if 'lstm' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","            elif 'fc' in name:\n","                if 'weight' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'bias' in name:\n","                    p.data.fill_(0)\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask) # (batch_size, seq_len, hidden_size)\n","        x = outputs[0] # extract last_hidden_states\n","        x, _ = self.lstm(x)\n","        x = self.dropout(x)\n","        x = self.classifier(x) # (batch_size, seq_len, num_class)\n","\n","        return x\n","\n","\n","class NBMELightningModule(pl.LightningModule):\n","    def __init__(self, cfg, tokenizer=None, valid_df=None, valid_labels=None):\n","        super(NBMELightningModule, self).__init__()\n","\n","        self.cfg = cfg\n","        self.model = NBMEModel(self.cfg)\n","        self.criterion = get_criterion(self.cfg)\n","        self.tokenizer = tokenizer\n","        self.valid_df = valid_df\n","        self.valid_labels = valid_labels\n","\n","    def setup(self, stage=None):\n","        # calculate training total steps\n","        if stage == \"fit\":\n","            if self.cfg.scheduler_cycle == \"one-cycle\":\n","                self.training_steps = math.ceil(len(self.trainer.datamodule.train_dataloader()) / self.trainer.accumulate_grad_batches) * self.trainer.max_epochs\n","            elif self.cfg.scheduler_cycle == \"epoch\":\n","                self.training_steps = math.ceil(len(self.trainer.datamodule.train_dataloader()) / self.trainer.accumulate_grad_batches) * 1\n","            else:\n","                raise NotImplementedError\n","            self.warmup_steps = int(self.training_steps * self.cfg.scheduler_warmup_ratio) if self.cfg.scheduler_warmup_ratio else None\n","    \n","    def forward(self, input_ids, attention_mask):\n","        return self.model(input_ids, attention_mask)\n","\n","    def training_step(self, batch, batch_idx):\n","        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        mask = (labels.view(-1, 1) != -1)\n","        loss = torch.masked_select(loss, mask).mean()\n","        self.log(\"train/loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        mask = (labels.view(-1, 1) != -1)\n","        loss = torch.masked_select(loss, mask).mean()\n","        self.log(\"val/loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n","\n","        return {\n","            \"loss\": loss,\n","            \"preds\": y_preds.detach()\n","        }\n","\n","    def validation_epoch_end(self, outputs):\n","        preds = torch.cat([output[\"preds\"] for output in outputs]).squeeze().cpu().numpy()\n","        char_preds = get_token_probs_to_char_probs(self.valid_df[\"pn_history\"].to_numpy(), preds, self.tokenizer)\n","        results = get_results(self.cfg, char_preds, th=0.5)\n","        preds = get_predictions(results)\n","        score = get_score(self.valid_labels, preds)\n","        self.log(\"val/micro-F1\", score, logger=True, prog_bar=True)\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n","        input_ids, attention_mask = batch[\"input_ids\"], batch[\"attention_mask\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        y_preds = y_preds.sigmoid()\n","\n","        return y_preds.squeeze()\n","\n","    def configure_optimizers(self):\n","        optimizer_params = get_optimizer_params(self.model, self.cfg.encoder_lr, self.cfg.decoder_lr, self.cfg.weight_decay)\n","        optimizer = get_optimizer(self.cfg, optimizer_params)\n","\n","        if self.cfg.scheduler_name is None:\n","            return [optimizer]\n","        else:\n","            scheduler = get_scheduler(self.cfg, optimizer, num_warmup_steps=self.warmup_steps, num_training_steps=self.training_steps)\n","            scheduler = {\"scheduler\": scheduler, \"interval\": self.cfg.scheduler_interval}\n","\n","            return [optimizer], [scheduler]\n","\n","\n","# ====================================\n","# Criterion, Optimizer, Scheduler #\n","# ====================================\n","def get_criterion(cfg):\n","    loss_name = cfg.loss_name\n","    loss_params = cfg.loss_params\n","\n","    return nn.__getattribute__(loss_name)(**loss_params)\n","\n","\n","def get_optimizer(cfg, parameters):\n","    optimizer_name = cfg.optimizer_name\n","    optimizer_params = cfg.optimizer_params\n","\n","    return optim.__getattribute__(optimizer_name)(parameters, **optimizer_params)\n","\n","\n","def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","    # param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_parameters = [\n","        {'params': [p for n, p in model.backbone.named_parameters() if not any(nd in n for nd in no_decay)],\n","            'lr': encoder_lr, 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.backbone.named_parameters() if any(nd in n for nd in no_decay)],\n","            'lr': encoder_lr, 'weight_decay': 0.0},\n","        {'params': [p for n, p in model.named_parameters() if \"backbone\" not in n],\n","            'lr': decoder_lr, 'weight_decay': 0.0}\n","    ]\n","\n","    return optimizer_parameters\n","\n","\n","def get_scheduler(cfg, optimizer, num_warmup_steps=None, num_training_steps=None):\n","    scheduler_name = cfg.scheduler_name\n","    scheduler_params = cfg.scheduler_params\n","\n","    if scheduler_name == \"cosine-warmup\":\n","        return get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","            **scheduler_params\n","        )\n","    elif scheduler_name == \"linear-warmup\":\n","        return get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","            **scheduler_params\n","        )\n","    else:\n","        return optim.lr_scheduler.__getattribute__(scheduler_name)(optimizer, **scheduler_params)\n","\n","\n","# ====================================\n","# Train & Predict #\n","# ====================================\n","def train_fold(cfg, train_df, valid_df, tokenizer, fold, valid_labels):\n","    # Seed\n","    seed_everything(cfg.seed)\n","\n","    # Wandb\n","    wandb_logger = WandbLogger(\n","        project=cfg.competition_name,\n","        group=cfg.group,\n","        name=f\"exp{cfg.exp_id}-fold-{fold}\",\n","        job_type=f\"exp{cfg.exp_id}\",\n","        reinit=True,\n","        anonymous=\"must\",\n","    )\n","\n","    # Model Checkpoint\n","    checkpoint = ModelCheckpoint(\n","        dirpath=cfg.model_dir,\n","        # filename=f\"exp{cfg.exp_id}-fold-{fold}\" + \"-{epoch}\",\n","        filename=f\"exp{cfg.exp_id}-fold-{fold}\",\n","        **cfg.checkpoint_params,\n","    )\n","\n","    # Learning Rate\n","    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n","    callbacks = [checkpoint, lr_monitor]\n","\n","    # Early Stopping\n","    if cfg.early_stopping:\n","        early_stopping = EarlyStopping(**cfg.early_stopping_params)\n","        callbacks += [early_stopping]\n","    \n","    # DataModule\n","    lightning_datamodule = NBMEDataModule(\n","        cfg=cfg,\n","        tokenizer=tokenizer,\n","        train_df=train_df,\n","        valid_df=valid_df,\n","    )\n","\n","    # Model\n","    lightning_model = NBMELightningModule(\n","        cfg,\n","        tokenizer,\n","        valid_df,\n","        valid_labels,\n","    )\n","\n","    # Trainer\n","    trainer = Trainer(\n","        gpus=cfg.gpus,\n","        max_epochs=cfg.max_epochs,\n","        callbacks=callbacks,\n","        logger=[wandb_logger],\n","        accumulate_grad_batches=cfg.accumulate_grad_batches,\n","        precision=cfg.precision,\n","        # deterministic=True,\n","        benchmark=False,\n","    )\n","\n","    trainer.fit(lightning_model, datamodule=lightning_datamodule)\n","    wandb.finish(quiet=True)\n","\n","    del lightning_datamodule, lightning_model, trainer\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","\n","def train_cv(cfg, input_df, tokenizer):\n","    oof_char_probs = []\n","    true_df = pd.DataFrame()\n","\n","    for fold_id in range(cfg.num_fold):\n","        if fold_id in cfg.train_fold:\n","            filename = f\"exp{cfg.exp_id}-fold-{fold_id}\"\n","            filelist = get_filname_listdir(cfg.model_dir)\n","\n","            train_df = input_df[input_df[\"fold\"] != fold_id].reset_index(drop=True)\n","            if cfg.use_pseudo_train:\n","                train_df = get_and_merge_external_data(cfg, train_df, fold_id) # merge external train\n","            valid_df = input_df[input_df[\"fold\"] == fold_id].reset_index(drop=True)\n","            valid_df[\"labels\"] = create_labels_for_scoring(valid_df)\n","\n","            # training\n","            if not filename in filelist:\n","                train_fold(\n","                    cfg=cfg,\n","                    train_df=train_df,\n","                    valid_df=valid_df,\n","                    tokenizer=tokenizer,\n","                    fold=fold_id,\n","                    valid_labels=valid_df[\"labels\"].to_numpy(),\n","                )\n","\n","            # oof\n","            char_probs = predict(\n","                cfg=cfg,\n","                input_df=valid_df,\n","                tokenizer=tokenizer,\n","                filename=filename,\n","                labels=valid_df[\"labels\"].to_numpy(),\n","            )\n","            # scoring and optimize threshodl for each case\n","            get_score_and_threshold(cfg, char_probs, valid_df, fold_id)\n","            \n","            oof_char_probs += char_probs\n","            true_df = pd.concat([true_df, valid_df], axis=0)\n","\n","    get_score_and_threshold(cfg, oof_char_probs, true_df.reset_index(drop=True), \"cv\")\n","    results = get_results(cfg, oof_char_probs, cases=true_df[\"case_num\"].to_list())\n","    preds = get_predictions(results)\n","    oof_score = get_score(true_df[\"labels\"].to_list(), preds)\n","    cfg.logger.info(f\"optimized case-threshold cv-score: {oof_score}\")\n","\n","\n","def predict_raw_prediction(cfg, input_df, tokenizer, filename, labels=None):\n","    checkpoint_path = os.path.join(cfg.model_dir, filename + \".ckpt\")\n","\n","    lightning_model = NBMELightningModule(\n","        cfg,\n","        tokenizer,\n","        input_df,\n","        labels,\n","    )\n","\n","    lightning_model = lightning_model.load_from_checkpoint(\n","        checkpoint_path=checkpoint_path,\n","        cfg=cfg,\n","    )\n","\n","    lightning_datamodule = NBMEDataModule(\n","        cfg,\n","        tokenizer=tokenizer,\n","        test_df=input_df\n","    )\n","\n","    trainer = Trainer(\n","        gpus=cfg.gpus,\n","    )\n","\n","    preds = trainer.predict(\n","        lightning_model,\n","        datamodule=lightning_datamodule,\n","        return_predictions=True\n","    )\n","\n","    preds = torch.cat(preds).cpu().numpy() # (sample, max_seq, num_class)\n","\n","    del lightning_datamodule, lightning_model, trainer\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    \n","    return preds\n","    \n","\n","def predict(cfg, input_df, tokenizer, filename, labels):\n","    file_path = os.path.join(cfg.exp_output_dir, f\"{filename}.npy\")\n","    \n","    if os.path.isfile(file_path):\n","        preds = np.load(file_path)\n","    else:\n","        preds = predict_raw_prediction(cfg, input_df, tokenizer, filename, labels)\n","        np.save(os.path.join(cfg.exp_output_dir, filename), preds)\n","\n","    char_probs = get_token_probs_to_char_probs(input_df[\"pn_history\"].to_numpy(), preds, tokenizer)\n","\n","    return char_probs\n","\n","\n","def predict_cv(cfg, input_df, tokenizer):\n","    \"\"\"\n","    CVモデルで予測\n","    \"\"\"\n","    fold_preds = []\n","    for fold_id in range(cfg.num_fold):\n","        if fold_id in cfg.train_fold:\n","            filename = f\"exp{cfg.exp_id}-fold-{fold_id}\"\n","            preds = predict_raw_prediction(cfg, input_df, tokenizer, filename)\n","            char_preds = get_token_probs_to_char_probs(input_df[\"pn_history\"].to_numpy(), preds, tokenizer)\n","            fold_preds.append(char_preds)\n","\n","    fold_preds = np.mean(fold_preds, axis=0)\n","    results = get_results(cfg, fold_preds, cases=input_df[\"case_num\"].to_list())\n","\n","    output_df = input_df.copy()\n","    output_df[\"location\"] = results\n","    \n","    return output_df\n","\n","\n","def predict_cv_for_ensamble(cfgs, input_df):\n","    \"\"\"\n","    CVモデルで予測\n","    \"\"\"\n","    fold_preds = []\n","    for cfg in cfgs:\n","        tokenizer = get_tokenizer(cfg)\n","        for fold_id in range(cfg.num_fold):\n","            if fold_id in cfg.train_fold:\n","                filename = f\"exp{cfg.exp_id}-fold-{fold_id}\"\n","                preds = predict_raw_prediction(cfg, input_df, tokenizer, filename)\n","                char_preds = get_token_probs_to_char_probs(input_df[\"pn_history\"].to_numpy(), preds, tokenizer)\n","                fold_preds.append(char_preds)\n","        \n","        del tokenizer\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","    fold_preds = np.mean(fold_preds, axis=0)\n","    results = get_results(cfg, fold_preds, cases=input_df[\"case_num\"].to_list())\n","\n","    output_df = input_df.copy()\n","    output_df[\"location\"] = results\n","    \n","    return output_df\n","\n","\n","def get_token_probs_to_char_probs(texts, predictions, tokenizer):\n","    \"\"\"\n","    予測値をtoken-level -> char-levelに変形\n","    \"\"\"\n","    results = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n","        encoded = tokenizer(\n","            text, \n","            add_special_tokens=True,\n","            return_offsets_mapping=True\n","        )\n","        \n","        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n","            start = offset_mapping[0]\n","            end = offset_mapping[1]\n","\n","            # 先行するスペースがあればスパンから除く\n","            # if text[start] == \" \":\n","            #     start = start + 1\n","            \n","            results[i][start: end] = pred\n","    \n","    return results\n","\n","\n","def get_results(cfg, char_probs, th=0.5, cases=None):\n","    \"\"\"\n","    \";\"区切りのスパンに変換\n","    \"\"\"\n","    results = []\n","    if cases:\n","        for char_prob, case in zip(char_probs, cases):\n","            th = cfg.pred_threshold[case]\n","            result = np.where(char_prob >= th)[0] + 1\n","            result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","            result = [f\"{min(r)} {max(r)}\" for r in result]\n","            result = \";\".join(result)\n","            results.append(result)\n","    else:\n","        for char_prob in char_probs:\n","            result = np.where(char_prob >= th)[0] + 1\n","            result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","            result = [f\"{min(r)} {max(r)}\" for r in result]\n","            result = \";\".join(result)\n","            results.append(result)\n","    \n","    return results\n","\n","\n","def get_predictions(results):\n","    \"\"\"\n","    各スパンのリストを要素とするリストに変換\n","    '3 4;7 9;12 13' -> [[3, 4], [7, 9], [12, 13]]\n","    \"\"\"\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(';')]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    \n","    return predictions\n","\n","\n","def create_labels_for_scoring(df):\n","    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n","    df = df.copy()\n","    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, 'location']\n","        if lst:\n","            new_lst = ';'.join(lst)\n","            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n","    # create labels\n","    truths = []\n","    for location_list in df['location_for_create_labels'].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(';')]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","    \n","    return truths\n","\n","\n","# ====================================\n","# Metrics #\n","# ====================================\n","def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    \n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    \n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","\n","    return score\n","\n","\n","def optimize_threshold(cfg, valid_labels, char_probs):\n","    best_thres = 0.5\n","    best_score = 0.0\n","    for th in np.arange(0.40, 0.70, 0.01):\n","        th = np.round(th, 2)\n","        results = get_results(cfg, char_probs, th=th)\n","        preds = get_predictions(results)\n","        score = get_score(valid_labels, preds)\n","\n","        if best_score < score:\n","            best_thres = th\n","            best_score = score\n","\n","    return best_thres, best_score\n","\n","\n","def get_score_and_threshold(cfg, pred_char_probs, valid_df, fold_id):\n","    \"\"\"\n","    case毎 & 全体のスコアリングと閾値の最適化\n","    \"\"\"\n","    class_scores = {}\n","    valid_df = valid_df.copy()\n","    valid_df[\"pred_char_probs\"] = pred_char_probs\n","\n","    for case in valid_df[\"case_num\"].unique():\n","        case_idx = valid_df.query('case_num == @case').index\n","        case_labels = valid_df.iloc[case_idx][\"labels\"].to_list()\n","        case_char_probs = valid_df.iloc[case_idx][\"pred_char_probs\"].to_list()\n","        best_thres, best_score = optimize_threshold(cfg, case_labels, case_char_probs)\n","        if fold_id != \"cv\":\n","            cfg.logger.info(f\"fold {fold_id}: case_num: {case} best_th: {best_thres}  score: {best_score:.5f}\")\n","        else:\n","            cfg.logger.info(f\"case_num: {case} best_th: {best_thres}  score: {best_score:.5f}\")\n","\n","    best_thres, best_score = optimize_threshold(cfg, valid_df[\"labels\"].to_list(), pred_char_probs)\n","    if fold_id != \"cv\":\n","        cfg.logger.info(f\"fold {fold_id}: best_th: {best_thres}  score: {best_score:.5f}\")\n","    else:\n","        cfg.logger.info(f\"best_th: {best_thres}  score: {best_score:.5f}\")\n","\n","\n","# ====================================\n","# Pseudo labeling #\n","# ====================================\n","def get_input_data_for_pseudo_labeling(cfg, nrows: int = None):\n","    train_df = pd.read_csv(cfg.train_csv)\n","    feature_texts_df = pd.read_csv(Config.features_csv)\n","    patient_notes_df = pd.read_csv(Config.patient_notes_csv)\n","\n","    train_pn_idx = list(train_df[\"pn_num\"].unique())\n","    extract_train_df = patient_notes_df[~patient_notes_df[\"pn_num\"].isin(train_pn_idx)].reset_index(drop=True)\n","    extract_train_df = extract_train_df.merge(feature_texts_df, on=[\"case_num\"], how=\"left\")\n","    extract_train_df[\"id\"] = extract_train_df[\"pn_num\"].astype(str).str.zfill(5) + \"_\" + extract_train_df[\"feature_num\"].astype(str).str.zfill(3)\n","    extract_train_df[\"pn_history\"] = extract_train_df[\"pn_history\"].apply(clean_feature_text_for_preprocess)\n","    extract_train_df = extract_train_df.reindex(columns=[\"id\", \"case_num\", \"pn_num\", \"feature_num\", \"feature_text\", \"pn_history\"])\n","\n","    if nrows is not None:\n","        select_idx = extract_train_df.drop_duplicates(subset=\"pn_num\").sample(n=nrows, random_state=2434)[\"pn_num\"].to_list()\n","        extract_train_df = extract_train_df[extract_train_df[\"pn_num\"].isin(select_idx)].reset_index(drop=True)\n","\n","    return extract_train_df\n","\n","\n","def create_external_input(pred_df):\n","    pred_df[\"predict\"] = get_predictions(pred_df[\"location\"].to_list())\n","\n","    all_annotation_texts = []\n","    for history, locations in zip(pred_df[\"pn_history\"].to_numpy(), pred_df[\"predict\"].to_numpy()):\n","        sample_annotation_texts = []\n","        for loc in locations:\n","            start, end = loc[0], loc[1]\n","            annotion_text = history[start: end]\n","            sample_annotation_texts.append(annotion_text)\n","        all_annotation_texts.append(sample_annotation_texts)\n","\n","    pred_df[\"annotation\"] = all_annotation_texts\n","    pred_df[\"location\"] = pred_df[\"location\"].apply(lambda x: x.split(\";\"))\n","\n","    pred_df[\"len_annotation\"] = pred_df[\"annotation\"].apply(len)\n","    pred_df = pred_df[pred_df[\"len_annotation\"] != 0].reset_index(drop=True)\n","\n","    return pred_df.drop(columns=[\"predict\", \"len_annotation\"], axis=1)\n","\n","\n","def predict_for_pseudo_labeling(cfg, input_df, tokenizer):\n","    \"\"\"\n","    pseudo-labeling for each fold model\n","    \"\"\"\n","    for fold_id in range(cfg.num_fold):\n","        if fold_id in cfg.train_fold:\n","            filename = f\"exp{cfg.exp_id}-fold-{fold_id}\"\n","            preds = predict_raw_prediction(cfg, input_df, tokenizer, filename)\n","            char_preds = get_token_probs_to_char_probs(input_df[\"pn_history\"].to_numpy(), preds, tokenizer)\n","            results = get_results(cfg, char_preds, cases=input_df[\"case_num\"].to_list())\n","\n","            output_df = input_df.copy()\n","            output_df[\"location\"] = results\n","\n","            output_df = create_external_input(output_df)\n","            output_df[\"fold\"] = fold_id\n","            output_df.to_csv(os.path.join(cfg.input_dir, f\"external_train_fold_{fold_id}.csv\"), index=False)\n","\n","            del output_df"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a1a5521e627f49858ca31f72c9ae62c0","8215d85918bd464391a371e258b8348e","ac1c9f910dac4eab9832dc826e881dfd","78934c9608d94a98ae5b917267d8ca9d","71ea3697a08a419bb228bfd387d548a4","bfeb2b34383b4033b73ed9ee1747fafe","2ee3d651c6334b72b6bd5481bfd708db","a72ca4d9f75740fba462f035c75b07ae","25f28a34d3d347a8aaf60cc68e4eb321","03d4e022f7d148e7907fd69069a2079e","5b4698b580854a6caad21961ece16ec5","2e4065898af7412bbe151884e3e7b664","03113a9a2c844d63bbd4adbdf6775a9d","8952df63e78a4126a7cb58149f9ca8db","5ed3996a1e0947edb05c5e06a4498b5d","2a1ab5ba67ac4e0eb860ca087b824d95","0e16a47d199a4a8c9141250f0b3c4ca9","cd2ca9f8b7a34ae397375915d4388fae","0d1a2d58b0c04805b305adc9502b1f0b","dc89e6a8c9af4f1e89cec25b905df184","384a33f542c2422fbd6e797dfa1e6e33","4d00031c16114a11890f74754002b6cd","35d53385ee7049c48f7bfb610fac48a7","f15a86497c8b48f39e5ab53cbc7e8842","b5743e7053a34b16b624cd13b80cde16","66bc2a3a5d594b57832dda0069fa7c4e","a5bd7c44b5b0462dbf3f53b9b2474591","461e35f3fd284475b054bbab944c0c32","93cfbbe80b9d4edda45355a5b9660522","2c683f497e104f8583bf0437a5a8a2c3","872863507066448398424fd9f9128530","664c5c9e25b844868a0090bcf4b33c45","77e12826ef8e436dbe45cb773a8add00","08510e1f5b554a7fabe7b0ade3b0937e","8e27d8d0db654bc0b16c4fd1fd3b2719","bdf452e0d1a34ad1989f0cf61cf59474","4b3c567808de49519442e7647106e91c","87319e0ba96e4fc0864552b7b56cdc38","6958c46b97e94795a4bfd320a1db8be2","51dc6ed1b54347e3acbc51e82f219166","2925d0d9345f48d396f9889ff780d200","08687119bfdf4187a797d954d7be3391","e32b0e2b00954d969976acfdfb9ca5e1","11014c6f419449c2b0267bf342f59750","2616bb68b8e34c629be3b8641f9c24f0","22b13fa959a1441babdc26a37aad9ef7","414ce57b48ff4c8ab362bdca9f89c86b","e7c30f15a1da493da3664ad28889380d","5fd532821cf64ff49abe85954b289143","4215f9e5d39f47a2b8178fd0e7d93f1d","dfb2faf0174b48c7aff9e03230d6fdef","023ade810e6747fe9d7013d758aa0fa7","6dc1070a7a224335b370e36471466851","b913f1cca66448ec8046e589c71ac9de","4896dca354aa45248f1e4599185b0be3","0a37066028a248faa97636a773ba895c","9455e7ba91fc4f62aa2bf8e9559afd6f","0491d55ec3a349669026429daa1b8ce9","c251965b7e254186afef69b421de3d00","288b1fb72672434b80a76fb8f6941f45","75ab82f8289742daa1637f2e18fc92b0","3f68734b85cc4f29aa76783c2b4bbd34","51e26132e8ca4587923e90446bf9fb6f","645a15c7ddb6471d8ad7ba912d89e880","2f3a0b213b174dadb445b2a4f66a5bad","8a7578fe89824adba3bdfca249b67320","993a0d29225c49b8b8d3d8e8d983550a","f9aedf9a3da3411693d75e65ea4262d6","ced228d60cfa4afb988eea538601ff09","10a33fecb23a40c19ab179779cb327cd","3e64eb21b6ee4c4d87649b33b1140ac3","7e5e2fa43fbd46d7ae07f04d61320d7c","7f9cdbc8394a436b90710ca5234aa8d1","571418996c004460a501c3ae39602056","f2e5be9caee4492ea9cc20c39cd9ed59","3dbab1500bc54524ae1c15e4f3818011","1b8f187149244c258b83009c59a3db8c","a57357960b554c408564b5d059e8e0b3","d2f94bd5bcca4067ac3d3f54fe57e979","ca8ea1f223884ca3a275923da0c6d55d","b6717abac7df48108a4f751ef4219347","a71af7236f8842d39c46115eba842f04","4faf45b197c64bc1bf55d4d6d53abf2f","eaab0377fd694e069dad9d7ef13ebe8f","0114c18a6b0c4f2997bb483c3d8ba03a","cf22ac5e01224f578e49b1f380cfae88","6896acac08fa4e0dad202fb6e88b900a","cbe6edb604d9415793e3d7c816138074","c07c386bdc134a4183b9eb55d9f79a04","0fe766ac0fd543d391d5a133dfbb5186","5c69b7eaa9e047e082b6f5b1a31a7d32","c70584a189c64475bb333bc4ba2451b2","e6896520a74b4cb7a11b97d962df940e","fae96eb6fe3340a0be8f36f50d30de97","497b01d3a81d4c69a25f652f1b030b2f","cee271a42979417286ca18299f00289b","b78dda3255834614b12cac5b971ae0b7","95e47f0888eb469a8943c47bcbdd0914","94f5471b169342508eafe8f1fe350f3f","5d47942a940148d8a8a91556f290116a","0dc7a8ceb48a4582aa070d43a3df2956","8146bd6cad0b4d09a262df3275669e6c","8578b017df5c4e07bc08b56944893921","7c4c7f4a7fac4042a00ebecc20b34445","45f7149a9df04666864a165c8a929c37","0bae89ae66334dd894da82467b109988","e1d12b6f4e984db29bafbd68f7238e82","c013d31e31424143a55507a224a4fcc1","4f9270c802be42f9a20edeb6ac94a15b","2adade2e4c7c43d289d308b9bfe4cd96"]},"id":"rQgD_e_gTYtP","executionInfo":{"status":"ok","timestamp":1649931948700,"user_tz":-540,"elapsed":290482,"user":{"displayName":"永友遥","userId":"11743586908271963047"}},"outputId":"e9b5d052-f2e0-468c-a323-4186543bfbd4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n","  category=PossibleUserWarning,\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","Missing logger folder: /content/lightning_logs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1a5521e627f49858ca31f72c9ae62c0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e4065898af7412bbe151884e3e7b664"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35d53385ee7049c48f7bfb610fac48a7"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08510e1f5b554a7fabe7b0ade3b0937e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2616bb68b8e34c629be3b8641f9c24f0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a37066028a248faa97636a773ba895c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"993a0d29225c49b8b8d3d8e8d983550a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a57357960b554c408564b5d059e8e0b3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c07c386bdc134a4183b9eb55d9f79a04"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d47942a940148d8a8a91556f290116a"}},"metadata":{}}],"source":["def main():\n","    # setup\n","    cfg1 = ConfigExp018()\n","    cfg2 = ConfigExp020()\n","    cfg1 = setup(cfg1)\n","    cfg2 = setup(cfg2)\n","    cfg1.logger = Logger(cfg1.exp_output_dir)\n","    # load dataset\n","    # train_df = get_input_data(Config, input_type=\"train\")\n","    test_df = get_input_data(cfg1, input_type=\"test\")\n","    submission_df = pd.read_csv(cfg1.sample_submission)\n","    # extract_train_df = get_input_data_for_pseudo_labeling(Config, nrows=5000)\n","\n","    # split\n","    # train_df = get_split(Config, train_df)\n","\n","    # tokenizer\n","    # tokenizer = get_tokenizer(Config)\n","\n","    # if not Config.inference_only:\n","    #     # training\n","    #     train_cv(\n","    #         cfg=Config,\n","    #         input_df=train_df,\n","    #         tokenizer=tokenizer,\n","    #     )\n","\n","    # predict\n","    raw_pred_df = predict_cv_for_ensamble(\n","        cfgs=[cfg1, cfg2],\n","        input_df=test_df,\n","    )\n","\n","    # pseudo-labeling\n","    # predict_for_pseudo_labeling(cfg=Config, input_df=extract_train_df, tokenizer=tokenizer)\n","\n","    # upload output to kaggle dataset\n","    # if Config.upload_from_colab:\n","    #     from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","    #     def dataset_create_new(dataset_name, upload_dir):\n","    #         dataset_metadata = {}\n","    #         dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    #         dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    #         dataset_metadata['title'] = dataset_name\n","    #         with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","    #             json.dump(dataset_metadata, f, indent=4)\n","    #         api = KaggleApi()\n","    #         api.authenticate()\n","    #         api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n","\n","    #     dataset_create_new(dataset_name=f\"{Config.competition_name}-exp{Config.exp_id}\", upload_dir=Config.exp_output_dir)\n","\n","    # make submission\n","    if not cfg1.on_colab:\n","        raw_pred_df[[\"id\", \"location\"]].to_csv(os.path.join(cfg1.submission, \"submission.csv\"), index=False)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGttOH6cYL6d","executionInfo":{"status":"aborted","timestamp":1649931529227,"user_tz":-540,"elapsed":4,"user":{"displayName":"永友遥","userId":"11743586908271963047"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"exp022.ipynb","provenance":[],"mount_file_id":"1r-f7AXb37o0hYWXBWhrkB6fPKKdyzobQ","authorship_tag":"ABX9TyPcjw1Bdgu7rpfdbc43o2YU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a1a5521e627f49858ca31f72c9ae62c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8215d85918bd464391a371e258b8348e","IPY_MODEL_ac1c9f910dac4eab9832dc826e881dfd","IPY_MODEL_78934c9608d94a98ae5b917267d8ca9d"],"layout":"IPY_MODEL_71ea3697a08a419bb228bfd387d548a4"}},"8215d85918bd464391a371e258b8348e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfeb2b34383b4033b73ed9ee1747fafe","placeholder":"​","style":"IPY_MODEL_2ee3d651c6334b72b6bd5481bfd708db","value":"Predicting DataLoader 0: 100%"}},"ac1c9f910dac4eab9832dc826e881dfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a72ca4d9f75740fba462f035c75b07ae","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25f28a34d3d347a8aaf60cc68e4eb321","value":1}},"78934c9608d94a98ae5b917267d8ca9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03d4e022f7d148e7907fd69069a2079e","placeholder":"​","style":"IPY_MODEL_5b4698b580854a6caad21961ece16ec5","value":" 1/1 [00:01&lt;00:00,  1.12s/it]"}},"71ea3697a08a419bb228bfd387d548a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"bfeb2b34383b4033b73ed9ee1747fafe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ee3d651c6334b72b6bd5481bfd708db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a72ca4d9f75740fba462f035c75b07ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25f28a34d3d347a8aaf60cc68e4eb321":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03d4e022f7d148e7907fd69069a2079e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b4698b580854a6caad21961ece16ec5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e4065898af7412bbe151884e3e7b664":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03113a9a2c844d63bbd4adbdf6775a9d","IPY_MODEL_8952df63e78a4126a7cb58149f9ca8db","IPY_MODEL_5ed3996a1e0947edb05c5e06a4498b5d"],"layout":"IPY_MODEL_2a1ab5ba67ac4e0eb860ca087b824d95"}},"03113a9a2c844d63bbd4adbdf6775a9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e16a47d199a4a8c9141250f0b3c4ca9","placeholder":"​","style":"IPY_MODEL_cd2ca9f8b7a34ae397375915d4388fae","value":"Predicting DataLoader 0: 100%"}},"8952df63e78a4126a7cb58149f9ca8db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d1a2d58b0c04805b305adc9502b1f0b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc89e6a8c9af4f1e89cec25b905df184","value":1}},"5ed3996a1e0947edb05c5e06a4498b5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_384a33f542c2422fbd6e797dfa1e6e33","placeholder":"​","style":"IPY_MODEL_4d00031c16114a11890f74754002b6cd","value":" 1/1 [00:02&lt;00:00,  2.07s/it]"}},"2a1ab5ba67ac4e0eb860ca087b824d95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"0e16a47d199a4a8c9141250f0b3c4ca9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd2ca9f8b7a34ae397375915d4388fae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d1a2d58b0c04805b305adc9502b1f0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc89e6a8c9af4f1e89cec25b905df184":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"384a33f542c2422fbd6e797dfa1e6e33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d00031c16114a11890f74754002b6cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35d53385ee7049c48f7bfb610fac48a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f15a86497c8b48f39e5ab53cbc7e8842","IPY_MODEL_b5743e7053a34b16b624cd13b80cde16","IPY_MODEL_66bc2a3a5d594b57832dda0069fa7c4e"],"layout":"IPY_MODEL_a5bd7c44b5b0462dbf3f53b9b2474591"}},"f15a86497c8b48f39e5ab53cbc7e8842":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_461e35f3fd284475b054bbab944c0c32","placeholder":"​","style":"IPY_MODEL_93cfbbe80b9d4edda45355a5b9660522","value":"Predicting DataLoader 0: 100%"}},"b5743e7053a34b16b624cd13b80cde16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c683f497e104f8583bf0437a5a8a2c3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_872863507066448398424fd9f9128530","value":1}},"66bc2a3a5d594b57832dda0069fa7c4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_664c5c9e25b844868a0090bcf4b33c45","placeholder":"​","style":"IPY_MODEL_77e12826ef8e436dbe45cb773a8add00","value":" 1/1 [00:01&lt;00:00,  1.64s/it]"}},"a5bd7c44b5b0462dbf3f53b9b2474591":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"461e35f3fd284475b054bbab944c0c32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93cfbbe80b9d4edda45355a5b9660522":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c683f497e104f8583bf0437a5a8a2c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"872863507066448398424fd9f9128530":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"664c5c9e25b844868a0090bcf4b33c45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77e12826ef8e436dbe45cb773a8add00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08510e1f5b554a7fabe7b0ade3b0937e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e27d8d0db654bc0b16c4fd1fd3b2719","IPY_MODEL_bdf452e0d1a34ad1989f0cf61cf59474","IPY_MODEL_4b3c567808de49519442e7647106e91c"],"layout":"IPY_MODEL_87319e0ba96e4fc0864552b7b56cdc38"}},"8e27d8d0db654bc0b16c4fd1fd3b2719":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6958c46b97e94795a4bfd320a1db8be2","placeholder":"​","style":"IPY_MODEL_51dc6ed1b54347e3acbc51e82f219166","value":"Predicting DataLoader 0: 100%"}},"bdf452e0d1a34ad1989f0cf61cf59474":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2925d0d9345f48d396f9889ff780d200","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08687119bfdf4187a797d954d7be3391","value":1}},"4b3c567808de49519442e7647106e91c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e32b0e2b00954d969976acfdfb9ca5e1","placeholder":"​","style":"IPY_MODEL_11014c6f419449c2b0267bf342f59750","value":" 1/1 [00:02&lt;00:00,  2.05s/it]"}},"87319e0ba96e4fc0864552b7b56cdc38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"6958c46b97e94795a4bfd320a1db8be2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51dc6ed1b54347e3acbc51e82f219166":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2925d0d9345f48d396f9889ff780d200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08687119bfdf4187a797d954d7be3391":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e32b0e2b00954d969976acfdfb9ca5e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11014c6f419449c2b0267bf342f59750":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2616bb68b8e34c629be3b8641f9c24f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22b13fa959a1441babdc26a37aad9ef7","IPY_MODEL_414ce57b48ff4c8ab362bdca9f89c86b","IPY_MODEL_e7c30f15a1da493da3664ad28889380d"],"layout":"IPY_MODEL_5fd532821cf64ff49abe85954b289143"}},"22b13fa959a1441babdc26a37aad9ef7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4215f9e5d39f47a2b8178fd0e7d93f1d","placeholder":"​","style":"IPY_MODEL_dfb2faf0174b48c7aff9e03230d6fdef","value":"Predicting DataLoader 0: 100%"}},"414ce57b48ff4c8ab362bdca9f89c86b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_023ade810e6747fe9d7013d758aa0fa7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6dc1070a7a224335b370e36471466851","value":1}},"e7c30f15a1da493da3664ad28889380d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b913f1cca66448ec8046e589c71ac9de","placeholder":"​","style":"IPY_MODEL_4896dca354aa45248f1e4599185b0be3","value":" 1/1 [00:02&lt;00:00,  2.10s/it]"}},"5fd532821cf64ff49abe85954b289143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"4215f9e5d39f47a2b8178fd0e7d93f1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfb2faf0174b48c7aff9e03230d6fdef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"023ade810e6747fe9d7013d758aa0fa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dc1070a7a224335b370e36471466851":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b913f1cca66448ec8046e589c71ac9de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4896dca354aa45248f1e4599185b0be3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a37066028a248faa97636a773ba895c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9455e7ba91fc4f62aa2bf8e9559afd6f","IPY_MODEL_0491d55ec3a349669026429daa1b8ce9","IPY_MODEL_c251965b7e254186afef69b421de3d00"],"layout":"IPY_MODEL_288b1fb72672434b80a76fb8f6941f45"}},"9455e7ba91fc4f62aa2bf8e9559afd6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75ab82f8289742daa1637f2e18fc92b0","placeholder":"​","style":"IPY_MODEL_3f68734b85cc4f29aa76783c2b4bbd34","value":"Predicting DataLoader 0: 100%"}},"0491d55ec3a349669026429daa1b8ce9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51e26132e8ca4587923e90446bf9fb6f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_645a15c7ddb6471d8ad7ba912d89e880","value":1}},"c251965b7e254186afef69b421de3d00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f3a0b213b174dadb445b2a4f66a5bad","placeholder":"​","style":"IPY_MODEL_8a7578fe89824adba3bdfca249b67320","value":" 1/1 [00:01&lt;00:00,  1.55s/it]"}},"288b1fb72672434b80a76fb8f6941f45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"75ab82f8289742daa1637f2e18fc92b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f68734b85cc4f29aa76783c2b4bbd34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51e26132e8ca4587923e90446bf9fb6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"645a15c7ddb6471d8ad7ba912d89e880":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f3a0b213b174dadb445b2a4f66a5bad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a7578fe89824adba3bdfca249b67320":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"993a0d29225c49b8b8d3d8e8d983550a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9aedf9a3da3411693d75e65ea4262d6","IPY_MODEL_ced228d60cfa4afb988eea538601ff09","IPY_MODEL_10a33fecb23a40c19ab179779cb327cd"],"layout":"IPY_MODEL_3e64eb21b6ee4c4d87649b33b1140ac3"}},"f9aedf9a3da3411693d75e65ea4262d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e5e2fa43fbd46d7ae07f04d61320d7c","placeholder":"​","style":"IPY_MODEL_7f9cdbc8394a436b90710ca5234aa8d1","value":"Predicting DataLoader 0: 100%"}},"ced228d60cfa4afb988eea538601ff09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_571418996c004460a501c3ae39602056","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2e5be9caee4492ea9cc20c39cd9ed59","value":1}},"10a33fecb23a40c19ab179779cb327cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3dbab1500bc54524ae1c15e4f3818011","placeholder":"​","style":"IPY_MODEL_1b8f187149244c258b83009c59a3db8c","value":" 1/1 [00:01&lt;00:00,  1.74s/it]"}},"3e64eb21b6ee4c4d87649b33b1140ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"7e5e2fa43fbd46d7ae07f04d61320d7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f9cdbc8394a436b90710ca5234aa8d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"571418996c004460a501c3ae39602056":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2e5be9caee4492ea9cc20c39cd9ed59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3dbab1500bc54524ae1c15e4f3818011":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b8f187149244c258b83009c59a3db8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a57357960b554c408564b5d059e8e0b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d2f94bd5bcca4067ac3d3f54fe57e979","IPY_MODEL_ca8ea1f223884ca3a275923da0c6d55d","IPY_MODEL_b6717abac7df48108a4f751ef4219347"],"layout":"IPY_MODEL_a71af7236f8842d39c46115eba842f04"}},"d2f94bd5bcca4067ac3d3f54fe57e979":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4faf45b197c64bc1bf55d4d6d53abf2f","placeholder":"​","style":"IPY_MODEL_eaab0377fd694e069dad9d7ef13ebe8f","value":"Predicting DataLoader 0: 100%"}},"ca8ea1f223884ca3a275923da0c6d55d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0114c18a6b0c4f2997bb483c3d8ba03a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf22ac5e01224f578e49b1f380cfae88","value":1}},"b6717abac7df48108a4f751ef4219347":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6896acac08fa4e0dad202fb6e88b900a","placeholder":"​","style":"IPY_MODEL_cbe6edb604d9415793e3d7c816138074","value":" 1/1 [00:01&lt;00:00,  1.37s/it]"}},"a71af7236f8842d39c46115eba842f04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"4faf45b197c64bc1bf55d4d6d53abf2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaab0377fd694e069dad9d7ef13ebe8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0114c18a6b0c4f2997bb483c3d8ba03a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf22ac5e01224f578e49b1f380cfae88":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6896acac08fa4e0dad202fb6e88b900a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbe6edb604d9415793e3d7c816138074":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c07c386bdc134a4183b9eb55d9f79a04":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0fe766ac0fd543d391d5a133dfbb5186","IPY_MODEL_5c69b7eaa9e047e082b6f5b1a31a7d32","IPY_MODEL_c70584a189c64475bb333bc4ba2451b2"],"layout":"IPY_MODEL_e6896520a74b4cb7a11b97d962df940e"}},"0fe766ac0fd543d391d5a133dfbb5186":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fae96eb6fe3340a0be8f36f50d30de97","placeholder":"​","style":"IPY_MODEL_497b01d3a81d4c69a25f652f1b030b2f","value":"Predicting DataLoader 0: 100%"}},"5c69b7eaa9e047e082b6f5b1a31a7d32":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cee271a42979417286ca18299f00289b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b78dda3255834614b12cac5b971ae0b7","value":1}},"c70584a189c64475bb333bc4ba2451b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95e47f0888eb469a8943c47bcbdd0914","placeholder":"​","style":"IPY_MODEL_94f5471b169342508eafe8f1fe350f3f","value":" 1/1 [00:01&lt;00:00,  1.44s/it]"}},"e6896520a74b4cb7a11b97d962df940e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"fae96eb6fe3340a0be8f36f50d30de97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"497b01d3a81d4c69a25f652f1b030b2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cee271a42979417286ca18299f00289b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b78dda3255834614b12cac5b971ae0b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95e47f0888eb469a8943c47bcbdd0914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94f5471b169342508eafe8f1fe350f3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d47942a940148d8a8a91556f290116a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0dc7a8ceb48a4582aa070d43a3df2956","IPY_MODEL_8146bd6cad0b4d09a262df3275669e6c","IPY_MODEL_8578b017df5c4e07bc08b56944893921"],"layout":"IPY_MODEL_7c4c7f4a7fac4042a00ebecc20b34445"}},"0dc7a8ceb48a4582aa070d43a3df2956":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45f7149a9df04666864a165c8a929c37","placeholder":"​","style":"IPY_MODEL_0bae89ae66334dd894da82467b109988","value":"Predicting DataLoader 0: 100%"}},"8146bd6cad0b4d09a262df3275669e6c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1d12b6f4e984db29bafbd68f7238e82","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c013d31e31424143a55507a224a4fcc1","value":1}},"8578b017df5c4e07bc08b56944893921":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f9270c802be42f9a20edeb6ac94a15b","placeholder":"​","style":"IPY_MODEL_2adade2e4c7c43d289d308b9bfe4cd96","value":" 1/1 [00:01&lt;00:00,  1.47s/it]"}},"7c4c7f4a7fac4042a00ebecc20b34445":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"45f7149a9df04666864a165c8a929c37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bae89ae66334dd894da82467b109988":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1d12b6f4e984db29bafbd68f7238e82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c013d31e31424143a55507a224a4fcc1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f9270c802be42f9a20edeb6ac94a15b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2adade2e4c7c43d289d308b9bfe4cd96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}