{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3rOHeiHoOKPe"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78XXjkCdOOzD"},"outputs":[],"source":["!pip install -q pytorch-lightning wandb torchmetrics transformers sentencepiece\n","!pip install -q --upgrade --force-reinstall --no-deps kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQmGCwMMOREH"},"outputs":[],"source":["!mkdir /root/.kaggle\n","!cp /content/drive/MyDrive/Colab/kaggle/kaggle.json /root/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yg3vCpmCcpvn"},"outputs":[],"source":["# import deberta-v2-v3-fast-tokenizer\n","import shutil\n","from pathlib import Path\n","\n","transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n","input_dir = Path(\"/content/drive/MyDrive/Colab/kaggle/nbme-score-clinical-patient-notes/input/deberta-v2-v3-fast-tokenizer\")\n","\n","convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","conversion_path = transformers_path/convert_file.name\n","\n","if conversion_path.exists():\n","    conversion_path.unlink()\n","\n","shutil.copy(convert_file, transformers_path)\n","deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n","    filepath = deberta_v2_path/filename\n","    \n","    if filepath.exists():\n","        filepath.unlink()\n","\n","    shutil.copy(input_dir/filename, filepath)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4386,"status":"ok","timestamp":1649697060850,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"tFUGUD38OVhD","outputId":"eeca185f-edfb-4796-a76f-3da03c14da29"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["import os\n","import gc\n","import sys\n","import json\n","import itertools\n","from tqdm.auto import tqdm\n","import logging\n","import datetime\n","import ast\n","import numpy as np\n","import pandas as pd\n","import sklearn.model_selection as sms\n","from sklearn.metrics import f1_score\n","import math\n","import re\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning import Trainer, seed_everything\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n","from pytorch_lightning.loggers import WandbLogger\n","\n","from transformers import AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n","\n","import wandb\n","\n","%env TOKENIZERS_PARALLELISM=true"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1649697060851,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"1duE-kW_OZZq"},"outputs":[],"source":["class Config:\n","    # ==============================\n","    # Globals #\n","    # ==============================\n","    competition_name = \"nbme-score-clinical-patient-notes\"\n","    group = \"DeBERTa-v3-large\"\n","    exp_id = \"019\"\n","    debug = False\n","    inference_only = False\n","    upload_from_colab = False\n","    colab_dir = \"/content/drive/MyDrive/Colab/kaggle/nbme-score-clinical-patient-notes\"\n","    kaggle_json_path = \"/root/.kaggle/kaggle.json\"\n","    kaggle_dataset_path = None\n","    gpus = 1\n","    seed = 2434\n","    max_epochs = 5\n","    accumulate_grad_batches = 4\n","    precision = 32\n","    num_fold = 5\n","    train_fold = [0,1,2,3,4] # 実行するfold\n","    pred_threshold = {\n","        0: 0.68,\n","        1: 0.52,\n","        2: 0.65,\n","        3: 0.52,\n","        4: 0.58,\n","        5: 0.47,\n","        6: 0.42,\n","        7: 0.51,\n","        8: 0.57,\n","        9: 0.5,\n","        # best_th: 0.57\n","    }\n","    use_pseudo_train = True\n","    # ==============================\n","    # Dataloader #\n","    # ==============================\n","    train_batch_size = 2\n","    valid_batch_size = 32\n","    test_batch_size = 32\n","    num_workers = 8\n","    # ==============================\n","    # Split #\n","    # ==============================\n","    split_name = \"StratifiedGroupKFold\"\n","    split_params = {\n","        \"n_splits\": num_fold if not debug else 4,\n","        \"shuffle\": True,\n","        \"random_state\": seed,\n","    }\n","    # ==============================\n","    # Model #\n","    # ==============================\n","    model_name = \"microsoft/deberta-v3-large\"\n","    max_length = 512\n","    hidden_size = 1024\n","    num_class = 1\n","    use_backbone_dropout = True\n","    dropout = 0.2\n","    initializer_range = 0.02\n","    lstm_params = {\n","        \"num_layers\": 1,\n","        \"batch_first\": True,\n","        \"bidirectional\": True,\n","        \"dropout\": 0.2,\n","    }\n","    # ==============================\n","    # Loss #\n","    # ==============================\n","    loss_name = \"BCEWithLogitsLoss\"\n","    loss_params = {\n","        \"reduction\": \"none\"\n","    }\n","    # ==============================\n","    # Optimizer #\n","    # ==============================\n","    optimizer_name = \"AdamW\"\n","    optimizer_params = {\n","        \"lr\": 2e-5,\n","        \"weight_decay\": 1e-2,\n","        \"eps\": 1e-6,\n","        \"betas\": (0.9, 0.999)\n","    }\n","    encoder_lr = 2e-5\n","    decoder_lr = 2e-5\n","    weight_decay = 0.01\n","    # ==============================\n","    # Scheduler #\n","    # ==============================\n","    scheduler_name = \"cosine-warmup\"\n","    scheduler_warmup_ratio = 0.1\n","    scheduler_params = {}\n","    scheduler_interval = \"step\"\n","    scheduler_cycle = \"one-cycle\" # epoch or one-cycle\n","    # ==============================\n","    # Callbacks #\n","    # ==============================\n","    checkpoint_params = {\n","        \"monitor\": \"val/micro-F1\",\n","        \"save_top_k\": 1,\n","        \"save_weights_only\": True,\n","        \"mode\": \"max\",\n","        \"verbose\": True,\n","    }\n","    early_stopping = False\n","    early_stopping_params = {\n","        \"monitor\": \"val/loss\",\n","        \"min_delta\": 0.0,\n","        \"patience\": 8,\n","        \"verbose\": False,\n","        \"mode\": \"min\",\n","    }"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7021,"status":"ok","timestamp":1649697067866,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"sokiSfvKSjft"},"outputs":[],"source":["# ====================================\n","# Setup #\n","# ====================================\n","class Logger:\n","    \"\"\" ref) https://github.com/ghmagazine/kagglebook/blob/master/ch04-model-interface/code/util.py\"\"\"\n","    def __init__(self, path):\n","        self.general_logger = logging.getLogger(path)\n","        stream_handler = logging.StreamHandler()\n","        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n","        if len(self.general_logger.handlers) == 0:\n","            self.general_logger.addHandler(stream_handler)\n","            self.general_logger.addHandler(file_general_handler)\n","            self.general_logger.setLevel(logging.INFO)\n","\n","    def info(self, message):\n","        # display time\n","        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n","\n","    @staticmethod\n","    def now_string():\n","        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n","\n","\n","def setup(cfg):\n","    cfg.on_colab = \"google.colab\" in sys.modules\n","    if cfg.on_colab:\n","        # kaggle api\n","        f = open(Config.kaggle_json_path, 'r')\n","        json_data = json.load(f)\n","        os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n","        # set input/output dir\n","        cfg.input_dir = os.path.join(cfg.colab_dir, \"input\")\n","        cfg.train_csv = os.path.join(cfg.input_dir, \"cleaned_train.csv\")\n","        cfg.external_train_csv = os.path.join(cfg.input_dir, \"external_exact_match_train.csv\")\n","        cfg.features_csv = os.path.join(cfg.input_dir, \"features.csv\")\n","        cfg.patient_notes_csv = os.path.join(cfg.input_dir, \"patient_notes.csv\")\n","        cfg.test_csv = os.path.join(cfg.input_dir, \"test.csv\")\n","        cfg.sample_submission = os.path.join(cfg.input_dir, \"sample_submission.csv\")\n","        cfg.output_dir = os.path.join(cfg.colab_dir, \"output\")\n","        cfg.exp_output_dir = os.path.join(cfg.output_dir, f\"exp{cfg.exp_id}\")\n","        cfg.model_dir = os.path.join(cfg.exp_output_dir, \"model\")\n","\n","        for d in [cfg.output_dir, cfg.exp_output_dir, cfg.model_dir]:\n","            os.makedirs(d, exist_ok=True)\n","            \n","        # wandb\n","        wandb.login()\n","    else:\n","        cfg.input_dir = f\"../input/{cfg.competition_name}\"\n","        cfg.train_csv = os.path.join(cfg.input_dir, \"train.csv\")\n","        cfg.features_csv = os.path.join(cfg.input_dir, \"features.csv\")\n","        cfg.patient_notes_csv = os.path.join(cfg.input_dir, \"patient_notes.csv\")\n","        cfg.test_csv = os.path.join(cfg.input_dir, \"test.csv\")\n","        cfg.sample_submission = os.path.join(cfg.input_dir, \"sample_submission.csv\")\n","        cfg.submission = \"./\"\n","        cfg.exp_output_dir = f\"exp{cfg.exp_id}\"\n","        cfg.model_dir = os.path.join(cfg.exp_output_dir, \"model\")\n","\n","        if cfg.kaggle_dataset_path is not None:\n","            cfg.model_dir = os.path.join(cfg.kaggle_dataset_path, \"model\")\n","\n","        for d in [cfg.exp_output_dir, cfg.model_dir]:\n","            os.makedirs(d, exist_ok=True)\n","\n","    return cfg\n","\n","\n","# ====================================\n","# Preprocess #\n","# ====================================\n","def get_input_data(cfg, input_type=\"train\"):\n","    input_df = pd.read_csv(cfg.train_csv) if input_type == \"train\" else pd.read_csv(cfg.test_csv)\n","    if cfg.debug and input_type != \"test\":\n","        input_df = input_df[input_df[\"pn_num\"].isin(input_df[\"pn_num\"].unique()[:100])].reset_index(drop=True)\n","    \n","    feature_texts_df = pd.read_csv(Config.features_csv)\n","    patient_notes_df = pd.read_csv(Config.patient_notes_csv)\n","\n","    if input_type == \"train\":\n","        # external_df = pd.read_csv(cfg.external_train_csv)\n","        # external_df = external_df.sample(14300 * 4, random_state=2434)\n","        # input_df = pd.concat([input_df, external_df], axis=0).reset_index(drop=True)\n","        input_df[\"annotation\"] = input_df[\"annotation\"].apply(ast.literal_eval)\n","        input_df[\"location\"] = input_df[\"location\"].apply(ast.literal_eval)\n","    \n","    input_df = input_df.merge(feature_texts_df, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","    input_df = input_df.merge(patient_notes_df, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","    input_df[\"pn_history\"] = input_df[\"pn_history\"].apply(clean_feature_text_for_preprocess)\n","\n","    return input_df\n","\n","\n","def get_and_merge_external_data(cfg, train_df: pd.DataFrame, fold: int):\n","    input_df = pd.read_csv(os.path.join(cfg.input_dir, f\"external_train_fold_{fold}.csv\"))\n","    input_df = input_df.sample(15000, random_state=2434)\n","    input_df[\"annotation\"] = input_df[\"annotation\"].apply(ast.literal_eval)\n","    input_df[\"location\"] = input_df[\"location\"].apply(ast.literal_eval)\n","    input_df[\"pn_history\"] = input_df[\"pn_history\"].apply(clean_feature_text_for_preprocess)\n","\n","    train_df = pd.concat([train_df, input_df], axis=0).reset_index(drop=True)\n","\n","    return train_df\n","\n","\n","def get_split(cfg, train_df):\n","    split_name = cfg.split_name\n","    split_params = cfg.split_params\n","    splitter = sms.__getattribute__(split_name)(**split_params)\n","\n","    groups = train_df[\"pn_num\"].to_numpy()\n","    train_df[\"fold\"] = -1\n","\n","    for fold_id, (train_idx, valid_idx) in enumerate(splitter.split(train_df, train_df[\"case_num\"], groups)):\n","        train_df.loc[valid_idx, \"fold\"] = int(fold_id)\n","\n","    return train_df\n","\n","\n","def get_filname_listdir(dirctory):\n","    listdir = os.listdir(dirctory)\n","    out_lst = [os.path.splitext(d)[0] for d in listdir]\n","    return out_lst\n","\n","\n","def get_tokenizer(cfg):\n","    if cfg.kaggle_dataset_path is not None:\n","        pretrained_dir = os.path.join(cfg.kaggle_dataset_path, \"pretrain_tokenizer\")\n","    else:\n","        pretrained_dir = os.path.join(cfg.exp_output_dir, \"pretrain_tokenizer\")\n","\n","    if not os.path.isdir(pretrained_dir):\n","        # deberta-v2 or deberta-v3\n","        if (\"deberta-v2\" in cfg.model_name) or (\"deberta-v3\" in cfg.model_name):\n","            tokenizer = DebertaV2TokenizerFast.from_pretrained(cfg.model_name)\n","        # except for (\"roberta\", \"deberta-v2\", \"deberta-v3\")\n","        elif \"roberta\" not in cfg.model_name:\n","            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n","        # roberta\n","        else:\n","            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name, trim_offsets=False)\n","\n","        tokenizer.save_pretrained(pretrained_dir)\n","\n","    else:\n","        # deberta-v2 or deberta-v3\n","        if (\"deberta-v2\" in cfg.model_name) or (\"deberta-v3\" in cfg.model_name):\n","            tokenizer = DebertaV2TokenizerFast.from_pretrained(pretrained_dir)\n","        # except for (\"roberta\", \"deberta-v2\", \"deberta-v3\")\n","        elif \"roberta\" not in cfg.model_name:\n","            tokenizer = AutoTokenizer.from_pretrained(pretrained_dir)\n","        # roberta\n","        else:\n","            tokenizer = AutoTokenizer.from_pretrained(pretrained_dir, trim_offsets=False)\n","\n","    return tokenizer\n","\n","\n","def get_backbone(cfg):\n","    if cfg.kaggle_dataset_path is not None:\n","        pretrained_dir = os.path.join(cfg.kaggle_dataset_path, \"pretrain_model\")\n","    else:\n","        pretrained_dir = os.path.join(cfg.exp_output_dir, \"pretrain_model\")\n","\n","    if not os.path.isdir(pretrained_dir):\n","        model_config = AutoConfig.from_pretrained(cfg.model_name)\n","        if not cfg.use_backbone_dropout:\n","            model_config.attention_probs_dropout_prob = 0.0\n","            model_config.hidden_dropout_prob = 0.0\n","        backbone = AutoModel.from_pretrained(cfg.model_name, config=model_config)\n","\n","        backbone.save_pretrained(pretrained_dir)\n","\n","    else:\n","        model_config = AutoConfig.from_pretrained(pretrained_dir)\n","        if not cfg.use_backbone_dropout:\n","            model_config.attention_probs_dropout_prob = 0.0\n","            model_config.hidden_dropout_prob = 0.0\n","        backbone = AutoModel.from_pretrained(pretrained_dir, config=model_config)\n","\n","    return backbone\n","\n","\n","def clean_feature_text_for_preprocess(text: str):\n","    \"\"\"\n","    reference: https://www.kaggle.com/code/theoviel/roberta-strikes-back\n","    \"\"\"\n","    text = re.sub('I-year', '1-year', text)\n","    text = re.sub('-OR-', \" or \", text)\n","    text = re.sub('-', ' ', text)\n","\n","    return text\n","\n","\n","# ====================================\n","# Dataset #\n","# ====================================\n","def get_inputs(cfg, text: str, feature_text: str, tokenizer):\n","    encoding = tokenizer(\n","        text,\n","        feature_text,\n","        max_length=cfg.max_length,\n","        padding=\"max_length\",\n","        return_offsets_mapping=False,\n","        # add_special_tokens=True\n","    )\n","\n","    for k, v in encoding.items():\n","        encoding[k] = torch.tensor(v, dtype=torch.long)\n","\n","    return encoding\n","\n","\n","def get_label(cfg, text: str, locations: list, tokenizer):\n","    encoding = tokenizer(\n","        text,\n","        max_length=cfg.max_length,\n","        padding=\"max_length\",\n","        return_offsets_mapping=True,\n","        # add_special_tokens=True\n","    )\n","    \n","    offset_mapping = encoding[\"offset_mapping\"]\n","    ignore_idx = np.where(np.array(encoding.sequence_ids()) != 0)[0]\n","    label = np.zeros(len(offset_mapping))\n","    label[ignore_idx] = -1\n","\n","    if len(locations) != 0:\n","        for location in locations:\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start_idx = -1\n","                end_idx = -1\n","                start, end = int(loc[0]), int(loc[1])\n","                for idx in range(len(offset_mapping)):\n","                    # DeBERTaのTokenizerは前の空白も含めるため+1する\n","                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                        start_idx = idx - 1\n","                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                        end_idx = idx + 1\n","                if start_idx == -1:\n","                    start_idx = end_idx\n","                if (start_idx != -1) & (end_idx != -1):\n","                    label[start_idx: end_idx] = 1\n","    \n","    return torch.tensor(label, dtype=torch.float)\n","\n","\n","class NBMEDataset(Dataset):\n","    def __init__(self, cfg, input_df: pd.DataFrame, tokenizer, phase: str = \"train\"):\n","        self.cfg = cfg\n","        self.input_df = input_df\n","        self.tokenizer = tokenizer\n","        self.phase = phase\n","        self.pn_histories = self.input_df[\"pn_history\"].to_numpy()\n","        self.feature_texts = self.input_df[\"feature_text\"].to_numpy()\n","        self.locations = self.input_df[\"location\"].to_numpy() if self.phase is \"train\" else None\n","\n","    def __len__(self):\n","        return len(self.input_df)\n","\n","    def __getitem__(self, idx):\n","        if self.phase == \"train\":\n","            inputs = get_inputs(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.feature_texts[idx],\n","                self.tokenizer,\n","            )\n","            label = get_label(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.locations[idx],\n","                self.tokenizer,\n","            )\n","\n","            return {\n","                \"input_ids\": inputs[\"input_ids\"],\n","                \"attention_mask\": inputs[\"attention_mask\"],\n","                \"labels\": label,\n","            }\n","\n","        elif self.phase == \"test\":\n","            inputs = get_inputs(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.feature_texts[idx],\n","                self.tokenizer,\n","            )\n","\n","            return {\n","                \"input_ids\": inputs[\"input_ids\"],\n","                \"attention_mask\": inputs[\"attention_mask\"],\n","            }\n","        else:\n","            raise NotImplementedError\n","\n","\n","class NBMEDataModule(pl.LightningDataModule):\n","    def __init__(self, cfg, tokenizer, train_df: pd.DataFrame = None, valid_df: pd.DataFrame = None, test_df: pd.DataFrame = None):\n","        super(NBMEDataModule, self).__init__()\n","\n","        self.cfg = cfg\n","        self.tokenizer = tokenizer\n","        self.train_df = train_df\n","        self.valid_df = valid_df\n","        self.test_df = test_df\n","\n","    def prepare_data(self):\n","        if self.test_df is None:\n","            self.train_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.train_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"train\"\n","            )\n","            self.val_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.valid_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"train\"\n","            )\n","        else:\n","            self.test_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.test_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"test\"\n","            )\n","\n","    def train_dataloader(self):\n","        return DataLoader(\n","            self.train_dataset,\n","            batch_size=self.cfg.train_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","    \n","    def val_dataloader(self):\n","        return DataLoader(\n","            self.val_dataset,\n","            batch_size=self.cfg.valid_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","\n","    def predict_dataloader(self):\n","        return DataLoader(\n","            self.test_dataset,\n","            batch_size=self.cfg.test_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","\n","\n","# ====================================\n","# Model #\n","# ====================================\n","class NBMEModel(nn.Module):\n","    def __init__(self, cfg):\n","        super(NBMEModel, self).__init__()\n","\n","        self.cfg = cfg\n","        self.backbone = get_backbone(self.cfg)\n","        self.dropout = nn.Dropout(self.cfg.dropout)\n","        self.lstm = nn.LSTM(self.cfg.hidden_size, self.cfg.hidden_size, **self.cfg.lstm_params)\n","        self.classifier = nn.Linear(self.cfg.hidden_size * 2, self.cfg.num_class)\n","        self._init_weights(self.classifier)\n","        self._reinitialize()\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.cfg.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.cfg.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def _reinitialize(self):\n","        \"\"\"\n","        Tensorflow/Keras-like initialization\n","        \"\"\"\n","        for name, p in self.named_parameters():\n","            if 'lstm' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","            elif 'fc' in name:\n","                if 'weight' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'bias' in name:\n","                    p.data.fill_(0)\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask) # (batch_size, seq_len, hidden_size)\n","        x = outputs[0] # extract last_hidden_states\n","        x, _ = self.lstm(x)\n","        x = self.dropout(x)\n","        x = self.classifier(x) # (batch_size, seq_len, num_class)\n","\n","        return x\n","\n","\n","class NBMELightningModule(pl.LightningModule):\n","    def __init__(self, cfg, tokenizer=None, valid_df=None, valid_labels=None):\n","        super(NBMELightningModule, self).__init__()\n","\n","        self.cfg = cfg\n","        self.model = NBMEModel(self.cfg)\n","        self.criterion = get_criterion(self.cfg)\n","        self.tokenizer = tokenizer\n","        self.valid_df = valid_df\n","        self.valid_labels = valid_labels\n","\n","    def setup(self, stage=None):\n","        # calculate training total steps\n","        if stage == \"fit\":\n","            if self.cfg.scheduler_cycle == \"one-cycle\":\n","                self.training_steps = math.ceil(len(self.trainer.datamodule.train_dataloader()) / self.trainer.accumulate_grad_batches) * self.trainer.max_epochs\n","            elif self.cfg.scheduler_cycle == \"epoch\":\n","                self.training_steps = math.ceil(len(self.trainer.datamodule.train_dataloader()) / self.trainer.accumulate_grad_batches) * 1\n","            else:\n","                raise NotImplementedError\n","            self.warmup_steps = int(self.training_steps * self.cfg.scheduler_warmup_ratio) if self.cfg.scheduler_warmup_ratio else None\n","    \n","    def forward(self, input_ids, attention_mask):\n","        return self.model(input_ids, attention_mask)\n","\n","    def training_step(self, batch, batch_idx):\n","        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        mask = (labels.view(-1, 1) != -1)\n","        loss = torch.masked_select(loss, mask).mean()\n","        self.log(\"train/loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        mask = (labels.view(-1, 1) != -1)\n","        loss = torch.masked_select(loss, mask).mean()\n","        self.log(\"val/loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n","\n","        return {\n","            \"loss\": loss,\n","            \"preds\": y_preds.detach()\n","        }\n","\n","    def validation_epoch_end(self, outputs):\n","        preds = torch.cat([output[\"preds\"] for output in outputs]).squeeze().cpu().numpy()\n","        char_preds = get_token_probs_to_char_probs(self.valid_df[\"pn_history\"].to_numpy(), preds, self.tokenizer)\n","        results = get_results(self.cfg, char_preds, th=0.5)\n","        preds = get_predictions(results)\n","        score = get_score(self.valid_labels, preds)\n","        self.log(\"val/micro-F1\", score, logger=True, prog_bar=True)\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n","        input_ids, attention_mask = batch[\"input_ids\"], batch[\"attention_mask\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        y_preds = y_preds.sigmoid()\n","\n","        return y_preds.squeeze()\n","\n","    def configure_optimizers(self):\n","        optimizer_params = get_optimizer_params(self.model, self.cfg.encoder_lr, self.cfg.decoder_lr, self.cfg.weight_decay)\n","        optimizer = get_optimizer(self.cfg, optimizer_params)\n","\n","        if self.cfg.scheduler_name is None:\n","            return [optimizer]\n","        else:\n","            scheduler = get_scheduler(self.cfg, optimizer, num_warmup_steps=self.warmup_steps, num_training_steps=self.training_steps)\n","            scheduler = {\"scheduler\": scheduler, \"interval\": self.cfg.scheduler_interval}\n","\n","            return [optimizer], [scheduler]\n","\n","\n","# ====================================\n","# Criterion, Optimizer, Scheduler #\n","# ====================================\n","def get_criterion(cfg):\n","    loss_name = cfg.loss_name\n","    loss_params = cfg.loss_params\n","\n","    return nn.__getattribute__(loss_name)(**loss_params)\n","\n","\n","def get_optimizer(cfg, parameters):\n","    optimizer_name = cfg.optimizer_name\n","    optimizer_params = cfg.optimizer_params\n","\n","    return optim.__getattribute__(optimizer_name)(parameters, **optimizer_params)\n","\n","\n","def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","    # param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_parameters = [\n","        {'params': [p for n, p in model.backbone.named_parameters() if not any(nd in n for nd in no_decay)],\n","            'lr': encoder_lr, 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.backbone.named_parameters() if any(nd in n for nd in no_decay)],\n","            'lr': encoder_lr, 'weight_decay': 0.0},\n","        {'params': [p for n, p in model.named_parameters() if \"backbone\" not in n],\n","            'lr': decoder_lr, 'weight_decay': 0.0}\n","    ]\n","\n","    return optimizer_parameters\n","\n","\n","def get_scheduler(cfg, optimizer, num_warmup_steps=None, num_training_steps=None):\n","    scheduler_name = cfg.scheduler_name\n","    scheduler_params = cfg.scheduler_params\n","\n","    if scheduler_name == \"cosine-warmup\":\n","        return get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","            **scheduler_params\n","        )\n","    elif scheduler_name == \"linear-warmup\":\n","        return get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","            **scheduler_params\n","        )\n","    else:\n","        return optim.lr_scheduler.__getattribute__(scheduler_name)(optimizer, **scheduler_params)\n","\n","\n","# ====================================\n","# Train & Predict #\n","# ====================================\n","def train_fold(cfg, train_df, valid_df, tokenizer, fold, valid_labels):\n","    # Seed\n","    seed_everything(cfg.seed)\n","\n","    # Wandb\n","    wandb_logger = WandbLogger(\n","        project=cfg.competition_name,\n","        group=cfg.group,\n","        name=f\"exp{cfg.exp_id}-fold-{fold}\",\n","        job_type=f\"exp{cfg.exp_id}\",\n","        reinit=True,\n","        anonymous=\"must\",\n","    )\n","\n","    # Model Checkpoint\n","    checkpoint = ModelCheckpoint(\n","        dirpath=cfg.model_dir,\n","        # filename=f\"exp{cfg.exp_id}-fold-{fold}\" + \"-{epoch}\",\n","        filename=f\"exp{cfg.exp_id}-fold-{fold}\",\n","        **cfg.checkpoint_params,\n","    )\n","\n","    # Learning Rate\n","    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n","    callbacks = [checkpoint, lr_monitor]\n","\n","    # Early Stopping\n","    if cfg.early_stopping:\n","        early_stopping = EarlyStopping(**cfg.early_stopping_params)\n","        callbacks += [early_stopping]\n","    \n","    # DataModule\n","    lightning_datamodule = NBMEDataModule(\n","        cfg=cfg,\n","        tokenizer=tokenizer,\n","        train_df=train_df,\n","        valid_df=valid_df,\n","    )\n","\n","    # Model\n","    lightning_model = NBMELightningModule(\n","        cfg,\n","        tokenizer,\n","        valid_df,\n","        valid_labels,\n","    )\n","\n","    # Trainer\n","    trainer = Trainer(\n","        gpus=cfg.gpus,\n","        max_epochs=cfg.max_epochs,\n","        callbacks=callbacks,\n","        logger=[wandb_logger],\n","        accumulate_grad_batches=cfg.accumulate_grad_batches,\n","        precision=cfg.precision,\n","        # deterministic=True,\n","        benchmark=False,\n","    )\n","\n","    trainer.fit(lightning_model, datamodule=lightning_datamodule)\n","    wandb.finish(quiet=True)\n","\n","    del lightning_datamodule, lightning_model, trainer\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","\n","def train_cv(cfg, input_df, tokenizer):\n","    oof_char_probs = []\n","    true_df = pd.DataFrame()\n","\n","    for fold_id in range(cfg.num_fold):\n","        if fold_id in cfg.train_fold:\n","            filename = f\"exp{cfg.exp_id}-fold-{fold_id}\"\n","            filelist = get_filname_listdir(cfg.model_dir)\n","\n","            train_df = input_df[input_df[\"fold\"] != fold_id].reset_index(drop=True)\n","            if cfg.use_pseudo_train:\n","                train_df = get_and_merge_external_data(cfg, train_df, fold_id) # merge external train\n","            valid_df = input_df[input_df[\"fold\"] == fold_id].reset_index(drop=True)\n","            valid_df[\"labels\"] = create_labels_for_scoring(valid_df)\n","\n","            # training\n","            if not filename in filelist:\n","                train_fold(\n","                    cfg=cfg,\n","                    train_df=train_df,\n","                    valid_df=valid_df,\n","                    tokenizer=tokenizer,\n","                    fold=fold_id,\n","                    valid_labels=valid_df[\"labels\"].to_numpy(),\n","                )\n","\n","            # oof\n","            char_probs = predict(\n","                cfg=cfg,\n","                input_df=valid_df,\n","                tokenizer=tokenizer,\n","                filename=filename,\n","                labels=valid_df[\"labels\"].to_numpy(),\n","            )\n","            # scoring and optimize threshodl for each case\n","            get_score_and_threshold(cfg, char_probs, valid_df, fold_id)\n","            \n","            oof_char_probs += char_probs\n","            true_df = pd.concat([true_df, valid_df], axis=0)\n","\n","    get_score_and_threshold(cfg, oof_char_probs, true_df.reset_index(drop=True), \"cv\")\n","    results = get_results(cfg, oof_char_probs, cases=true_df[\"case_num\"].to_list())\n","    preds = get_predictions(results)\n","    oof_score = get_score(true_df[\"labels\"].to_list(), preds)\n","    cfg.logger.info(f\"optimized case-threshold cv-score: {oof_score}\")\n","\n","\n","def predict_raw_prediction(cfg, input_df, tokenizer, filename, labels=None):\n","    checkpoint_path = os.path.join(cfg.model_dir, filename + \".ckpt\")\n","\n","    lightning_model = NBMELightningModule(\n","        cfg,\n","        tokenizer,\n","        input_df,\n","        labels,\n","    )\n","\n","    lightning_model = lightning_model.load_from_checkpoint(\n","        checkpoint_path=checkpoint_path,\n","        cfg=cfg,\n","    )\n","\n","    lightning_datamodule = NBMEDataModule(\n","        cfg,\n","        tokenizer=tokenizer,\n","        test_df=input_df\n","    )\n","\n","    trainer = Trainer(\n","        gpus=cfg.gpus,\n","    )\n","\n","    preds = trainer.predict(\n","        lightning_model,\n","        datamodule=lightning_datamodule,\n","        return_predictions=True\n","    )\n","\n","    preds = torch.cat(preds).cpu().numpy() # (sample, max_seq, num_class)\n","\n","    del lightning_datamodule, lightning_model, trainer\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    \n","    return preds\n","    \n","\n","def predict(cfg, input_df, tokenizer, filename, labels):\n","    file_path = os.path.join(cfg.exp_output_dir, f\"{filename}.npy\")\n","    \n","    if os.path.isfile(file_path):\n","        preds = np.load(file_path)\n","    else:\n","        preds = predict_raw_prediction(cfg, input_df, tokenizer, filename, labels)\n","        np.save(os.path.join(cfg.exp_output_dir, filename), preds)\n","\n","    char_probs = get_token_probs_to_char_probs(input_df[\"pn_history\"].to_numpy(), preds, tokenizer)\n","\n","    return char_probs\n","\n","\n","def predict_cv(cfg, input_df, tokenizer):\n","    \"\"\"\n","    CVモデルで予測\n","    \"\"\"\n","    fold_preds = []\n","    for fold_id in range(cfg.num_fold):\n","        if fold_id in cfg.train_fold:\n","            filename = f\"exp{cfg.exp_id}-fold-{fold_id}\"\n","            preds = predict_raw_prediction(cfg, input_df, tokenizer, filename)\n","            char_preds = get_token_probs_to_char_probs(input_df[\"pn_history\"].to_numpy(), preds, tokenizer)\n","            fold_preds.append(char_preds)\n","\n","    fold_preds = np.mean(fold_preds, axis=0)\n","    results = get_results(cfg, fold_preds, cases=input_df[\"case_num\"].to_list())\n","\n","    output_df = input_df.copy()\n","    output_df[\"location\"] = results\n","    \n","    return output_df\n","\n","\n","def get_token_probs_to_char_probs(texts, predictions, tokenizer):\n","    \"\"\"\n","    予測値をtoken-level -> char-levelに変形\n","    \"\"\"\n","    results = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n","        encoded = tokenizer(\n","            text, \n","            add_special_tokens=True,\n","            return_offsets_mapping=True\n","        )\n","        \n","        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n","            start = offset_mapping[0]\n","            end = offset_mapping[1]\n","\n","            # 先行するスペースがあればスパンから除く\n","            # if text[start] == \" \":\n","            #     start = start + 1\n","            \n","            results[i][start: end] = pred\n","    \n","    return results\n","\n","\n","def get_results(cfg, char_probs, th=0.5, cases=None):\n","    \"\"\"\n","    \";\"区切りのスパンに変換\n","    \"\"\"\n","    results = []\n","    if cases:\n","        for char_prob, case in zip(char_probs, cases):\n","            th = cfg.pred_threshold[case]\n","            result = np.where(char_prob >= th)[0] + 1\n","            result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","            result = [f\"{min(r)} {max(r)}\" for r in result]\n","            result = \";\".join(result)\n","            results.append(result)\n","    else:\n","        for char_prob in char_probs:\n","            result = np.where(char_prob >= th)[0] + 1\n","            result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","            result = [f\"{min(r)} {max(r)}\" for r in result]\n","            result = \";\".join(result)\n","            results.append(result)\n","    \n","    return results\n","\n","\n","def get_predictions(results):\n","    \"\"\"\n","    各スパンのリストを要素とするリストに変換\n","    '3 4;7 9;12 13' -> [[3, 4], [7, 9], [12, 13]]\n","    \"\"\"\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(';')]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    \n","    return predictions\n","\n","\n","def create_labels_for_scoring(df):\n","    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n","    df = df.copy()\n","    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, 'location']\n","        if lst:\n","            new_lst = ';'.join(lst)\n","            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n","    # create labels\n","    truths = []\n","    for location_list in df['location_for_create_labels'].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(';')]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","    \n","    return truths\n","\n","\n","# ====================================\n","# Metrics #\n","# ====================================\n","def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    \n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    \n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","\n","    return score\n","\n","\n","def optimize_threshold(cfg, valid_labels, char_probs):\n","    best_thres = 0.5\n","    best_score = 0.0\n","    for th in np.arange(0.40, 0.70, 0.01):\n","        th = np.round(th, 2)\n","        results = get_results(cfg, char_probs, th=th)\n","        preds = get_predictions(results)\n","        score = get_score(valid_labels, preds)\n","\n","        if best_score < score:\n","            best_thres = th\n","            best_score = score\n","\n","    return best_thres, best_score\n","\n","\n","def get_score_and_threshold(cfg, pred_char_probs, valid_df, fold_id):\n","    \"\"\"\n","    case毎 & 全体のスコアリングと閾値の最適化\n","    \"\"\"\n","    class_scores = {}\n","    valid_df = valid_df.copy()\n","    valid_df[\"pred_char_probs\"] = pred_char_probs\n","\n","    for case in valid_df[\"case_num\"].unique():\n","        case_idx = valid_df.query('case_num == @case').index\n","        case_labels = valid_df.iloc[case_idx][\"labels\"].to_list()\n","        case_char_probs = valid_df.iloc[case_idx][\"pred_char_probs\"].to_list()\n","        best_thres, best_score = optimize_threshold(cfg, case_labels, case_char_probs)\n","        if fold_id != \"cv\":\n","            cfg.logger.info(f\"fold {fold_id}: case_num: {case} best_th: {best_thres}  score: {best_score:.5f}\")\n","        else:\n","            cfg.logger.info(f\"case_num: {case} best_th: {best_thres}  score: {best_score:.5f}\")\n","\n","    best_thres, best_score = optimize_threshold(cfg, valid_df[\"labels\"].to_list(), pred_char_probs)\n","    if fold_id != \"cv\":\n","        cfg.logger.info(f\"fold {fold_id}: best_th: {best_thres}  score: {best_score:.5f}\")\n","    else:\n","        cfg.logger.info(f\"best_th: {best_thres}  score: {best_score:.5f}\")\n","\n","\n","# ====================================\n","# Pseudo labeling #\n","# ====================================\n","def get_input_data_for_pseudo_labeling(cfg, nrows: int = None):\n","    train_df = pd.read_csv(cfg.train_csv)\n","    feature_texts_df = pd.read_csv(Config.features_csv)\n","    patient_notes_df = pd.read_csv(Config.patient_notes_csv)\n","\n","    train_pn_idx = list(train_df[\"pn_num\"].unique())\n","    extract_train_df = patient_notes_df[~patient_notes_df[\"pn_num\"].isin(train_pn_idx)].reset_index(drop=True)\n","    extract_train_df = extract_train_df.merge(feature_texts_df, on=[\"case_num\"], how=\"left\")\n","    extract_train_df[\"id\"] = extract_train_df[\"pn_num\"].astype(str).str.zfill(5) + \"_\" + extract_train_df[\"feature_num\"].astype(str).str.zfill(3)\n","    extract_train_df[\"pn_history\"] = extract_train_df[\"pn_history\"].apply(clean_feature_text_for_preprocess)\n","    extract_train_df = extract_train_df.reindex(columns=[\"id\", \"case_num\", \"pn_num\", \"feature_num\", \"feature_text\", \"pn_history\"])\n","\n","    if nrows is not None:\n","        select_idx = extract_train_df.drop_duplicates(subset=\"pn_num\").sample(n=nrows, random_state=2434)[\"pn_num\"].to_list()\n","        extract_train_df = extract_train_df[extract_train_df[\"pn_num\"].isin(select_idx)].reset_index(drop=True)\n","\n","    return extract_train_df\n","\n","\n","def create_external_input(pred_df):\n","    pred_df[\"predict\"] = get_predictions(pred_df[\"location\"].to_list())\n","\n","    all_annotation_texts = []\n","    for history, locations in zip(pred_df[\"pn_history\"].to_numpy(), pred_df[\"predict\"].to_numpy()):\n","        sample_annotation_texts = []\n","        for loc in locations:\n","            start, end = loc[0], loc[1]\n","            annotion_text = history[start: end]\n","            sample_annotation_texts.append(annotion_text)\n","        all_annotation_texts.append(sample_annotation_texts)\n","\n","    pred_df[\"annotation\"] = all_annotation_texts\n","    pred_df[\"location\"] = pred_df[\"location\"].apply(lambda x: x.split(\";\"))\n","\n","    pred_df[\"len_annotation\"] = pred_df[\"annotation\"].apply(len)\n","    pred_df = pred_df[pred_df[\"len_annotation\"] != 0].reset_index(drop=True)\n","\n","    return pred_df.drop(columns=[\"predict\", \"len_annotation\"], axis=1)\n","\n","\n","def predict_for_pseudo_labeling(cfg, input_df, tokenizer):\n","    \"\"\"\n","    pseudo-labeling for each fold model\n","    \"\"\"\n","    for fold_id in range(cfg.num_fold):\n","        if fold_id in cfg.train_fold:\n","            filename = f\"exp{cfg.exp_id}-fold-{fold_id}\"\n","            preds = predict_raw_prediction(cfg, input_df, tokenizer, filename)\n","            char_preds = get_token_probs_to_char_probs(input_df[\"pn_history\"].to_numpy(), preds, tokenizer)\n","            results = get_results(cfg, char_preds, cases=input_df[\"case_num\"].to_list())\n","\n","            output_df = input_df.copy()\n","            output_df[\"location\"] = results\n","\n","            output_df = create_external_input(output_df)\n","            output_df[\"fold\"] = fold_id\n","            output_df.to_csv(os.path.join(cfg.input_dir, f\"external_train_fold_{fold_id}.csv\"), index=False)\n","\n","            del output_df"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0f7e10c06771496595c15992650da6d0","7a0e1d62d8cd4e2c9d0b66f38ac85f9f","e749406c0fb44a84b1be79aff4d6706a","8937179368714a7f933b69cb08ce2f8f","edafd90c76f94c34b70c4f688de2a45e","0cc669f7eb9645b98938644e17ca72df","cb085aff033644dfb5489a009d48418d","5cf9855d65af466187483de0063f5d91","aad7d91b0e3541d2921aa59cc80cb1d8","07a64933ed264182a92c4c397c884e27","1ce83732f6cf4f908e64bce4e525de7b","4ca1ffcaf04f4f2db85a0645dadbf459","32bfb11210aa43bfb441ac45ea524ed0","e7f891f2a0804199a4e11db28a5ee4a6","7f2dca2a6212484991d2ca1d5f9500cd","fd871f6fdbd942d48bccfbc633046c6b","a860782468644f0aab17ba4842518cd0","b2913a8586e847ccbd213a5613ac77e8","6891c70d2f2145898bb03256f729ff95","f13479e811c747f7a0f06ef32318e679","beae6d2d0cd0475996a109eb9185c4a3","35b179cdc4924859812bc615b58b3b7e","6da8e32f47a644a08f9441cde6ff353c","6f7ec78a7f454c62a3bfadc5718f35ea","56252af0686a4c1887309678db83bbce","a9292b4533a941c1a113ba804bdf6dea","d555d8153ff847688e1e4bae51a02b36","eb2438fa4905497ba80896c3b7ad72ac","a5e6810e9b4e44108b1ef5a246d7d6eb","a3c622151bb844089fe17ba1dc8aa74a","8841b38710f449f3bbd61132e01e41ee","dbf8e309ba744eb9a65ac79f14978235","9f23a353dbbc434a9c73cfc955d23079","2ac3b02c00094120b76d2ceceac6cabe","d20dde0867904641ab643fee341422df","c3c055b66fca4f469c51c1eda04b153d","64c3bd205a554513a85eaee15b28e642","36b7e88586354756970865c61f819d42","e23e227df6574e6f9e576d9ac134bd9d","a64925ec311444039884fbbd075cb53e","671b319e88cb4667813b7d1eb3790178","b2e01fef5ec2441cac5b2a17f88fd133","fb1d811d77a24eada45944ef21249a46","a1bbe601139b4209bf225267d379bf79","63c15fcb0d794d318c4b6cd711b8a8a9","cb5922292694406585e765dfcbaeecc6","1043e38b40b04cd3b2c062219e4810c9","267319ab879941628698783c586be1e8","ba35422a2d384e3ab9eb5912c9b6dbb2","f07ae4689aee4c0ebfc217954b6c1286","19cfcc82a0cf4cc1953d59225d672a8d","75af9464c7a74a2fb017039bc6e59b57","c9c7c96a6bbe456cb2e0f04e048d4f08","16dd49033e7d44d18ced889c3a1bbfcf","0cac5082a97c426cbf1efefdce5f1e11"]},"id":"rQgD_e_gTYtP","executionInfo":{"status":"ok","timestamp":1649697866662,"user_tz":-540,"elapsed":798804,"user":{"displayName":"永友遥","userId":"11743586908271963047"}},"outputId":"3f5a08f3-9b93-43fd-a7e9-16daea30b654"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mazupero\u001b[0m (use `wandb login --relogin` to force relogin)\n","[2022-04-11 17:11:18] - fold 0: case_num: 0 best_th: 0.56  score: 0.88867\n","[2022-04-11 17:11:19] - fold 0: case_num: 1 best_th: 0.55  score: 0.91145\n","[2022-04-11 17:11:20] - fold 0: case_num: 2 best_th: 0.65  score: 0.86152\n","[2022-04-11 17:11:21] - fold 0: case_num: 3 best_th: 0.68  score: 0.92379\n","[2022-04-11 17:11:22] - fold 0: case_num: 4 best_th: 0.4  score: 0.90841\n","[2022-04-11 17:11:24] - fold 0: case_num: 5 best_th: 0.69  score: 0.81191\n","[2022-04-11 17:11:25] - fold 0: case_num: 6 best_th: 0.52  score: 0.88382\n","[2022-04-11 17:11:25] - fold 0: case_num: 7 best_th: 0.67  score: 0.87120\n","[2022-04-11 17:11:27] - fold 0: case_num: 8 best_th: 0.57  score: 0.92892\n","[2022-04-11 17:11:28] - fold 0: case_num: 9 best_th: 0.64  score: 0.93327\n","[2022-04-11 17:11:40] - fold 0: best_th: 0.64  score: 0.88675\n","[2022-04-11 17:11:44] - fold 1: case_num: 0 best_th: 0.64  score: 0.90438\n","[2022-04-11 17:11:45] - fold 1: case_num: 1 best_th: 0.43  score: 0.89890\n","[2022-04-11 17:11:47] - fold 1: case_num: 2 best_th: 0.67  score: 0.82964\n","[2022-04-11 17:11:48] - fold 1: case_num: 3 best_th: 0.51  score: 0.93333\n","[2022-04-11 17:11:49] - fold 1: case_num: 4 best_th: 0.56  score: 0.93266\n","[2022-04-11 17:11:50] - fold 1: case_num: 5 best_th: 0.63  score: 0.84667\n","[2022-04-11 17:11:51] - fold 1: case_num: 6 best_th: 0.41  score: 0.89273\n","[2022-04-11 17:11:52] - fold 1: case_num: 7 best_th: 0.54  score: 0.83941\n","[2022-04-11 17:11:54] - fold 1: case_num: 8 best_th: 0.68  score: 0.90691\n","[2022-04-11 17:11:55] - fold 1: case_num: 9 best_th: 0.4  score: 0.92412\n","[2022-04-11 17:12:07] - fold 1: best_th: 0.65  score: 0.88629\n","[2022-04-11 17:12:12] - fold 2: case_num: 0 best_th: 0.63  score: 0.88258\n","[2022-04-11 17:12:13] - fold 2: case_num: 1 best_th: 0.42  score: 0.88662\n","[2022-04-11 17:12:15] - fold 2: case_num: 2 best_th: 0.45  score: 0.81518\n","[2022-04-11 17:12:16] - fold 2: case_num: 3 best_th: 0.59  score: 0.91421\n","[2022-04-11 17:12:17] - fold 2: case_num: 4 best_th: 0.58  score: 0.93551\n","[2022-04-11 17:12:19] - fold 2: case_num: 5 best_th: 0.64  score: 0.80045\n","[2022-04-11 17:12:20] - fold 2: case_num: 6 best_th: 0.55  score: 0.91070\n","[2022-04-11 17:12:21] - fold 2: case_num: 7 best_th: 0.4  score: 0.87280\n","[2022-04-11 17:12:22] - fold 2: case_num: 8 best_th: 0.69  score: 0.92060\n","[2022-04-11 17:12:23] - fold 2: case_num: 9 best_th: 0.41  score: 0.93643\n","[2022-04-11 17:12:36] - fold 2: best_th: 0.46  score: 0.87550\n","[2022-04-11 17:12:40] - fold 3: case_num: 0 best_th: 0.5  score: 0.86173\n","[2022-04-11 17:12:41] - fold 3: case_num: 1 best_th: 0.52  score: 0.90033\n","[2022-04-11 17:12:42] - fold 3: case_num: 2 best_th: 0.65  score: 0.87885\n","[2022-04-11 17:12:44] - fold 3: case_num: 3 best_th: 0.52  score: 0.91132\n","[2022-04-11 17:12:45] - fold 3: case_num: 4 best_th: 0.61  score: 0.90583\n","[2022-04-11 17:12:46] - fold 3: case_num: 5 best_th: 0.4  score: 0.82864\n","[2022-04-11 17:12:47] - fold 3: case_num: 6 best_th: 0.62  score: 0.91247\n","[2022-04-11 17:12:48] - fold 3: case_num: 7 best_th: 0.52  score: 0.86078\n","[2022-04-11 17:12:49] - fold 3: case_num: 8 best_th: 0.48  score: 0.91959\n","[2022-04-11 17:12:51] - fold 3: case_num: 9 best_th: 0.64  score: 0.92071\n","[2022-04-11 17:13:03] - fold 3: best_th: 0.52  score: 0.88664\n","[2022-04-11 17:13:08] - fold 4: case_num: 0 best_th: 0.69  score: 0.91648\n","[2022-04-11 17:13:09] - fold 4: case_num: 1 best_th: 0.57  score: 0.90044\n","[2022-04-11 17:13:10] - fold 4: case_num: 2 best_th: 0.61  score: 0.85785\n","[2022-04-11 17:13:11] - fold 4: case_num: 3 best_th: 0.52  score: 0.90490\n","[2022-04-11 17:13:12] - fold 4: case_num: 4 best_th: 0.43  score: 0.92700\n","[2022-04-11 17:13:14] - fold 4: case_num: 5 best_th: 0.55  score: 0.84455\n","[2022-04-11 17:13:15] - fold 4: case_num: 6 best_th: 0.4  score: 0.87749\n","[2022-04-11 17:13:16] - fold 4: case_num: 7 best_th: 0.66  score: 0.86964\n","[2022-04-11 17:13:17] - fold 4: case_num: 8 best_th: 0.61  score: 0.90112\n","[2022-04-11 17:13:18] - fold 4: case_num: 9 best_th: 0.63  score: 0.91513\n","[2022-04-11 17:13:31] - fold 4: best_th: 0.55  score: 0.88573\n","[2022-04-11 17:13:37] - case_num: 0 best_th: 0.68  score: 0.88909\n","[2022-04-11 17:13:43] - case_num: 1 best_th: 0.52  score: 0.89829\n","[2022-04-11 17:13:49] - case_num: 2 best_th: 0.65  score: 0.84395\n","[2022-04-11 17:13:56] - case_num: 3 best_th: 0.52  score: 0.91721\n","[2022-04-11 17:14:01] - case_num: 4 best_th: 0.58  score: 0.91986\n","[2022-04-11 17:14:09] - case_num: 5 best_th: 0.47  score: 0.82412\n","[2022-04-11 17:14:14] - case_num: 6 best_th: 0.42  score: 0.89469\n","[2022-04-11 17:14:18] - case_num: 7 best_th: 0.51  score: 0.86107\n","[2022-04-11 17:14:25] - case_num: 8 best_th: 0.57  score: 0.91409\n","[2022-04-11 17:14:31] - case_num: 9 best_th: 0.5  score: 0.92352\n","[2022-04-11 17:15:37] - best_th: 0.57  score: 0.88361\n","[2022-04-11 17:15:39] - optimized case-threshold cv-score: 0.8832770078235616\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n","  category=PossibleUserWarning,\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f7e10c06771496595c15992650da6d0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ca1ffcaf04f4f2db85a0645dadbf459"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6da8e32f47a644a08f9441cde6ff353c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ac3b02c00094120b76d2ceceac6cabe"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63c15fcb0d794d318c4b6cd711b8a8a9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting upload for file model.tar\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8.40G/8.40G [04:42<00:00, 31.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: model.tar (8GB)\n","Starting upload for file pretrain_tokenizer.tar\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10.6M/10.6M [00:02<00:00, 3.83MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: pretrain_tokenizer.tar (11MB)\n","Starting upload for file pretrain_model.tar\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.62G/1.62G [00:42<00:00, 40.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: pretrain_model.tar (2GB)\n","Starting upload for file exp019-fold-0.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.53M/5.53M [00:02<00:00, 2.77MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp019-fold-0.npy (6MB)\n","Starting upload for file exp019-fold-4.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:02<00:00, 2.34MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp019-fold-4.npy (6MB)\n","Starting upload for file exp019-fold-3.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:02<00:00, 2.75MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp019-fold-3.npy (6MB)\n","Starting upload for file exp019-fold-2.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.64M/5.64M [00:03<00:00, 1.88MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp019-fold-2.npy (6MB)\n","Starting upload for file exp019-fold-1.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.58M/5.58M [00:02<00:00, 1.99MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp019-fold-1.npy (6MB)\n","Starting upload for file Experiment.log\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4.68k/4.68k [00:01<00:00, 2.61kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: Experiment.log (5KB)\n"]}],"source":["def main(Config):\n","    # setup\n","    Config = setup(Config)\n","    Config.logger = Logger(Config.exp_output_dir)\n","    # load dataset\n","    train_df = get_input_data(Config, input_type=\"train\")\n","    test_df = get_input_data(Config, input_type=\"test\")\n","    # submission_df = pd.read_csv(Config.sample_submission)\n","    # extract_train_df = get_input_data_for_pseudo_labeling(Config, nrows=3000)\n","\n","    # split\n","    train_df = get_split(Config, train_df)\n","\n","    # tokenizer\n","    tokenizer = get_tokenizer(Config)\n","\n","    if not Config.inference_only:\n","        # training\n","        train_cv(\n","            cfg=Config,\n","            input_df=train_df,\n","            tokenizer=tokenizer,\n","        )\n","\n","    # predict\n","    raw_pred_df = predict_cv(\n","        cfg=Config,\n","        input_df=test_df,\n","        tokenizer=tokenizer,\n","    )\n","\n","    # pseudo-labeling\n","    # predict_for_pseudo_labeling(cfg=Config, input_df=extract_train_df, tokenizer=tokenizer)\n","\n","    # upload output to kaggle dataset\n","    if Config.upload_from_colab:\n","        from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","        def dataset_create_new(dataset_name, upload_dir):\n","            dataset_metadata = {}\n","            dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","            dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","            dataset_metadata['title'] = dataset_name\n","            with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","                json.dump(dataset_metadata, f, indent=4)\n","            api = KaggleApi()\n","            api.authenticate()\n","            api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n","\n","        dataset_create_new(dataset_name=f\"{Config.competition_name}-exp{Config.exp_id}\", upload_dir=Config.exp_output_dir)\n","\n","    # make submission\n","    if not Config.on_colab:\n","        raw_pred_df[[\"id\", \"location\"]].to_csv(os.path.join(Config.submission, \"submission.csv\"), index=False)\n","\n","\n","if __name__ == \"__main__\":\n","    main(Config)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1649697866663,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"HGttOH6cYL6d"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"exp019.ipynb","provenance":[],"mount_file_id":"1NSmsVKIjvBM3CruzGA8ddDhLvIDHnbFG","authorship_tag":"ABX9TyO6d+DzaimAObMJ5a2mxyqE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0f7e10c06771496595c15992650da6d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a0e1d62d8cd4e2c9d0b66f38ac85f9f","IPY_MODEL_e749406c0fb44a84b1be79aff4d6706a","IPY_MODEL_8937179368714a7f933b69cb08ce2f8f"],"layout":"IPY_MODEL_edafd90c76f94c34b70c4f688de2a45e"}},"7a0e1d62d8cd4e2c9d0b66f38ac85f9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cc669f7eb9645b98938644e17ca72df","placeholder":"​","style":"IPY_MODEL_cb085aff033644dfb5489a009d48418d","value":"Predicting DataLoader 0: 100%"}},"e749406c0fb44a84b1be79aff4d6706a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cf9855d65af466187483de0063f5d91","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aad7d91b0e3541d2921aa59cc80cb1d8","value":1}},"8937179368714a7f933b69cb08ce2f8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07a64933ed264182a92c4c397c884e27","placeholder":"​","style":"IPY_MODEL_1ce83732f6cf4f908e64bce4e525de7b","value":" 1/1 [00:01&lt;00:00,  1.43s/it]"}},"edafd90c76f94c34b70c4f688de2a45e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"0cc669f7eb9645b98938644e17ca72df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb085aff033644dfb5489a009d48418d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cf9855d65af466187483de0063f5d91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aad7d91b0e3541d2921aa59cc80cb1d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07a64933ed264182a92c4c397c884e27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ce83732f6cf4f908e64bce4e525de7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ca1ffcaf04f4f2db85a0645dadbf459":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32bfb11210aa43bfb441ac45ea524ed0","IPY_MODEL_e7f891f2a0804199a4e11db28a5ee4a6","IPY_MODEL_7f2dca2a6212484991d2ca1d5f9500cd"],"layout":"IPY_MODEL_fd871f6fdbd942d48bccfbc633046c6b"}},"32bfb11210aa43bfb441ac45ea524ed0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a860782468644f0aab17ba4842518cd0","placeholder":"​","style":"IPY_MODEL_b2913a8586e847ccbd213a5613ac77e8","value":"Predicting DataLoader 0: 100%"}},"e7f891f2a0804199a4e11db28a5ee4a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6891c70d2f2145898bb03256f729ff95","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f13479e811c747f7a0f06ef32318e679","value":1}},"7f2dca2a6212484991d2ca1d5f9500cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_beae6d2d0cd0475996a109eb9185c4a3","placeholder":"​","style":"IPY_MODEL_35b179cdc4924859812bc615b58b3b7e","value":" 1/1 [00:03&lt;00:00,  3.34s/it]"}},"fd871f6fdbd942d48bccfbc633046c6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"a860782468644f0aab17ba4842518cd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2913a8586e847ccbd213a5613ac77e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6891c70d2f2145898bb03256f729ff95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f13479e811c747f7a0f06ef32318e679":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"beae6d2d0cd0475996a109eb9185c4a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35b179cdc4924859812bc615b58b3b7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6da8e32f47a644a08f9441cde6ff353c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f7ec78a7f454c62a3bfadc5718f35ea","IPY_MODEL_56252af0686a4c1887309678db83bbce","IPY_MODEL_a9292b4533a941c1a113ba804bdf6dea"],"layout":"IPY_MODEL_d555d8153ff847688e1e4bae51a02b36"}},"6f7ec78a7f454c62a3bfadc5718f35ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb2438fa4905497ba80896c3b7ad72ac","placeholder":"​","style":"IPY_MODEL_a5e6810e9b4e44108b1ef5a246d7d6eb","value":"Predicting DataLoader 0: 100%"}},"56252af0686a4c1887309678db83bbce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3c622151bb844089fe17ba1dc8aa74a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8841b38710f449f3bbd61132e01e41ee","value":1}},"a9292b4533a941c1a113ba804bdf6dea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbf8e309ba744eb9a65ac79f14978235","placeholder":"​","style":"IPY_MODEL_9f23a353dbbc434a9c73cfc955d23079","value":" 1/1 [00:03&lt;00:00,  3.29s/it]"}},"d555d8153ff847688e1e4bae51a02b36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"eb2438fa4905497ba80896c3b7ad72ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5e6810e9b4e44108b1ef5a246d7d6eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3c622151bb844089fe17ba1dc8aa74a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8841b38710f449f3bbd61132e01e41ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbf8e309ba744eb9a65ac79f14978235":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f23a353dbbc434a9c73cfc955d23079":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ac3b02c00094120b76d2ceceac6cabe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d20dde0867904641ab643fee341422df","IPY_MODEL_c3c055b66fca4f469c51c1eda04b153d","IPY_MODEL_64c3bd205a554513a85eaee15b28e642"],"layout":"IPY_MODEL_36b7e88586354756970865c61f819d42"}},"d20dde0867904641ab643fee341422df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e23e227df6574e6f9e576d9ac134bd9d","placeholder":"​","style":"IPY_MODEL_a64925ec311444039884fbbd075cb53e","value":"Predicting DataLoader 0: 100%"}},"c3c055b66fca4f469c51c1eda04b153d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_671b319e88cb4667813b7d1eb3790178","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2e01fef5ec2441cac5b2a17f88fd133","value":1}},"64c3bd205a554513a85eaee15b28e642":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb1d811d77a24eada45944ef21249a46","placeholder":"​","style":"IPY_MODEL_a1bbe601139b4209bf225267d379bf79","value":" 1/1 [00:03&lt;00:00,  3.85s/it]"}},"36b7e88586354756970865c61f819d42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e23e227df6574e6f9e576d9ac134bd9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a64925ec311444039884fbbd075cb53e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"671b319e88cb4667813b7d1eb3790178":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2e01fef5ec2441cac5b2a17f88fd133":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb1d811d77a24eada45944ef21249a46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1bbe601139b4209bf225267d379bf79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63c15fcb0d794d318c4b6cd711b8a8a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb5922292694406585e765dfcbaeecc6","IPY_MODEL_1043e38b40b04cd3b2c062219e4810c9","IPY_MODEL_267319ab879941628698783c586be1e8"],"layout":"IPY_MODEL_ba35422a2d384e3ab9eb5912c9b6dbb2"}},"cb5922292694406585e765dfcbaeecc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f07ae4689aee4c0ebfc217954b6c1286","placeholder":"​","style":"IPY_MODEL_19cfcc82a0cf4cc1953d59225d672a8d","value":"Predicting DataLoader 0: 100%"}},"1043e38b40b04cd3b2c062219e4810c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75af9464c7a74a2fb017039bc6e59b57","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c9c7c96a6bbe456cb2e0f04e048d4f08","value":1}},"267319ab879941628698783c586be1e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16dd49033e7d44d18ced889c3a1bbfcf","placeholder":"​","style":"IPY_MODEL_0cac5082a97c426cbf1efefdce5f1e11","value":" 1/1 [00:03&lt;00:00,  3.03s/it]"}},"ba35422a2d384e3ab9eb5912c9b6dbb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"f07ae4689aee4c0ebfc217954b6c1286":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19cfcc82a0cf4cc1953d59225d672a8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75af9464c7a74a2fb017039bc6e59b57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9c7c96a6bbe456cb2e0f04e048d4f08":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16dd49033e7d44d18ced889c3a1bbfcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cac5082a97c426cbf1efefdce5f1e11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}