{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"3rOHeiHoOKPe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649150533782,"user_tz":-540,"elapsed":372,"user":{"displayName":"永友遥","userId":"11743586908271963047"}},"outputId":"4e1121fa-eb24-4c2a-8b41-85516da3576f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Apr  5 09:22:13 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    26W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"78XXjkCdOOzD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649150556620,"user_tz":-540,"elapsed":22843,"user":{"displayName":"永友遥","userId":"11743586908271963047"}},"outputId":"10d19cd8-5647-441e-8198-7421b8210c4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 582 kB 14.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.7 MB 72.9 MB/s \n","\u001b[K     |████████████████████████████████| 398 kB 85.7 MB/s \n","\u001b[K     |████████████████████████████████| 3.8 MB 64.9 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 67.9 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 65.7 MB/s \n","\u001b[K     |████████████████████████████████| 136 kB 73.7 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 80.8 MB/s \n","\u001b[K     |████████████████████████████████| 181 kB 72.6 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 59.5 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n","\u001b[K     |████████████████████████████████| 6.5 MB 72.9 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 84.1 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 5.7 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 87.4 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 88.3 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 3.7 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 58 kB 4.9 MB/s \n","\u001b[?25h  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q pytorch-lightning wandb torchmetrics transformers sentencepiece\n","!pip install -q --upgrade --force-reinstall --no-deps kaggle"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"nQmGCwMMOREH","executionInfo":{"status":"ok","timestamp":1649150557368,"user_tz":-540,"elapsed":756,"user":{"displayName":"永友遥","userId":"11743586908271963047"}}},"outputs":[],"source":["!mkdir /root/.kaggle\n","!cp /content/drive/MyDrive/Colab/kaggle/kaggle.json /root/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"yg3vCpmCcpvn","executionInfo":{"status":"ok","timestamp":1649150559666,"user_tz":-540,"elapsed":2302,"user":{"displayName":"永友遥","userId":"11743586908271963047"}}},"outputs":[],"source":["# import deberta-v2-v3-fast-tokenizer\n","import shutil\n","from pathlib import Path\n","\n","transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n","input_dir = Path(\"/content/drive/MyDrive/Colab/kaggle/nbme-score-clinical-patient-notes/input/deberta-v2-v3-fast-tokenizer\")\n","\n","convert_file = input_dir / \"convert_slow_tokenizer.py\"\n","conversion_path = transformers_path/convert_file.name\n","\n","if conversion_path.exists():\n","    conversion_path.unlink()\n","\n","shutil.copy(convert_file, transformers_path)\n","deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n","\n","for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n","    filepath = deberta_v2_path/filename\n","    \n","    if filepath.exists():\n","        filepath.unlink()\n","\n","    shutil.copy(input_dir/filename, filepath)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9759,"status":"ok","timestamp":1649150569418,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"tFUGUD38OVhD","outputId":"f4d06f6b-0fb1-4342-d1f5-0d2e97d96119"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["import os\n","import gc\n","import sys\n","import json\n","import itertools\n","from tqdm.auto import tqdm\n","import logging\n","import datetime\n","import ast\n","import numpy as np\n","import pandas as pd\n","import sklearn.model_selection as sms\n","from sklearn.metrics import f1_score\n","import math\n","import re\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning import Trainer, seed_everything\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n","from pytorch_lightning.loggers import WandbLogger\n","\n","from transformers import AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n","\n","import wandb\n","\n","%env TOKENIZERS_PARALLELISM=true"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1649150569419,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"1duE-kW_OZZq"},"outputs":[],"source":["class Config:\n","    # ==============================\n","    # Globals #\n","    # ==============================\n","    competition_name = \"nbme-score-clinical-patient-notes\"\n","    group = \"DeBERTa-v3-large\"\n","    exp_id = \"011\"\n","    debug = False\n","    inference_only = True\n","    upload_from_colab = True\n","    colab_dir = \"/content/drive/MyDrive/Colab/kaggle/nbme-score-clinical-patient-notes\"\n","    kaggle_json_path = \"/root/.kaggle/kaggle.json\"\n","    kaggle_dataset_path = None\n","    gpus = 1\n","    seed = 2434\n","    max_epochs = 5\n","    accumulate_grad_batches = 4\n","    precision = 32\n","    num_fold = 5\n","    train_fold = [0,1,2,3,4] # 実行するfold\n","    pred_threshold = 0.52\n","    # ==============================\n","    # Dataloader #\n","    # ==============================\n","    train_batch_size = 2\n","    valid_batch_size = 32\n","    test_batch_size = 32\n","    num_workers = 8\n","    # ==============================\n","    # Split #\n","    # ==============================\n","    split_name = \"GroupKFold\"\n","    split_params = {\n","        \"n_splits\": num_fold if not debug else 4,\n","        # \"shuffle\": True,\n","        # \"random_state\": seed,\n","    }\n","    # ==============================\n","    # Model #\n","    # ==============================\n","    model_name = \"microsoft/deberta-v3-large\"\n","    max_length = 512\n","    hidden_size = 1024\n","    num_class = 1\n","    use_backbone_dropout = False\n","    dropout = 0.0\n","    initializer_range = 0.02\n","    lstm_params = {\n","        \"num_layers\": 1,\n","        \"batch_first\": True,\n","        \"bidirectional\": True,\n","        \"dropout\": 0.0\n","    }\n","    # ==============================\n","    # Loss #\n","    # ==============================\n","    loss_name = \"BCEWithLogitsLoss\"\n","    loss_params = {\n","        \"reduction\": \"none\"\n","    }\n","    # ==============================\n","    # Optimizer #\n","    # ==============================\n","    optimizer_name = \"AdamW\"\n","    optimizer_params = {\n","        \"lr\": 2e-5,\n","        \"weight_decay\": 1e-2,\n","        \"eps\": 1e-6,\n","        \"betas\": (0.9, 0.999)\n","    }\n","    encoder_lr = 2e-5\n","    decoder_lr = 2e-5\n","    weight_decay = 0.01\n","    # ==============================\n","    # Scheduler #\n","    # ==============================\n","    scheduler_name = \"cosine-warmup\"\n","    scheduler_warmup_ratio = 0.1\n","    scheduler_params = {}\n","    scheduler_interval = \"step\"\n","    scheduler_cycle = \"one-cycle\" # epoch or one-cycle\n","    # ==============================\n","    # Callbacks #\n","    # ==============================\n","    checkpoint_params = {\n","        \"monitor\": \"val/micro-F1\",\n","        \"save_top_k\": 1,\n","        \"save_weights_only\": True,\n","        \"mode\": \"max\",\n","        \"verbose\": True,\n","    }\n","    early_stopping = False\n","    early_stopping_params = {\n","        \"monitor\": \"val/loss\",\n","        \"min_delta\": 0.0,\n","        \"patience\": 8,\n","        \"verbose\": False,\n","        \"mode\": \"min\",\n","    }"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5459,"status":"ok","timestamp":1649150574874,"user":{"displayName":"永友遥","userId":"11743586908271963047"},"user_tz":-540},"id":"dS4JYVxT1wEt"},"outputs":[],"source":["# ====================================\n","# Setup #\n","# ====================================\n","class Logger:\n","    \"\"\" ref) https://github.com/ghmagazine/kagglebook/blob/master/ch04-model-interface/code/util.py\"\"\"\n","    def __init__(self, path):\n","        self.general_logger = logging.getLogger(path)\n","        stream_handler = logging.StreamHandler()\n","        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n","        if len(self.general_logger.handlers) == 0:\n","            self.general_logger.addHandler(stream_handler)\n","            self.general_logger.addHandler(file_general_handler)\n","            self.general_logger.setLevel(logging.INFO)\n","\n","    def info(self, message):\n","        # display time\n","        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n","\n","    @staticmethod\n","    def now_string():\n","        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n","\n","\n","def setup(cfg):\n","    cfg.on_colab = \"google.colab\" in sys.modules\n","    if cfg.on_colab:\n","        # kaggle api\n","        f = open(Config.kaggle_json_path, 'r')\n","        json_data = json.load(f)\n","        os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n","        # set input/output dir\n","        cfg.input_dir = os.path.join(cfg.colab_dir, \"input\")\n","        cfg.train_csv = os.path.join(cfg.input_dir, \"cleaned_train.csv\")\n","        cfg.features_csv = os.path.join(cfg.input_dir, \"features.csv\")\n","        cfg.patient_notes_csv = os.path.join(cfg.input_dir, \"patient_notes.csv\")\n","        cfg.test_csv = os.path.join(cfg.input_dir, \"test.csv\")\n","        cfg.sample_submission = os.path.join(cfg.input_dir, \"sample_submission.csv\")\n","        cfg.output_dir = os.path.join(cfg.colab_dir, \"output\")\n","        cfg.exp_output_dir = os.path.join(cfg.output_dir, f\"exp{cfg.exp_id}\")\n","        cfg.model_dir = os.path.join(cfg.exp_output_dir, \"model\")\n","\n","        for d in [cfg.output_dir, cfg.exp_output_dir, cfg.model_dir]:\n","            os.makedirs(d, exist_ok=True)\n","            \n","        # wandb\n","        wandb.login()\n","    else:\n","        cfg.input_dir = f\"../input/{cfg.competition_name}\"\n","        cfg.train_csv = os.path.join(cfg.input_dir, \"train.csv\")\n","        cfg.features_csv = os.path.join(cfg.input_dir, \"features.csv\")\n","        cfg.patient_notes_csv = os.path.join(cfg.input_dir, \"patient_notes.csv\")\n","        cfg.test_csv = os.path.join(cfg.input_dir, \"test.csv\")\n","        cfg.sample_submission = os.path.join(cfg.input_dir, \"sample_submission.csv\")\n","        cfg.submission = \"./\"\n","        cfg.exp_output_dir = f\"exp{cfg.exp_id}\"\n","        cfg.model_dir = os.path.join(cfg.exp_output_dir, \"model\")\n","\n","        if cfg.kaggle_dataset_path is not None:\n","            cfg.model_dir = os.path.join(cfg.kaggle_dataset_path, \"model\")\n","\n","        for d in [cfg.exp_output_dir, cfg.model_dir]:\n","            os.makedirs(d, exist_ok=True)\n","\n","    return cfg\n","\n","\n","# ====================================\n","# Preprocess #\n","# ====================================\n","def get_input_data(cfg, input_type=\"train\"):\n","    input_df = pd.read_csv(cfg.train_csv) if input_type == \"train\" else pd.read_csv(cfg.test_csv)\n","    if cfg.debug and input_type != \"test\":\n","        input_df = input_df[input_df[\"pn_num\"].isin(input_df[\"pn_num\"].unique()[:100])].reset_index(drop=True)\n","    \n","    feature_texts_df = pd.read_csv(Config.features_csv)\n","    patient_notes_df = pd.read_csv(Config.patient_notes_csv)\n","\n","    if input_type == \"train\":\n","        input_df[\"annotation\"] = input_df[\"annotation\"].apply(ast.literal_eval)\n","        input_df[\"location\"] = input_df[\"location\"].apply(ast.literal_eval)\n","    \n","    input_df = input_df.merge(feature_texts_df, on=[\"feature_num\", \"case_num\"], how=\"left\")\n","    input_df = input_df.merge(patient_notes_df, on=[\"pn_num\", \"case_num\"], how=\"left\")\n","\n","    input_df[\"pn_history\"] = input_df[\"pn_history\"].apply(clean_feature_text_for_preprocess)\n","\n","    return input_df\n","\n","\n","def get_split(cfg, train_df):\n","    split_name = cfg.split_name\n","    split_params = cfg.split_params\n","    splitter = sms.__getattribute__(split_name)(**split_params)\n","\n","    groups = train_df[\"pn_num\"].to_numpy()\n","    train_df[\"fold\"] = -1\n","\n","    for fold_id, (train_idx, valid_idx) in enumerate(splitter.split(train_df, train_df[\"location\"], groups)):\n","        train_df.loc[valid_idx, \"fold\"] = int(fold_id)\n","\n","    return train_df\n","\n","\n","def get_filname_listdir(dirctory):\n","    listdir = os.listdir(dirctory)\n","    out_lst = [os.path.splitext(d)[0] for d in listdir]\n","    return out_lst\n","\n","\n","def get_tokenizer(cfg):\n","    if cfg.kaggle_dataset_path is not None:\n","        pretrained_dir = os.path.join(cfg.kaggle_dataset_path, \"pretrain_tokenizer\")\n","    else:\n","        pretrained_dir = os.path.join(cfg.exp_output_dir, \"pretrain_tokenizer\")\n","\n","    if not os.path.isdir(pretrained_dir):\n","        # deberta-v2 or deberta-v3\n","        if (\"deberta-v2\" in cfg.model_name) or (\"deberta-v3\" in cfg.model_name):\n","            tokenizer = DebertaV2TokenizerFast.from_pretrained(cfg.model_name)\n","        # except for (\"roberta\", \"deberta-v2\", \"deberta-v3\")\n","        elif \"roberta\" not in cfg.model_name:\n","            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n","        # roberta\n","        else:\n","            tokenizer = AutoTokenizer.from_pretrained(cfg.model_name, trim_offsets=False)\n","\n","        tokenizer.save_pretrained(pretrained_dir)\n","\n","    else:\n","        # deberta-v2 or deberta-v3\n","        if (\"deberta-v2\" in cfg.model_name) or (\"deberta-v3\" in cfg.model_name):\n","            tokenizer = DebertaV2TokenizerFast.from_pretrained(pretrained_dir)\n","        # except for (\"roberta\", \"deberta-v2\", \"deberta-v3\")\n","        elif \"roberta\" not in cfg.model_name:\n","            tokenizer = AutoTokenizer.from_pretrained(pretrained_dir)\n","        # roberta\n","        else:\n","            tokenizer = AutoTokenizer.from_pretrained(pretrained_dir, trim_offsets=False)\n","\n","    return tokenizer\n","\n","\n","def get_backbone(cfg):\n","    if cfg.kaggle_dataset_path is not None:\n","        pretrained_dir = os.path.join(cfg.kaggle_dataset_path, \"pretrain_model\")\n","    else:\n","        pretrained_dir = os.path.join(cfg.exp_output_dir, \"pretrain_model\")\n","\n","    if not os.path.isdir(pretrained_dir):\n","        model_config = AutoConfig.from_pretrained(cfg.model_name)\n","        if not cfg.use_backbone_dropout:\n","            model_config.attention_probs_dropout_prob = 0.0\n","            model_config.hidden_dropout_prob = 0.0\n","        backbone = AutoModel.from_pretrained(cfg.model_name, config=model_config)\n","\n","        backbone.save_pretrained(pretrained_dir)\n","\n","    else:\n","        model_config = AutoConfig.from_pretrained(pretrained_dir)\n","        if not cfg.use_backbone_dropout:\n","            model_config.attention_probs_dropout_prob = 0.0\n","            model_config.hidden_dropout_prob = 0.0\n","        backbone = AutoModel.from_pretrained(pretrained_dir, config=model_config)\n","\n","    return backbone\n","\n","\n","def clean_feature_text_for_preprocess(text: str):\n","    \"\"\"\n","    reference: https://www.kaggle.com/code/theoviel/roberta-strikes-back\n","    \"\"\"\n","    text = re.sub('I-year', '1-year', text)\n","    text = re.sub('-OR-', \" or \", text)\n","    text = re.sub('-', ' ', text)\n","\n","    return text\n","\n","\n","# ====================================\n","# Dataset #\n","# ====================================\n","def get_inputs(cfg, text: str, feature_text: str, tokenizer):\n","    encoding = tokenizer(\n","        text,\n","        feature_text,\n","        max_length=cfg.max_length,\n","        padding=\"max_length\",\n","        return_offsets_mapping=False,\n","        # add_special_tokens=True\n","    )\n","\n","    for k, v in encoding.items():\n","        encoding[k] = torch.tensor(v, dtype=torch.long)\n","\n","    return encoding\n","\n","\n","def get_label(cfg, text: str, locations: list, tokenizer):\n","    encoding = tokenizer(\n","        text,\n","        max_length=cfg.max_length,\n","        padding=\"max_length\",\n","        return_offsets_mapping=True,\n","        # add_special_tokens=True\n","    )\n","    \n","    offset_mapping = encoding[\"offset_mapping\"]\n","    ignore_idx = np.where(np.array(encoding.sequence_ids()) != 0)[0]\n","    label = np.zeros(len(offset_mapping))\n","    label[ignore_idx] = -1\n","\n","    if len(locations) != 0:\n","        for location in locations:\n","            for loc in [s.split() for s in location.split(\";\")]:\n","                start_idx = -1\n","                end_idx = -1\n","                start, end = int(loc[0]), int(loc[1])\n","                for idx in range(len(offset_mapping)):\n","                    # DeBERTaのTokenizerは前の空白も含めるため+1する\n","                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n","                        start_idx = idx - 1\n","                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n","                        end_idx = idx + 1\n","                if start_idx == -1:\n","                    start_idx = end_idx\n","                if (start_idx != -1) & (end_idx != -1):\n","                    label[start_idx: end_idx] = 1\n","    \n","    return torch.tensor(label, dtype=torch.float)\n","\n","\n","class NBMEDataset(Dataset):\n","    def __init__(self, cfg, input_df: pd.DataFrame, tokenizer, phase: str = \"train\"):\n","        self.cfg = cfg\n","        self.input_df = input_df\n","        self.tokenizer = tokenizer\n","        self.phase = phase\n","        self.pn_histories = self.input_df[\"pn_history\"].to_numpy()\n","        self.feature_texts = self.input_df[\"feature_text\"].to_numpy()\n","        self.locations = self.input_df[\"location\"].to_numpy() if self.phase is \"train\" else None\n","\n","    def __len__(self):\n","        return len(self.input_df)\n","\n","    def __getitem__(self, idx):\n","        if self.phase == \"train\":\n","            inputs = get_inputs(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.feature_texts[idx],\n","                self.tokenizer,\n","            )\n","            label = get_label(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.locations[idx],\n","                self.tokenizer,\n","            )\n","\n","            return {\n","                \"input_ids\": inputs[\"input_ids\"],\n","                \"attention_mask\": inputs[\"attention_mask\"],\n","                \"labels\": label,\n","            }\n","\n","        elif self.phase == \"test\":\n","            inputs = get_inputs(\n","                self.cfg,\n","                self.pn_histories[idx],\n","                self.feature_texts[idx],\n","                self.tokenizer,\n","            )\n","\n","            return {\n","                \"input_ids\": inputs[\"input_ids\"],\n","                \"attention_mask\": inputs[\"attention_mask\"],\n","            }\n","        else:\n","            raise NotImplementedError\n","\n","\n","class NBMEDataModule(pl.LightningDataModule):\n","    def __init__(self, cfg, tokenizer, train_df: pd.DataFrame = None, valid_df: pd.DataFrame = None, test_df: pd.DataFrame = None):\n","        super(NBMEDataModule, self).__init__()\n","\n","        self.cfg = cfg\n","        self.tokenizer = tokenizer\n","        self.train_df = train_df\n","        self.valid_df = valid_df\n","        self.test_df = test_df\n","\n","    def prepare_data(self):\n","        if self.test_df is None:\n","            self.train_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.train_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"train\"\n","            )\n","            self.val_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.valid_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"train\"\n","            )\n","        else:\n","            self.test_dataset = NBMEDataset(\n","                cfg=self.cfg,\n","                input_df=self.test_df,\n","                tokenizer=self.tokenizer,\n","                phase=\"test\"\n","            )\n","\n","    def train_dataloader(self):\n","        return DataLoader(\n","            self.train_dataset,\n","            batch_size=self.cfg.train_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","    \n","    def val_dataloader(self):\n","        return DataLoader(\n","            self.val_dataset,\n","            batch_size=self.cfg.valid_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","\n","    def predict_dataloader(self):\n","        return DataLoader(\n","            self.test_dataset,\n","            batch_size=self.cfg.test_batch_size,\n","            num_workers=self.cfg.num_workers,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","        )\n","\n","\n","# ====================================\n","# Model #\n","# ====================================\n","class NBMEModel(nn.Module):\n","    def __init__(self, cfg):\n","        super(NBMEModel, self).__init__()\n","\n","        self.cfg = cfg\n","        self.backbone = get_backbone(self.cfg)\n","        self.dropout = nn.Dropout(self.cfg.dropout)\n","        self.lstm_1 = nn.LSTM(self.cfg.hidden_size, self.cfg.hidden_size, **self.cfg.lstm_params)\n","        self.lstm_2 = nn.LSTM(self.cfg.hidden_size * 2, self.cfg.hidden_size // 2, **self.cfg.lstm_params)\n","        self.classifier = nn.Linear(self.cfg.hidden_size, self.cfg.num_class)\n","        self._init_weights(self.classifier)\n","        self._reinitialize()\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.cfg.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.cfg.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def _reinitialize(self):\n","        \"\"\"\n","        Tensorflow/Keras-like initialization\n","        \"\"\"\n","        for name, p in self.named_parameters():\n","            if 'lstm' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","            elif 'fc' in name:\n","                if 'weight' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'bias' in name:\n","                    p.data.fill_(0)\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask) # (batch_size, seq_len, hidden_size)\n","        x = outputs[0] # extract last_hidden_states\n","        x, _ = self.lstm_1(x)\n","        x, _ = self.lstm_2(x)\n","        x = self.dropout(x)\n","        x = self.classifier(x) # (batch_size, seq_len, num_class)\n","\n","        return x\n","\n","\n","class NBMELightningModule(pl.LightningModule):\n","    def __init__(self, cfg, tokenizer=None, valid_df=None, valid_labels=None):\n","        super(NBMELightningModule, self).__init__()\n","\n","        self.cfg = cfg\n","        self.model = NBMEModel(self.cfg)\n","        self.criterion = get_criterion(self.cfg)\n","        self.tokenizer = tokenizer\n","        self.valid_df = valid_df\n","        self.valid_labels = valid_labels\n","\n","    def setup(self, stage=None):\n","        # calculate training total steps\n","        if stage == \"fit\":\n","            if self.cfg.scheduler_cycle == \"one-cycle\":\n","                self.training_steps = math.ceil(len(self.trainer.datamodule.train_dataloader()) / self.trainer.accumulate_grad_batches) * self.trainer.max_epochs\n","            elif self.cfg.scheduler_cycle == \"epoch\":\n","                self.training_steps = math.ceil(len(self.trainer.datamodule.train_dataloader()) / self.trainer.accumulate_grad_batches) * 1\n","            else:\n","                raise NotImplementedError\n","            self.warmup_steps = int(self.training_steps * self.cfg.scheduler_warmup_ratio) if self.cfg.scheduler_warmup_ratio else None\n","    \n","    def forward(self, input_ids, attention_mask):\n","        return self.model(input_ids, attention_mask)\n","\n","    def training_step(self, batch, batch_idx):\n","        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        mask = (labels.view(-1, 1) != -1)\n","        loss = torch.masked_select(loss, mask).mean()\n","        self.log(\"train/loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        mask = (labels.view(-1, 1) != -1)\n","        loss = torch.masked_select(loss, mask).mean()\n","        self.log(\"val/loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n","\n","        return {\n","            \"loss\": loss,\n","            \"preds\": y_preds.detach()\n","        }\n","\n","    def validation_epoch_end(self, outputs):\n","        preds = torch.cat([output[\"preds\"] for output in outputs]).squeeze().cpu().numpy()\n","        char_preds = get_token_probs_to_char_probs(self.valid_df[\"pn_history\"].to_numpy(), preds, self.tokenizer)\n","        results = get_results(char_preds, th=0.5)\n","        preds = get_predictions(results)\n","        score = get_score(self.valid_labels, preds)\n","        self.log(\"val/micro-F1\", score, logger=True, prog_bar=True)\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n","        input_ids, attention_mask = batch[\"input_ids\"], batch[\"attention_mask\"]\n","        y_preds = self.forward(input_ids, attention_mask)\n","        y_preds = y_preds.sigmoid()\n","\n","        return y_preds.squeeze()\n","\n","    def configure_optimizers(self):\n","        optimizer_params = get_optimizer_params(self.model, self.cfg.encoder_lr, self.cfg.decoder_lr, self.cfg.weight_decay)\n","        optimizer = get_optimizer(self.cfg, optimizer_params)\n","\n","        if self.cfg.scheduler_name is None:\n","            return [optimizer]\n","        else:\n","            scheduler = get_scheduler(self.cfg, optimizer, num_warmup_steps=self.warmup_steps, num_training_steps=self.training_steps)\n","            scheduler = {\"scheduler\": scheduler, \"interval\": self.cfg.scheduler_interval}\n","\n","            return [optimizer], [scheduler]\n","\n","\n","# ====================================\n","# Criterion, Optimizer, Scheduler #\n","# ====================================\n","def get_criterion(cfg):\n","    loss_name = cfg.loss_name\n","    loss_params = cfg.loss_params\n","\n","    return nn.__getattribute__(loss_name)(**loss_params)\n","\n","\n","def get_optimizer(cfg, parameters):\n","    optimizer_name = cfg.optimizer_name\n","    optimizer_params = cfg.optimizer_params\n","\n","    return optim.__getattribute__(optimizer_name)(parameters, **optimizer_params)\n","\n","\n","def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","    # param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_parameters = [\n","        {'params': [p for n, p in model.backbone.named_parameters() if not any(nd in n for nd in no_decay)],\n","            'lr': encoder_lr, 'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.backbone.named_parameters() if any(nd in n for nd in no_decay)],\n","            'lr': encoder_lr, 'weight_decay': 0.0},\n","        {'params': [p for n, p in model.named_parameters() if \"backbone\" not in n],\n","            'lr': decoder_lr, 'weight_decay': 0.0}\n","    ]\n","\n","    return optimizer_parameters\n","\n","\n","def get_scheduler(cfg, optimizer, num_warmup_steps=None, num_training_steps=None):\n","    scheduler_name = cfg.scheduler_name\n","    scheduler_params = cfg.scheduler_params\n","\n","    if scheduler_name == \"cosine-warmup\":\n","        return get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","            **scheduler_params\n","        )\n","    elif scheduler_name == \"linear-warmup\":\n","        return get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps,\n","            **scheduler_params\n","        )\n","    else:\n","        return optim.lr_scheduler.__getattribute__(scheduler_name)(optimizer, **scheduler_params)\n","\n","\n","# ====================================\n","# Train & Predict #\n","# ====================================\n","def train_fold(cfg, train_df, valid_df, tokenizer, fold, valid_labels):\n","    # Seed\n","    seed_everything(cfg.seed)\n","\n","    # Wandb\n","    wandb_logger = WandbLogger(\n","        project=cfg.competition_name,\n","        group=cfg.group,\n","        name=f\"exp{cfg.exp_id}-fold-{fold}\",\n","        job_type=f\"exp{cfg.exp_id}\",\n","        reinit=True,\n","        anonymous=\"must\",\n","    )\n","\n","    # Model Checkpoint\n","    checkpoint = ModelCheckpoint(\n","        dirpath=cfg.model_dir,\n","        # filename=f\"exp{cfg.exp_id}-fold-{fold}\" + \"-{epoch}\",\n","        filename=f\"exp{cfg.exp_id}-fold-{fold}\",\n","        **cfg.checkpoint_params,\n","    )\n","\n","    # Learning Rate\n","    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n","    callbacks = [checkpoint, lr_monitor]\n","\n","    # Early Stopping\n","    if cfg.early_stopping:\n","        early_stopping = EarlyStopping(**cfg.early_stopping_params)\n","        callbacks += [early_stopping]\n","    \n","    # DataModule\n","    lightning_datamodule = NBMEDataModule(\n","        cfg=cfg,\n","        tokenizer=tokenizer,\n","        train_df=train_df,\n","        valid_df=valid_df,\n","    )\n","\n","    # Model\n","    lightning_model = NBMELightningModule(\n","        cfg,\n","        tokenizer,\n","        valid_df,\n","        valid_labels,\n","    )\n","\n","    # Trainer\n","    trainer = Trainer(\n","        gpus=cfg.gpus,\n","        max_epochs=cfg.max_epochs,\n","        callbacks=callbacks,\n","        logger=[wandb_logger],\n","        accumulate_grad_batches=cfg.accumulate_grad_batches,\n","        precision=cfg.precision,\n","        # deterministic=True,\n","        benchmark=False,\n","    )\n","\n","    trainer.fit(lightning_model, datamodule=lightning_datamodule)\n","    wandb.finish(quiet=True)\n","\n","    del lightning_datamodule, lightning_model, trainer\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","\n","def train_cv(cfg, input_df, tokenizer):\n","    oof_char_probs = []\n","    true_labels = []\n","\n","    for fold_id in range(cfg.num_fold):\n","        if fold_id in cfg.train_fold:\n","            filename = f\"exp{cfg.exp_id}-fold-{fold_id}\"\n","            filelist = get_filname_listdir(cfg.model_dir)\n","\n","            train_df = input_df[input_df[\"fold\"] != fold_id].reset_index(drop=True)\n","            valid_df = input_df[input_df[\"fold\"] == fold_id].reset_index(drop=True)\n","            valid_labels = create_labels_for_scoring(valid_df)\n","\n","            # training\n","            if not filename in filelist:\n","                train_fold(\n","                    cfg=cfg,\n","                    train_df=train_df,\n","                    valid_df=valid_df,\n","                    tokenizer=tokenizer,\n","                    fold=fold_id,\n","                    valid_labels=valid_labels,\n","                )\n","\n","            # oof\n","            char_probs = predict(\n","                cfg=cfg,\n","                input_df=valid_df,\n","                tokenizer=tokenizer,\n","                filename=filename,\n","                labels=valid_labels,\n","            )\n","            results = get_results(char_probs, th=0.5)\n","            preds = get_predictions(results)\n","            oof_score = get_score(valid_labels, preds)\n","            cfg.logger.info(f\"Fold: {fold_id} oof-score: {oof_score}\")\n","            \n","            oof_char_probs += char_probs\n","            true_labels += valid_labels\n","\n","    return oof_char_probs, true_labels\n","\n","\n","def predict_raw_prediction(cfg, input_df, tokenizer, filename, labels=None):\n","    checkpoint_path = os.path.join(cfg.model_dir, filename + \".ckpt\")\n","\n","    lightning_model = NBMELightningModule(\n","        cfg,\n","        tokenizer,\n","        input_df,\n","        labels,\n","    )\n","\n","    lightning_model = lightning_model.load_from_checkpoint(\n","        checkpoint_path=checkpoint_path,\n","        cfg=cfg,\n","    )\n","\n","    lightning_datamodule = NBMEDataModule(\n","        cfg,\n","        tokenizer=tokenizer,\n","        test_df=input_df\n","    )\n","\n","    trainer = Trainer(\n","        gpus=cfg.gpus,\n","    )\n","\n","    preds = trainer.predict(\n","        lightning_model,\n","        datamodule=lightning_datamodule,\n","        return_predictions=True\n","    )\n","\n","    preds = torch.cat(preds).cpu().numpy() # (sample, max_seq, num_class)\n","\n","    del lightning_datamodule, lightning_model, trainer\n","\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    \n","    return preds\n","    \n","\n","def predict(cfg, input_df, tokenizer, filename, labels):\n","    file_path = os.path.join(cfg.exp_output_dir, f\"{filename}.npy\")\n","    \n","    if os.path.isfile(file_path):\n","        preds = np.load(file_path)\n","    else:\n","        preds = predict_raw_prediction(cfg, input_df, tokenizer, filename, labels)\n","        np.save(os.path.join(cfg.exp_output_dir, filename), preds)\n","\n","    char_probs = get_token_probs_to_char_probs(input_df[\"pn_history\"].to_numpy(), preds, tokenizer)\n","\n","    return char_probs\n","\n","\n","def predict_cv(cfg, input_df, tokenizer):\n","    \"\"\"\n","    CVモデルで予測\n","    \"\"\"\n","    fold_preds = []\n","    for fold_id in range(cfg.num_fold):\n","        if fold_id in cfg.train_fold:\n","            filename = f\"exp{cfg.exp_id}-fold-{fold_id}\"\n","            preds = predict_raw_prediction(cfg, input_df, tokenizer, filename)\n","            char_preds = get_token_probs_to_char_probs(input_df[\"pn_history\"].to_numpy(), preds, tokenizer)\n","            fold_preds.append(char_preds)\n","\n","    fold_preds = np.mean(fold_preds, axis=0)\n","    results = get_results(fold_preds, th=cfg.pred_threshold)\n","\n","    output_df = input_df.copy()\n","    output_df[\"location\"] = results\n","    \n","    return output_df\n","\n","\n","def get_token_probs_to_char_probs(texts, predictions, tokenizer):\n","    \"\"\"\n","    予測値をtoken-level -> char-levelに変形\n","    \"\"\"\n","    results = [np.zeros(len(t)) for t in texts]\n","    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n","        encoded = tokenizer(\n","            text, \n","            add_special_tokens=True,\n","            return_offsets_mapping=True\n","        )\n","        \n","        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n","            start = offset_mapping[0]\n","            end = offset_mapping[1]\n","\n","            # 先行するスペースがあればスパンから除く\n","            # if text[start] == \" \":\n","            #     start = start + 1\n","            \n","            results[i][start: end] = pred\n","    \n","    return results\n","\n","\n","def get_results(char_probs, th=0.5):\n","    \"\"\"\n","    \";\"区切りのスパンに変換\n","    \"\"\"\n","    results = []\n","    for char_prob in char_probs:\n","        result = np.where(char_prob >= th)[0] + 1\n","        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n","        result = [f\"{min(r)} {max(r)}\" for r in result]\n","        result = \";\".join(result)\n","        results.append(result)\n","    \n","    return results\n","\n","\n","def get_predictions(results):\n","    \"\"\"\n","    各スパンのリストを要素とするリストに変換\n","    '3 4;7 9;12 13' -> [[3, 4], [7, 9], [12, 13]]\n","    \"\"\"\n","    predictions = []\n","    for result in results:\n","        prediction = []\n","        if result != \"\":\n","            for loc in [s.split() for s in result.split(';')]:\n","                start, end = int(loc[0]), int(loc[1])\n","                prediction.append([start, end])\n","        predictions.append(prediction)\n","    \n","    return predictions\n","\n","\n","def create_labels_for_scoring(df):\n","    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n","    df = df.copy()\n","    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n","    for i in range(len(df)):\n","        lst = df.loc[i, 'location']\n","        if lst:\n","            new_lst = ';'.join(lst)\n","            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n","    # create labels\n","    truths = []\n","    for location_list in df['location_for_create_labels'].values:\n","        truth = []\n","        if len(location_list) > 0:\n","            location = location_list[0]\n","            for loc in [s.split() for s in location.split(';')]:\n","                start, end = int(loc[0]), int(loc[1])\n","                truth.append([start, end])\n","        truths.append(truth)\n","    \n","    return truths\n","\n","\n","# ====================================\n","# Metrics #\n","# ====================================\n","def micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on binary arrays.\n","\n","    Args:\n","        preds (list of lists of ints): Predictions.\n","        truths (list of lists of ints): Ground truths.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    # Micro : aggregating over all instances\n","    preds = np.concatenate(preds)\n","    truths = np.concatenate(truths)\n","\n","    return f1_score(truths, preds)\n","\n","\n","def spans_to_binary(spans, length=None):\n","    \"\"\"\n","    Converts spans to a binary array indicating whether each character is in the span.\n","\n","    Args:\n","        spans (list of lists of two ints): Spans.\n","\n","    Returns:\n","        np array [length]: Binarized spans.\n","    \"\"\"\n","    length = np.max(spans) if length is None else length\n","    binary = np.zeros(length)\n","    for start, end in spans:\n","        binary[start:end] = 1\n","    \n","    return binary\n","\n","\n","def span_micro_f1(preds, truths):\n","    \"\"\"\n","    Micro f1 on spans.\n","\n","    Args:\n","        preds (list of lists of two ints): Prediction spans.\n","        truths (list of lists of two ints): Ground truth spans.\n","\n","    Returns:\n","        float: f1 score.\n","    \"\"\"\n","    bin_preds = []\n","    bin_truths = []\n","    for pred, truth in zip(preds, truths):\n","        if not len(pred) and not len(truth):\n","            continue\n","        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n","        bin_preds.append(spans_to_binary(pred, length))\n","        bin_truths.append(spans_to_binary(truth, length))\n","    \n","    return micro_f1(bin_preds, bin_truths)\n","\n","\n","def get_score(y_true, y_pred):\n","    score = span_micro_f1(y_true, y_pred)\n","\n","    return score\n","\n","\n","# ====================================\n","# Postprocess #\n","# ====================================\n","def optimize_threshold_for_postprocess(cfg, valid_labels, char_probs):\n","    best_thres = 0.5\n","    best_score = 0.0\n","    for th in np.arange(0.45, 0.55, 0.01):\n","        th = np.round(th, 2)\n","        results = get_results(char_probs, th=th)\n","        preds = get_predictions(results)\n","        score = get_score(valid_labels, preds)\n","\n","        if best_score < score:\n","            best_thres = th\n","            best_score = score\n","\n","        cfg.logger.info(f\"th: {th}  score: {score:.5f}\")\n","    cfg.logger.info(f\"best_th: {best_thres}  score: {best_score:.5f}\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f992c1550d9743f88295bde4ee5662e3","43bdfefe09554987a47ef0c32f4910c6","598c20c435524c2d815793ec8bfead44","12b5783dbe8d4807b46a4361062fc67a","adc3e391a80141a8ba6236cb59d8d7ee","8d913c2f9c034b479b6a886179e69ccc","01e970b56f6343108c3268f37884a22f","3960c117f51f444494e5e79d4196687c","4673f0649ef943f18bee3692bffdf0e4","aa72936dfa2641b1b02044ab2cfed62f","edb7c1c2e43b45bfaf54bad8d4cbf482","0e9a6d205330420c96e2f59c27a28430","9c37fbe339714cccb86a913142c1a506","82d27265956843d5be5319e096cb8af3","bf19293a3035443ab34c18d4030e2e3a","a7755415a37245f6836d6edc08213d64","e56a105a3a494dfb873f6f190bced1f2","ab47973d58e5405988eae27c2557795d","e2a17bb953874692a7f96e21da5e0183","e74f4af410f5413c98328607f188af62","443805996fc347e1831a6997f49ec1f2","d11da900616f4748949c48bb5b5cdde1","90ac60447c044777b51048dda6df7ce8","5850cb538d6f412c9113d8a60f9ce421","69974032ad274e5fbf04e71200af6d3e","de0a43d8e10c421d8dfbf51f9153eae6","4b9f61c8423143a2a458c1993801d555","ee7ab9695216454fb81ad47932760923","2278bc8542514bbf999577716d82cdc8","e0bb2ad238ea44c894e02969978fd4da","699ea7b6e21f47a38c01b1d7e0dd8d7c","bdcaef110e9740eaa5c591dd73cdeae9","583ee0a78c8a48f0a3149505b29de607","337ca406942842eb94dea1a4a1f06569","b281dbb782ff4e0096e50209fcae2ca1","58be74c77ee14cca8f3771deea97ce16","16660a41b96c442a889ea7e339ad94c4","f45ddcb5901c43bdb712af4548b7f4ed","0e038f93475d4a2c81debab5629ddc46","8127016e35c842bd9331624be435efc6","c068132a53a14fbfbf8983602174587d","7cd8f7fc6cf0443aad25e620a0a471ed","91ceb5d90521468c85cd2ceddc048e1c","3c0cff0ad60f4176a354238eaa62ffd6","d8e944e8293a49b49e7b2c3158de4875","3aa6820c8fdc43adaffcfe5b0b9db473","92316e30ac3c4b90bca6f7764ce0e89e","fb8a8531ee42425d87c2ecf0d620b304","3454f0acfcfd4f9380d707913daf4cc6","ca2ad58ca3564da286675128e4a854dd","590a2c79c93e4d7fa322ea95f078bfb7","ddbdd454ec4b4bb8852cc2a81b72e364","e791d041b7a542c4a76cfa61078b4686","0589cf32bf20427c92c69967466147e8","1f037aa016134d80885bcdd076e14009"]},"id":"ytwVk3R5jvUe","executionInfo":{"status":"ok","timestamp":1649151098674,"user_tz":-540,"elapsed":523812,"user":{"displayName":"永友遥","userId":"11743586908271963047"}},"outputId":"05025fc5-f18b-4869-c928-f7732ed8cb9e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n","  category=PossibleUserWarning,\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","Missing logger folder: /content/lightning_logs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f992c1550d9743f88295bde4ee5662e3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e9a6d205330420c96e2f59c27a28430"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90ac60447c044777b51048dda6df7ce8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"337ca406942842eb94dea1a4a1f06569"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8e944e8293a49b49e7b2c3158de4875"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting upload for file model.tar\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8.59G/8.59G [03:56<00:00, 39.1MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: model.tar (9GB)\n","Starting upload for file pretrain_tokenizer.tar\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10.6M/10.6M [00:03<00:00, 3.45MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: pretrain_tokenizer.tar (11MB)\n","Starting upload for file pretrain_model.tar\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.62G/1.62G [00:43<00:00, 39.7MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: pretrain_model.tar (2GB)\n","Starting upload for file exp011-fold-0.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:03<00:00, 1.92MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp011-fold-0.npy (6MB)\n","Starting upload for file exp011-fold-1.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:02<00:00, 2.59MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp011-fold-1.npy (6MB)\n","Starting upload for file exp011-fold-2.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:02<00:00, 2.82MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp011-fold-2.npy (6MB)\n","Starting upload for file exp011-fold-3.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:02<00:00, 2.36MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp011-fold-3.npy (6MB)\n","Starting upload for file exp011-fold-4.npy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.59M/5.59M [00:02<00:00, 2.61MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: exp011-fold-4.npy (6MB)\n","Starting upload for file Experiment.log\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 902/902 [00:02<00:00, 301B/s]  \n"]},{"output_type":"stream","name":"stdout","text":["Upload successful: Experiment.log (902B)\n"]}],"source":["def main(Config):\n","    # setup\n","    Config = setup(Config)\n","    Config.logger = Logger(Config.exp_output_dir)\n","    # load dataset\n","    train_df = get_input_data(Config, input_type=\"train\")\n","    test_df = get_input_data(Config, input_type=\"test\")\n","    submission_df = pd.read_csv(Config.sample_submission)\n","\n","    # split\n","    train_df = get_split(Config, train_df)\n","\n","    # tokenizer\n","    tokenizer = get_tokenizer(Config)\n","\n","    if not Config.inference_only:\n","        # training\n","        raw_oof_char_probs, true_labels = train_cv(\n","            cfg=Config,\n","            input_df=train_df,\n","            tokenizer=tokenizer,\n","        )\n","        # optimize threshold\n","        optimize_threshold_for_postprocess(Config, true_labels, raw_oof_char_probs)\n","\n","    # predict\n","    raw_pred_df = predict_cv(\n","        cfg=Config,\n","        input_df=test_df,\n","        tokenizer=tokenizer,\n","    )\n","\n","    # upload output to kaggle dataset\n","    if Config.upload_from_colab:\n","        from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","        def dataset_create_new(dataset_name, upload_dir):\n","            dataset_metadata = {}\n","            dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","            dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","            dataset_metadata['title'] = dataset_name\n","            with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","                json.dump(dataset_metadata, f, indent=4)\n","            api = KaggleApi()\n","            api.authenticate()\n","            api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')\n","\n","        dataset_create_new(dataset_name=f\"{Config.competition_name}-exp{Config.exp_id}\", upload_dir=Config.exp_output_dir)\n","\n","    # make submission\n","    if not Config.on_colab:\n","        raw_pred_df[[\"id\", \"location\"]].to_csv(os.path.join(Config.submission, \"submission.csv\"), index=False)\n","\n","\n","if __name__ == \"__main__\":\n","    main(Config)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"nfsZJQyVq-oT","executionInfo":{"status":"ok","timestamp":1649151098675,"user_tz":-540,"elapsed":16,"user":{"displayName":"永友遥","userId":"11743586908271963047"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"exp011.ipynb","provenance":[],"mount_file_id":"1PfcuiewqayXeUwvrfyUiajbRl4QjLips","authorship_tag":"ABX9TyOkOdLIs3HH39kpLnRj1swh"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f992c1550d9743f88295bde4ee5662e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43bdfefe09554987a47ef0c32f4910c6","IPY_MODEL_598c20c435524c2d815793ec8bfead44","IPY_MODEL_12b5783dbe8d4807b46a4361062fc67a"],"layout":"IPY_MODEL_adc3e391a80141a8ba6236cb59d8d7ee"}},"43bdfefe09554987a47ef0c32f4910c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d913c2f9c034b479b6a886179e69ccc","placeholder":"​","style":"IPY_MODEL_01e970b56f6343108c3268f37884a22f","value":"Predicting DataLoader 0: 100%"}},"598c20c435524c2d815793ec8bfead44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3960c117f51f444494e5e79d4196687c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4673f0649ef943f18bee3692bffdf0e4","value":1}},"12b5783dbe8d4807b46a4361062fc67a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa72936dfa2641b1b02044ab2cfed62f","placeholder":"​","style":"IPY_MODEL_edb7c1c2e43b45bfaf54bad8d4cbf482","value":" 1/1 [00:01&lt;00:00,  1.31s/it]"}},"adc3e391a80141a8ba6236cb59d8d7ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"8d913c2f9c034b479b6a886179e69ccc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01e970b56f6343108c3268f37884a22f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3960c117f51f444494e5e79d4196687c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4673f0649ef943f18bee3692bffdf0e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa72936dfa2641b1b02044ab2cfed62f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edb7c1c2e43b45bfaf54bad8d4cbf482":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e9a6d205330420c96e2f59c27a28430":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c37fbe339714cccb86a913142c1a506","IPY_MODEL_82d27265956843d5be5319e096cb8af3","IPY_MODEL_bf19293a3035443ab34c18d4030e2e3a"],"layout":"IPY_MODEL_a7755415a37245f6836d6edc08213d64"}},"9c37fbe339714cccb86a913142c1a506":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e56a105a3a494dfb873f6f190bced1f2","placeholder":"​","style":"IPY_MODEL_ab47973d58e5405988eae27c2557795d","value":"Predicting DataLoader 0: 100%"}},"82d27265956843d5be5319e096cb8af3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2a17bb953874692a7f96e21da5e0183","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e74f4af410f5413c98328607f188af62","value":1}},"bf19293a3035443ab34c18d4030e2e3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_443805996fc347e1831a6997f49ec1f2","placeholder":"​","style":"IPY_MODEL_d11da900616f4748949c48bb5b5cdde1","value":" 1/1 [00:01&lt;00:00,  1.79s/it]"}},"a7755415a37245f6836d6edc08213d64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e56a105a3a494dfb873f6f190bced1f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab47973d58e5405988eae27c2557795d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2a17bb953874692a7f96e21da5e0183":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e74f4af410f5413c98328607f188af62":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"443805996fc347e1831a6997f49ec1f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d11da900616f4748949c48bb5b5cdde1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90ac60447c044777b51048dda6df7ce8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5850cb538d6f412c9113d8a60f9ce421","IPY_MODEL_69974032ad274e5fbf04e71200af6d3e","IPY_MODEL_de0a43d8e10c421d8dfbf51f9153eae6"],"layout":"IPY_MODEL_4b9f61c8423143a2a458c1993801d555"}},"5850cb538d6f412c9113d8a60f9ce421":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee7ab9695216454fb81ad47932760923","placeholder":"​","style":"IPY_MODEL_2278bc8542514bbf999577716d82cdc8","value":"Predicting DataLoader 0: 100%"}},"69974032ad274e5fbf04e71200af6d3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0bb2ad238ea44c894e02969978fd4da","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_699ea7b6e21f47a38c01b1d7e0dd8d7c","value":1}},"de0a43d8e10c421d8dfbf51f9153eae6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdcaef110e9740eaa5c591dd73cdeae9","placeholder":"​","style":"IPY_MODEL_583ee0a78c8a48f0a3149505b29de607","value":" 1/1 [00:01&lt;00:00,  1.79s/it]"}},"4b9f61c8423143a2a458c1993801d555":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"ee7ab9695216454fb81ad47932760923":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2278bc8542514bbf999577716d82cdc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0bb2ad238ea44c894e02969978fd4da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"699ea7b6e21f47a38c01b1d7e0dd8d7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bdcaef110e9740eaa5c591dd73cdeae9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"583ee0a78c8a48f0a3149505b29de607":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"337ca406942842eb94dea1a4a1f06569":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b281dbb782ff4e0096e50209fcae2ca1","IPY_MODEL_58be74c77ee14cca8f3771deea97ce16","IPY_MODEL_16660a41b96c442a889ea7e339ad94c4"],"layout":"IPY_MODEL_f45ddcb5901c43bdb712af4548b7f4ed"}},"b281dbb782ff4e0096e50209fcae2ca1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e038f93475d4a2c81debab5629ddc46","placeholder":"​","style":"IPY_MODEL_8127016e35c842bd9331624be435efc6","value":"Predicting DataLoader 0: 100%"}},"58be74c77ee14cca8f3771deea97ce16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c068132a53a14fbfbf8983602174587d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cd8f7fc6cf0443aad25e620a0a471ed","value":1}},"16660a41b96c442a889ea7e339ad94c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91ceb5d90521468c85cd2ceddc048e1c","placeholder":"​","style":"IPY_MODEL_3c0cff0ad60f4176a354238eaa62ffd6","value":" 1/1 [00:01&lt;00:00,  1.78s/it]"}},"f45ddcb5901c43bdb712af4548b7f4ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"0e038f93475d4a2c81debab5629ddc46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8127016e35c842bd9331624be435efc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c068132a53a14fbfbf8983602174587d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cd8f7fc6cf0443aad25e620a0a471ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91ceb5d90521468c85cd2ceddc048e1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c0cff0ad60f4176a354238eaa62ffd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8e944e8293a49b49e7b2c3158de4875":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3aa6820c8fdc43adaffcfe5b0b9db473","IPY_MODEL_92316e30ac3c4b90bca6f7764ce0e89e","IPY_MODEL_fb8a8531ee42425d87c2ecf0d620b304"],"layout":"IPY_MODEL_3454f0acfcfd4f9380d707913daf4cc6"}},"3aa6820c8fdc43adaffcfe5b0b9db473":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca2ad58ca3564da286675128e4a854dd","placeholder":"​","style":"IPY_MODEL_590a2c79c93e4d7fa322ea95f078bfb7","value":"Predicting DataLoader 0: 100%"}},"92316e30ac3c4b90bca6f7764ce0e89e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddbdd454ec4b4bb8852cc2a81b72e364","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e791d041b7a542c4a76cfa61078b4686","value":1}},"fb8a8531ee42425d87c2ecf0d620b304":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0589cf32bf20427c92c69967466147e8","placeholder":"​","style":"IPY_MODEL_1f037aa016134d80885bcdd076e14009","value":" 1/1 [00:01&lt;00:00,  1.82s/it]"}},"3454f0acfcfd4f9380d707913daf4cc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"ca2ad58ca3564da286675128e4a854dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"590a2c79c93e4d7fa322ea95f078bfb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ddbdd454ec4b4bb8852cc2a81b72e364":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e791d041b7a542c4a76cfa61078b4686":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0589cf32bf20427c92c69967466147e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f037aa016134d80885bcdd076e14009":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}